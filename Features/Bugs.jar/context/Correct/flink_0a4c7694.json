{
  "files": [
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Method",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n    synchronized(requestLock) {\n        if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n            numberOfUninitializedChannels++;\n        }\n    }\n}",
            "dst_parent": "public final class BufferReader implements org.apache.flink.runtime.io.network.api.reader.BufferReaderBase {\n    private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger(org.apache.flink.runtime.io.network.api.reader.BufferReader.class);\n\n    private final java.lang.Object requestLock = new java.lang.Object();\n\n    private final org.apache.flink.runtime.execution.RuntimeEnvironment environment;\n\n    private final org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment;\n\n    private final org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent> taskEventHandler = new org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private final org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId;\n\n    private final int totalNumberOfInputChannels;\n\n    private final int queueToRequest;\n\n    private final java.util.Map<org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID, org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannels;\n\n    private org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool;\n\n    private boolean isReleased;\n\n    private boolean isTaskEvent;\n\n    private final java.util.concurrent.BlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannelsWithData = new java.util.concurrent.LinkedBlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel>();\n\n    private final java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>> readerListener = new java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>>(null);\n\n    private final java.util.List<org.apache.flink.runtime.event.task.TaskEvent> pendingEvents = new java.util.ArrayList<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private int numberOfUninitializedChannels;\n\n    private boolean isIterativeReader;\n\n    private int currentNumEndOfSuperstepEvents;\n\n    private int channelIndexOfLastReadBuffer = -1;\n\n    private boolean hasRequestedPartitions = false;\n\n    public BufferReader(org.apache.flink.runtime.execution.RuntimeEnvironment environment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId, int numberOfInputChannels, int queueToRequest) {\n        this.consumedResultId = com.google.common.base.Preconditions.checkNotNull(consumedResultId);\n        this.environment = com.google.common.base.Preconditions.checkNotNull(environment);\n        this.networkEnvironment = networkEnvironment;\n        com.google.common.base.Preconditions.checkArgument(numberOfInputChannels >= 0);\n        this.totalNumberOfInputChannels = numberOfInputChannels;\n        com.google.common.base.Preconditions.checkArgument(queueToRequest >= 0);\n        this.queueToRequest = queueToRequest;\n        this.inputChannels = com.google.common.collect.Maps.newHashMapWithExpectedSize(numberOfInputChannels);\n    }\n\n    public void setBufferPool(org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool) {\n        com.google.common.base.Preconditions.checkArgument(bufferPool.getNumberOfRequiredMemorySegments() == totalNumberOfInputChannels, \"Buffer pool has not enough buffers for this reader.\");\n        com.google.common.base.Preconditions.checkState(this.bufferPool == null, \"Buffer pool has already been set for reader.\");\n        this.bufferPool = com.google.common.base.Preconditions.checkNotNull(bufferPool);\n    }\n\n    public org.apache.flink.runtime.jobgraph.IntermediateDataSetID getConsumedResultId() {\n        return consumedResultId;\n    }\n\n    public java.lang.String getTaskNameWithSubtasks() {\n        return environment.getTaskNameWithSubtasks();\n    }\n\n    public org.apache.flink.runtime.io.network.partition.IntermediateResultPartitionProvider getIntermediateResultPartitionProvider() {\n        return networkEnvironment.getPartitionManager();\n    }\n\n    public org.apache.flink.runtime.io.network.TaskEventDispatcher getTaskEventDispatcher() {\n        return networkEnvironment.getTaskEventDispatcher();\n    }\n\n    public org.apache.flink.runtime.io.network.ConnectionManager getConnectionManager() {\n        return networkEnvironment.getConnectionManager();\n    }\n\n    @java.lang.Override\n    public int getNumberOfInputChannels() {\n        return totalNumberOfInputChannels;\n    }\n\n    public org.apache.flink.runtime.io.network.buffer.BufferProvider getBufferProvider() {\n        return bufferPool;\n    }\n\n    public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        synchronized(requestLock) {\n            if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n                numberOfUninitializedChannels++;\n            }\n        }\n    }\n\n    public void updateInputChannel(org.apache.flink.runtime.deployment.PartitionInfo partitionInfo) throws java.io.IOException {\n        synchronized(requestLock) {\n            if (isReleased) {\n                return;\n            }\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel current = inputChannels.get(partitionId);\n            if (current.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class) {\n                org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n                org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n                if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n                    newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n                } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n                    newChannel = unknownChannel.toLocalInputChannel();\n                } else {\n                    throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n                }\n                inputChannels.put(partitionId, newChannel);\n                newChannel.requestIntermediateResultPartition(queueToRequest);\n                for (org.apache.flink.runtime.event.task.TaskEvent event : pendingEvents) {\n                    newChannel.sendTaskEvent(event);\n                }\n                if ((--numberOfUninitializedChannels) == 0) {\n                    pendingEvents.clear();\n                }\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void requestPartitionsOnce() throws java.io.IOException {\n        if (!hasRequestedPartitions) {\n            if (totalNumberOfInputChannels != inputChannels.size()) {\n                throw new java.lang.IllegalStateException(\"Mismatch between number of total input channels and the currently number of set input channels.\");\n            }\n            synchronized(requestLock) {\n                for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                    inputChannel.requestIntermediateResultPartition(queueToRequest);\n                }\n            }\n            hasRequestedPartitions = true;\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBufferBlocking() throws java.io.IOException, java.lang.InterruptedException {\n        requestPartitionsOnce();\n        while (true) {\n            if (java.lang.Thread.interrupted()) {\n                throw new java.lang.InterruptedException();\n            }\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel currentChannel = null;\n            while (currentChannel == null) {\n                currentChannel = inputChannelsWithData.poll(2000, java.util.concurrent.TimeUnit.MILLISECONDS);\n            } \n            isTaskEvent = false;\n            final org.apache.flink.runtime.io.network.buffer.Buffer buffer = currentChannel.getNextBuffer();\n            if (buffer == null) {\n                throw new java.lang.IllegalStateException(\"Bug in reader logic: queried for a buffer although none was available.\");\n            }\n            if (buffer.isBuffer()) {\n                channelIndexOfLastReadBuffer = currentChannel.getChannelIndex();\n                return buffer;\n            } else {\n                try {\n                    final org.apache.flink.runtime.event.task.AbstractEvent event = org.apache.flink.runtime.io.network.api.serialization.EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n                    if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfPartitionEvent.class) {\n                        currentChannel.releaseAllResources();\n                        return null;\n                    } else if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfSuperstepEvent.class) {\n                        incrementEndOfSuperstepEventAndCheck();\n                        return null;\n                    } else if (event instanceof org.apache.flink.runtime.event.task.TaskEvent) {\n                        taskEventHandler.publish(((org.apache.flink.runtime.event.task.TaskEvent) (event)));\n                        isTaskEvent = true;\n                        return null;\n                    } else {\n                        throw new java.lang.IllegalStateException((((\"Received unexpected event \" + event) + \" from input channel \") + currentChannel) + \".\");\n                    }\n                } catch (java.lang.Throwable t) {\n                    throw new java.io.IOException(\"Error while reading event: \" + t.getMessage(), t);\n                } finally {\n                    buffer.recycle();\n                }\n            }\n        } \n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBuffer(org.apache.flink.runtime.io.network.buffer.Buffer exchangeBuffer) {\n        throw new java.lang.UnsupportedOperationException(\"Buffer exchange when reading data is not yet supported.\");\n    }\n\n    @java.lang.Override\n    public int getChannelIndexOfLastBuffer() {\n        return channelIndexOfLastReadBuffer;\n    }\n\n    @java.lang.Override\n    public boolean isTaskEvent() {\n        return isTaskEvent;\n    }\n\n    @java.lang.Override\n    public boolean isFinished() {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                if (!inputChannel.isReleased()) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n\n    public void releaseAllResources() throws java.io.IOException {\n        synchronized(requestLock) {\n            if (!isReleased) {\n                try {\n                    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                        try {\n                            inputChannel.releaseAllResources();\n                        } catch (java.io.IOException e) {\n                            org.apache.flink.runtime.io.network.api.reader.BufferReader.LOG.warn(\"Error during release of channel resources: \" + e.getMessage(), e);\n                        }\n                    }\n                    if (bufferPool != null) {\n                        bufferPool.destroy();\n                    }\n                } finally {\n                    isReleased = true;\n                }\n            }\n        }\n    }\n\n    public void onAvailableInputChannel(org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        inputChannelsWithData.add(inputChannel);\n        if (readerListener.get() != null) {\n            readerListener.get().onEvent(this);\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToReader(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase> listener) {\n        if (!this.readerListener.compareAndSet(null, listener)) {\n            throw new java.lang.IllegalStateException(listener + \" is already registered as a record availability listener\");\n        }\n    }\n\n    @java.lang.Override\n    public void sendTaskEvent(org.apache.flink.runtime.event.task.TaskEvent event) throws java.io.IOException, java.lang.InterruptedException {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                inputChannel.sendTaskEvent(event);\n            }\n            if (numberOfUninitializedChannels > 0) {\n                pendingEvents.add(event);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToTaskEvent(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.event.task.TaskEvent> listener, java.lang.Class<? extends org.apache.flink.runtime.event.task.TaskEvent> eventType) {\n        taskEventHandler.subscribe(listener, eventType);\n    }\n\n    @java.lang.Override\n    public void setIterativeReader() {\n        isIterativeReader = true;\n    }\n\n    @java.lang.Override\n    public void startNextSuperstep() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Tried to start next superstep in a non-iterative reader.\");\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents == totalNumberOfInputChannels, \"Tried to start next superstep before reaching end of previous superstep.\");\n        currentNumEndOfSuperstepEvents = 0;\n    }\n\n    @java.lang.Override\n    public boolean hasReachedEndOfSuperstep() {\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    private boolean incrementEndOfSuperstepEventAndCheck() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Received end of superstep event in a non-iterative reader.\");\n        currentNumEndOfSuperstepEvents++;\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents <= totalNumberOfInputChannels, (\"Received too many (\" + currentNumEndOfSuperstepEvents) + \") end of superstep events.\");\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return java.lang.String.format(\"BufferReader %s [task: %s, current/total number of input channels: %d/%d]\", consumedResultId, getTaskNameWithSubtasks(), inputChannels.size(), totalNumberOfInputChannels);\n    }\n\n    public static org.apache.flink.runtime.io.network.api.reader.BufferReader create(org.apache.flink.runtime.execution.RuntimeEnvironment runtimeEnvironment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.deployment.PartitionConsumerDeploymentDescriptor desc) {\n        final org.apache.flink.runtime.jobgraph.IntermediateDataSetID resultId = desc.getResultId();\n        final int queueIndex = desc.getQueueIndex();\n        final org.apache.flink.runtime.deployment.PartitionInfo[] partitions = desc.getPartitions();\n        final int numberOfInputChannels = partitions.length;\n        final org.apache.flink.runtime.io.network.api.reader.BufferReader reader = new org.apache.flink.runtime.io.network.api.reader.BufferReader(runtimeEnvironment, networkEnvironment, resultId, numberOfInputChannels, queueIndex);\n        final org.apache.flink.runtime.io.network.partition.consumer.InputChannel[] inputChannels = new org.apache.flink.runtime.io.network.partition.consumer.InputChannel[numberOfInputChannels];\n        int channelIndex = 0;\n        for (org.apache.flink.runtime.deployment.PartitionInfo partition : partitions) {\n            final org.apache.flink.runtime.executiongraph.ExecutionAttemptID producerExecutionId = partition.getProducerExecutionId();\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partition.getPartitionId();\n            final org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation producerLocation = partition.getProducerLocation();\n            switch (producerLocation) {\n                case LOCAL :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n                case REMOTE :\n                    final org.apache.flink.runtime.io.network.RemoteAddress producerAddress = com.google.common.base.Preconditions.checkNotNull(partition.getProducerAddress(), \"Missing producer address for remote intermediate result partition.\");\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel(channelIndex, producerExecutionId, partitionId, reader, producerAddress);\n                    break;\n                case UNKNOWN :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n            }\n            reader.setInputChannel(partitionId, inputChannels[channelIndex]);\n            channelIndex++;\n        }\n        return reader;\n    }\n}",
            "dst_parent_type": "Class",
            "dst_type": "Method",
            "operator": "UPD",
            "src": "boolean hasInputChannelWithData() {\n    return !inputChannelsWithData.isEmpty();\n}",
            "src_parent": "public final class BufferReader implements org.apache.flink.runtime.io.network.api.reader.BufferReaderBase {\n    private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger(org.apache.flink.runtime.io.network.api.reader.BufferReader.class);\n\n    private final java.lang.Object requestLock = new java.lang.Object();\n\n    private final org.apache.flink.runtime.execution.RuntimeEnvironment environment;\n\n    private final org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment;\n\n    private final org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent> taskEventHandler = new org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private final org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId;\n\n    private final int totalNumberOfInputChannels;\n\n    private final int queueToRequest;\n\n    private final java.util.Map<org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID, org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannels;\n\n    private org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool;\n\n    private boolean isReleased;\n\n    private boolean isTaskEvent;\n\n    private final java.util.concurrent.BlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannelsWithData = new java.util.concurrent.LinkedBlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel>();\n\n    private final java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>> readerListener = new java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>>(null);\n\n    private boolean isIterativeReader;\n\n    private int currentNumEndOfSuperstepEvents;\n\n    private int channelIndexOfLastReadBuffer = -1;\n\n    private boolean hasRequestedPartitions = false;\n\n    public BufferReader(org.apache.flink.runtime.execution.RuntimeEnvironment environment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId, int numberOfInputChannels, int queueToRequest) {\n        this.consumedResultId = com.google.common.base.Preconditions.checkNotNull(consumedResultId);\n        this.environment = com.google.common.base.Preconditions.checkNotNull(environment);\n        this.networkEnvironment = networkEnvironment;\n        com.google.common.base.Preconditions.checkArgument(numberOfInputChannels >= 0);\n        this.totalNumberOfInputChannels = numberOfInputChannels;\n        com.google.common.base.Preconditions.checkArgument(queueToRequest >= 0);\n        this.queueToRequest = queueToRequest;\n        this.inputChannels = com.google.common.collect.Maps.newHashMapWithExpectedSize(numberOfInputChannels);\n    }\n\n    public void setBufferPool(org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool) {\n        com.google.common.base.Preconditions.checkArgument(bufferPool.getNumberOfRequiredMemorySegments() == totalNumberOfInputChannels, \"Buffer pool has not enough buffers for this reader.\");\n        com.google.common.base.Preconditions.checkState(this.bufferPool == null, \"Buffer pool has already been set for reader.\");\n        this.bufferPool = com.google.common.base.Preconditions.checkNotNull(bufferPool);\n    }\n\n    public org.apache.flink.runtime.jobgraph.IntermediateDataSetID getConsumedResultId() {\n        return consumedResultId;\n    }\n\n    public java.lang.String getTaskNameWithSubtasks() {\n        return environment.getTaskNameWithSubtasks();\n    }\n\n    public org.apache.flink.runtime.io.network.partition.IntermediateResultPartitionProvider getIntermediateResultPartitionProvider() {\n        return networkEnvironment.getPartitionManager();\n    }\n\n    public org.apache.flink.runtime.io.network.TaskEventDispatcher getTaskEventDispatcher() {\n        return networkEnvironment.getTaskEventDispatcher();\n    }\n\n    public org.apache.flink.runtime.io.network.ConnectionManager getConnectionManager() {\n        return networkEnvironment.getConnectionManager();\n    }\n\n    boolean hasInputChannelWithData() {\n        return !inputChannelsWithData.isEmpty();\n    }\n\n    public int getNumberOfInputChannels() {\n        return totalNumberOfInputChannels;\n    }\n\n    public org.apache.flink.runtime.io.network.buffer.BufferProvider getBufferProvider() {\n        return bufferPool;\n    }\n\n    public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        synchronized(requestLock) {\n            inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel));\n        }\n    }\n\n    public void updateInputChannel(org.apache.flink.runtime.deployment.PartitionInfo partitionInfo) throws java.io.IOException {\n        synchronized(requestLock) {\n            if (isReleased) {\n                return;\n            }\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel current = inputChannels.get(partitionId);\n            if (current.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class) {\n                org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n                org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n                if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n                    newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n                } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n                    newChannel = unknownChannel.toLocalInputChannel();\n                } else {\n                    throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n                }\n                inputChannels.put(partitionId, newChannel);\n                newChannel.requestIntermediateResultPartition(queueToRequest);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void requestPartitionsOnce() throws java.io.IOException {\n        if (!hasRequestedPartitions) {\n            if (totalNumberOfInputChannels != inputChannels.size()) {\n                throw new java.lang.IllegalStateException(\"Mismatch between number of total input channels and the currently number of set input channels.\");\n            }\n            synchronized(requestLock) {\n                for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                    inputChannel.requestIntermediateResultPartition(queueToRequest);\n                }\n            }\n            hasRequestedPartitions = true;\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBufferBlocking() throws java.io.IOException, java.lang.InterruptedException {\n        requestPartitionsOnce();\n        while (true) {\n            if (java.lang.Thread.interrupted()) {\n                throw new java.lang.InterruptedException();\n            }\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel currentChannel = null;\n            while (currentChannel == null) {\n                currentChannel = inputChannelsWithData.poll(2000, java.util.concurrent.TimeUnit.MILLISECONDS);\n            } \n            isTaskEvent = false;\n            final org.apache.flink.runtime.io.network.buffer.Buffer buffer = currentChannel.getNextBuffer();\n            if (buffer == null) {\n                throw new java.lang.IllegalStateException(\"Bug in reader logic: queried for a buffer although none was available.\");\n            }\n            if (buffer.isBuffer()) {\n                channelIndexOfLastReadBuffer = currentChannel.getChannelIndex();\n                return buffer;\n            } else {\n                try {\n                    final org.apache.flink.runtime.event.task.AbstractEvent event = org.apache.flink.runtime.io.network.api.serialization.EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n                    if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfPartitionEvent.class) {\n                        currentChannel.releaseAllResources();\n                        return null;\n                    } else if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfSuperstepEvent.class) {\n                        incrementEndOfSuperstepEventAndCheck();\n                        return null;\n                    } else if (event instanceof org.apache.flink.runtime.event.task.TaskEvent) {\n                        taskEventHandler.publish(((org.apache.flink.runtime.event.task.TaskEvent) (event)));\n                        isTaskEvent = true;\n                        return null;\n                    } else {\n                        throw new java.lang.IllegalStateException((((\"Received unexpected event \" + event) + \" from input channel \") + currentChannel) + \".\");\n                    }\n                } catch (java.lang.Throwable t) {\n                    throw new java.io.IOException(\"Error while reading event: \" + t.getMessage(), t);\n                } finally {\n                    buffer.recycle();\n                }\n            }\n        } \n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBuffer(org.apache.flink.runtime.io.network.buffer.Buffer exchangeBuffer) {\n        throw new java.lang.UnsupportedOperationException(\"Buffer exchange when reading data is not yet supported.\");\n    }\n\n    @java.lang.Override\n    public int getChannelIndexOfLastBuffer() {\n        return channelIndexOfLastReadBuffer;\n    }\n\n    @java.lang.Override\n    public boolean isTaskEvent() {\n        return isTaskEvent;\n    }\n\n    @java.lang.Override\n    public boolean isFinished() {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                if (!inputChannel.isReleased()) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n\n    public void releaseAllResources() throws java.io.IOException {\n        synchronized(requestLock) {\n            if (!isReleased) {\n                try {\n                    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                        try {\n                            inputChannel.releaseAllResources();\n                        } catch (java.io.IOException e) {\n                            org.apache.flink.runtime.io.network.api.reader.BufferReader.LOG.warn(\"Error during release of channel resources: \" + e.getMessage(), e);\n                        }\n                    }\n                    if (bufferPool != null) {\n                        bufferPool.destroy();\n                    }\n                } finally {\n                    isReleased = true;\n                }\n            }\n        }\n    }\n\n    public void onAvailableInputChannel(org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        inputChannelsWithData.add(inputChannel);\n        if (readerListener.get() != null) {\n            readerListener.get().onEvent(this);\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToReader(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase> listener) {\n        if (!this.readerListener.compareAndSet(null, listener)) {\n            throw new java.lang.IllegalStateException(listener + \" is already registered as a record availability listener\");\n        }\n    }\n\n    @java.lang.Override\n    public void sendTaskEvent(org.apache.flink.runtime.event.task.TaskEvent event) throws java.io.IOException, java.lang.InterruptedException {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                inputChannel.sendTaskEvent(event);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToTaskEvent(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.event.task.TaskEvent> listener, java.lang.Class<? extends org.apache.flink.runtime.event.task.TaskEvent> eventType) {\n        taskEventHandler.subscribe(listener, eventType);\n    }\n\n    @java.lang.Override\n    public void setIterativeReader() {\n        isIterativeReader = true;\n    }\n\n    @java.lang.Override\n    public void startNextSuperstep() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Tried to start next superstep in a non-iterative reader.\");\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents == totalNumberOfInputChannels, \"Tried to start next superstep before reaching end of previous superstep.\");\n        currentNumEndOfSuperstepEvents = 0;\n    }\n\n    @java.lang.Override\n    public boolean hasReachedEndOfSuperstep() {\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    private boolean incrementEndOfSuperstepEventAndCheck() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Received end of superstep event in a non-iterative reader.\");\n        currentNumEndOfSuperstepEvents++;\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents <= totalNumberOfInputChannels, (\"Received too many (\" + currentNumEndOfSuperstepEvents) + \") end of superstep events.\");\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return java.lang.String.format(\"BufferReader %s [task: %s, current/total number of input channels: %d/%d]\", consumedResultId, getTaskNameWithSubtasks(), inputChannels.size(), totalNumberOfInputChannels);\n    }\n\n    public static org.apache.flink.runtime.io.network.api.reader.BufferReader create(org.apache.flink.runtime.execution.RuntimeEnvironment runtimeEnvironment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.deployment.PartitionConsumerDeploymentDescriptor desc) {\n        final org.apache.flink.runtime.jobgraph.IntermediateDataSetID resultId = desc.getResultId();\n        final int queueIndex = desc.getQueueIndex();\n        final org.apache.flink.runtime.deployment.PartitionInfo[] partitions = desc.getPartitions();\n        final int numberOfInputChannels = partitions.length;\n        final org.apache.flink.runtime.io.network.api.reader.BufferReader reader = new org.apache.flink.runtime.io.network.api.reader.BufferReader(runtimeEnvironment, networkEnvironment, resultId, numberOfInputChannels, queueIndex);\n        final org.apache.flink.runtime.io.network.partition.consumer.InputChannel[] inputChannels = new org.apache.flink.runtime.io.network.partition.consumer.InputChannel[numberOfInputChannels];\n        int channelIndex = 0;\n        for (org.apache.flink.runtime.deployment.PartitionInfo partition : partitions) {\n            final org.apache.flink.runtime.executiongraph.ExecutionAttemptID producerExecutionId = partition.getProducerExecutionId();\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partition.getPartitionId();\n            final org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation producerLocation = partition.getProducerLocation();\n            switch (producerLocation) {\n                case LOCAL :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n                case REMOTE :\n                    final org.apache.flink.runtime.io.network.RemoteAddress producerAddress = com.google.common.base.Preconditions.checkNotNull(partition.getProducerAddress(), \"Missing producer address for remote intermediate result partition.\");\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel(channelIndex, producerExecutionId, partitionId, reader, producerAddress);\n                    break;\n                case UNKNOWN :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n            }\n            reader.setInputChannel(partitionId, inputChannels[channelIndex]);\n            channelIndex++;\n        }\n        return reader;\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Method"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "TypeReference",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "void",
            "dst_parent": "public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n    synchronized(requestLock) {\n        if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n            numberOfUninitializedChannels++;\n        }\n    }\n}",
            "dst_parent_type": "Method",
            "dst_type": "TypeReference",
            "operator": "UPD",
            "src": "boolean",
            "src_parent": "boolean hasInputChannelWithData() {\n    return !inputChannelsWithData.isEmpty();\n}",
            "src_parent_type": "Method",
            "src_type": "TypeReference"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Method",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n    synchronized(requestLock) {\n        inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel));\n    }\n}",
            "src_parent": "public final class BufferReader implements org.apache.flink.runtime.io.network.api.reader.BufferReaderBase {\n    private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger(org.apache.flink.runtime.io.network.api.reader.BufferReader.class);\n\n    private final java.lang.Object requestLock = new java.lang.Object();\n\n    private final org.apache.flink.runtime.execution.RuntimeEnvironment environment;\n\n    private final org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment;\n\n    private final org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent> taskEventHandler = new org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private final org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId;\n\n    private final int totalNumberOfInputChannels;\n\n    private final int queueToRequest;\n\n    private final java.util.Map<org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID, org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannels;\n\n    private org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool;\n\n    private boolean isReleased;\n\n    private boolean isTaskEvent;\n\n    private final java.util.concurrent.BlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannelsWithData = new java.util.concurrent.LinkedBlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel>();\n\n    private final java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>> readerListener = new java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>>(null);\n\n    private boolean isIterativeReader;\n\n    private int currentNumEndOfSuperstepEvents;\n\n    private int channelIndexOfLastReadBuffer = -1;\n\n    private boolean hasRequestedPartitions = false;\n\n    public BufferReader(org.apache.flink.runtime.execution.RuntimeEnvironment environment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId, int numberOfInputChannels, int queueToRequest) {\n        this.consumedResultId = com.google.common.base.Preconditions.checkNotNull(consumedResultId);\n        this.environment = com.google.common.base.Preconditions.checkNotNull(environment);\n        this.networkEnvironment = networkEnvironment;\n        com.google.common.base.Preconditions.checkArgument(numberOfInputChannels >= 0);\n        this.totalNumberOfInputChannels = numberOfInputChannels;\n        com.google.common.base.Preconditions.checkArgument(queueToRequest >= 0);\n        this.queueToRequest = queueToRequest;\n        this.inputChannels = com.google.common.collect.Maps.newHashMapWithExpectedSize(numberOfInputChannels);\n    }\n\n    public void setBufferPool(org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool) {\n        com.google.common.base.Preconditions.checkArgument(bufferPool.getNumberOfRequiredMemorySegments() == totalNumberOfInputChannels, \"Buffer pool has not enough buffers for this reader.\");\n        com.google.common.base.Preconditions.checkState(this.bufferPool == null, \"Buffer pool has already been set for reader.\");\n        this.bufferPool = com.google.common.base.Preconditions.checkNotNull(bufferPool);\n    }\n\n    public org.apache.flink.runtime.jobgraph.IntermediateDataSetID getConsumedResultId() {\n        return consumedResultId;\n    }\n\n    public java.lang.String getTaskNameWithSubtasks() {\n        return environment.getTaskNameWithSubtasks();\n    }\n\n    public org.apache.flink.runtime.io.network.partition.IntermediateResultPartitionProvider getIntermediateResultPartitionProvider() {\n        return networkEnvironment.getPartitionManager();\n    }\n\n    public org.apache.flink.runtime.io.network.TaskEventDispatcher getTaskEventDispatcher() {\n        return networkEnvironment.getTaskEventDispatcher();\n    }\n\n    public org.apache.flink.runtime.io.network.ConnectionManager getConnectionManager() {\n        return networkEnvironment.getConnectionManager();\n    }\n\n    boolean hasInputChannelWithData() {\n        return !inputChannelsWithData.isEmpty();\n    }\n\n    public int getNumberOfInputChannels() {\n        return totalNumberOfInputChannels;\n    }\n\n    public org.apache.flink.runtime.io.network.buffer.BufferProvider getBufferProvider() {\n        return bufferPool;\n    }\n\n    public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        synchronized(requestLock) {\n            inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel));\n        }\n    }\n\n    public void updateInputChannel(org.apache.flink.runtime.deployment.PartitionInfo partitionInfo) throws java.io.IOException {\n        synchronized(requestLock) {\n            if (isReleased) {\n                return;\n            }\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel current = inputChannels.get(partitionId);\n            if (current.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class) {\n                org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n                org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n                if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n                    newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n                } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n                    newChannel = unknownChannel.toLocalInputChannel();\n                } else {\n                    throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n                }\n                inputChannels.put(partitionId, newChannel);\n                newChannel.requestIntermediateResultPartition(queueToRequest);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void requestPartitionsOnce() throws java.io.IOException {\n        if (!hasRequestedPartitions) {\n            if (totalNumberOfInputChannels != inputChannels.size()) {\n                throw new java.lang.IllegalStateException(\"Mismatch between number of total input channels and the currently number of set input channels.\");\n            }\n            synchronized(requestLock) {\n                for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                    inputChannel.requestIntermediateResultPartition(queueToRequest);\n                }\n            }\n            hasRequestedPartitions = true;\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBufferBlocking() throws java.io.IOException, java.lang.InterruptedException {\n        requestPartitionsOnce();\n        while (true) {\n            if (java.lang.Thread.interrupted()) {\n                throw new java.lang.InterruptedException();\n            }\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel currentChannel = null;\n            while (currentChannel == null) {\n                currentChannel = inputChannelsWithData.poll(2000, java.util.concurrent.TimeUnit.MILLISECONDS);\n            } \n            isTaskEvent = false;\n            final org.apache.flink.runtime.io.network.buffer.Buffer buffer = currentChannel.getNextBuffer();\n            if (buffer == null) {\n                throw new java.lang.IllegalStateException(\"Bug in reader logic: queried for a buffer although none was available.\");\n            }\n            if (buffer.isBuffer()) {\n                channelIndexOfLastReadBuffer = currentChannel.getChannelIndex();\n                return buffer;\n            } else {\n                try {\n                    final org.apache.flink.runtime.event.task.AbstractEvent event = org.apache.flink.runtime.io.network.api.serialization.EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n                    if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfPartitionEvent.class) {\n                        currentChannel.releaseAllResources();\n                        return null;\n                    } else if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfSuperstepEvent.class) {\n                        incrementEndOfSuperstepEventAndCheck();\n                        return null;\n                    } else if (event instanceof org.apache.flink.runtime.event.task.TaskEvent) {\n                        taskEventHandler.publish(((org.apache.flink.runtime.event.task.TaskEvent) (event)));\n                        isTaskEvent = true;\n                        return null;\n                    } else {\n                        throw new java.lang.IllegalStateException((((\"Received unexpected event \" + event) + \" from input channel \") + currentChannel) + \".\");\n                    }\n                } catch (java.lang.Throwable t) {\n                    throw new java.io.IOException(\"Error while reading event: \" + t.getMessage(), t);\n                } finally {\n                    buffer.recycle();\n                }\n            }\n        } \n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBuffer(org.apache.flink.runtime.io.network.buffer.Buffer exchangeBuffer) {\n        throw new java.lang.UnsupportedOperationException(\"Buffer exchange when reading data is not yet supported.\");\n    }\n\n    @java.lang.Override\n    public int getChannelIndexOfLastBuffer() {\n        return channelIndexOfLastReadBuffer;\n    }\n\n    @java.lang.Override\n    public boolean isTaskEvent() {\n        return isTaskEvent;\n    }\n\n    @java.lang.Override\n    public boolean isFinished() {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                if (!inputChannel.isReleased()) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n\n    public void releaseAllResources() throws java.io.IOException {\n        synchronized(requestLock) {\n            if (!isReleased) {\n                try {\n                    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                        try {\n                            inputChannel.releaseAllResources();\n                        } catch (java.io.IOException e) {\n                            org.apache.flink.runtime.io.network.api.reader.BufferReader.LOG.warn(\"Error during release of channel resources: \" + e.getMessage(), e);\n                        }\n                    }\n                    if (bufferPool != null) {\n                        bufferPool.destroy();\n                    }\n                } finally {\n                    isReleased = true;\n                }\n            }\n        }\n    }\n\n    public void onAvailableInputChannel(org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        inputChannelsWithData.add(inputChannel);\n        if (readerListener.get() != null) {\n            readerListener.get().onEvent(this);\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToReader(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase> listener) {\n        if (!this.readerListener.compareAndSet(null, listener)) {\n            throw new java.lang.IllegalStateException(listener + \" is already registered as a record availability listener\");\n        }\n    }\n\n    @java.lang.Override\n    public void sendTaskEvent(org.apache.flink.runtime.event.task.TaskEvent event) throws java.io.IOException, java.lang.InterruptedException {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                inputChannel.sendTaskEvent(event);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToTaskEvent(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.event.task.TaskEvent> listener, java.lang.Class<? extends org.apache.flink.runtime.event.task.TaskEvent> eventType) {\n        taskEventHandler.subscribe(listener, eventType);\n    }\n\n    @java.lang.Override\n    public void setIterativeReader() {\n        isIterativeReader = true;\n    }\n\n    @java.lang.Override\n    public void startNextSuperstep() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Tried to start next superstep in a non-iterative reader.\");\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents == totalNumberOfInputChannels, \"Tried to start next superstep before reaching end of previous superstep.\");\n        currentNumEndOfSuperstepEvents = 0;\n    }\n\n    @java.lang.Override\n    public boolean hasReachedEndOfSuperstep() {\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    private boolean incrementEndOfSuperstepEventAndCheck() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Received end of superstep event in a non-iterative reader.\");\n        currentNumEndOfSuperstepEvents++;\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents <= totalNumberOfInputChannels, (\"Received too many (\" + currentNumEndOfSuperstepEvents) + \") end of superstep events.\");\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return java.lang.String.format(\"BufferReader %s [task: %s, current/total number of input channels: %d/%d]\", consumedResultId, getTaskNameWithSubtasks(), inputChannels.size(), totalNumberOfInputChannels);\n    }\n\n    public static org.apache.flink.runtime.io.network.api.reader.BufferReader create(org.apache.flink.runtime.execution.RuntimeEnvironment runtimeEnvironment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.deployment.PartitionConsumerDeploymentDescriptor desc) {\n        final org.apache.flink.runtime.jobgraph.IntermediateDataSetID resultId = desc.getResultId();\n        final int queueIndex = desc.getQueueIndex();\n        final org.apache.flink.runtime.deployment.PartitionInfo[] partitions = desc.getPartitions();\n        final int numberOfInputChannels = partitions.length;\n        final org.apache.flink.runtime.io.network.api.reader.BufferReader reader = new org.apache.flink.runtime.io.network.api.reader.BufferReader(runtimeEnvironment, networkEnvironment, resultId, numberOfInputChannels, queueIndex);\n        final org.apache.flink.runtime.io.network.partition.consumer.InputChannel[] inputChannels = new org.apache.flink.runtime.io.network.partition.consumer.InputChannel[numberOfInputChannels];\n        int channelIndex = 0;\n        for (org.apache.flink.runtime.deployment.PartitionInfo partition : partitions) {\n            final org.apache.flink.runtime.executiongraph.ExecutionAttemptID producerExecutionId = partition.getProducerExecutionId();\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partition.getPartitionId();\n            final org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation producerLocation = partition.getProducerLocation();\n            switch (producerLocation) {\n                case LOCAL :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n                case REMOTE :\n                    final org.apache.flink.runtime.io.network.RemoteAddress producerAddress = com.google.common.base.Preconditions.checkNotNull(partition.getProducerAddress(), \"Missing producer address for remote intermediate result partition.\");\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel(channelIndex, producerExecutionId, partitionId, reader, producerAddress);\n                    break;\n                case UNKNOWN :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n            }\n            reader.setInputChannel(partitionId, inputChannels[channelIndex]);\n            channelIndex++;\n        }\n        return reader;\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Method"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Package",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "true",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Class",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "private final java.util.List<org.apache.flink.runtime.event.task.TaskEvent> pendingEvents = new java.util.ArrayList<org.apache.flink.runtime.event.task.TaskEvent>();",
            "src_parent": "public final class BufferReader implements org.apache.flink.runtime.io.network.api.reader.BufferReaderBase {\n    private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger(org.apache.flink.runtime.io.network.api.reader.BufferReader.class);\n\n    private final java.lang.Object requestLock = new java.lang.Object();\n\n    private final org.apache.flink.runtime.execution.RuntimeEnvironment environment;\n\n    private final org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment;\n\n    private final org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent> taskEventHandler = new org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private final org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId;\n\n    private final int totalNumberOfInputChannels;\n\n    private final int queueToRequest;\n\n    private final java.util.Map<org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID, org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannels;\n\n    private org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool;\n\n    private boolean isReleased;\n\n    private boolean isTaskEvent;\n\n    private final java.util.concurrent.BlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannelsWithData = new java.util.concurrent.LinkedBlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel>();\n\n    private final java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>> readerListener = new java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>>(null);\n\n    private final java.util.List<org.apache.flink.runtime.event.task.TaskEvent> pendingEvents = new java.util.ArrayList<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private int numberOfUninitializedChannels;\n\n    private boolean isIterativeReader;\n\n    private int currentNumEndOfSuperstepEvents;\n\n    private int channelIndexOfLastReadBuffer = -1;\n\n    private boolean hasRequestedPartitions = false;\n\n    public BufferReader(org.apache.flink.runtime.execution.RuntimeEnvironment environment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId, int numberOfInputChannels, int queueToRequest) {\n        this.consumedResultId = com.google.common.base.Preconditions.checkNotNull(consumedResultId);\n        this.environment = com.google.common.base.Preconditions.checkNotNull(environment);\n        this.networkEnvironment = networkEnvironment;\n        com.google.common.base.Preconditions.checkArgument(numberOfInputChannels >= 0);\n        this.totalNumberOfInputChannels = numberOfInputChannels;\n        com.google.common.base.Preconditions.checkArgument(queueToRequest >= 0);\n        this.queueToRequest = queueToRequest;\n        this.inputChannels = com.google.common.collect.Maps.newHashMapWithExpectedSize(numberOfInputChannels);\n    }\n\n    public void setBufferPool(org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool) {\n        com.google.common.base.Preconditions.checkArgument(bufferPool.getNumberOfRequiredMemorySegments() == totalNumberOfInputChannels, \"Buffer pool has not enough buffers for this reader.\");\n        com.google.common.base.Preconditions.checkState(this.bufferPool == null, \"Buffer pool has already been set for reader.\");\n        this.bufferPool = com.google.common.base.Preconditions.checkNotNull(bufferPool);\n    }\n\n    public org.apache.flink.runtime.jobgraph.IntermediateDataSetID getConsumedResultId() {\n        return consumedResultId;\n    }\n\n    public java.lang.String getTaskNameWithSubtasks() {\n        return environment.getTaskNameWithSubtasks();\n    }\n\n    public org.apache.flink.runtime.io.network.partition.IntermediateResultPartitionProvider getIntermediateResultPartitionProvider() {\n        return networkEnvironment.getPartitionManager();\n    }\n\n    public org.apache.flink.runtime.io.network.TaskEventDispatcher getTaskEventDispatcher() {\n        return networkEnvironment.getTaskEventDispatcher();\n    }\n\n    public org.apache.flink.runtime.io.network.ConnectionManager getConnectionManager() {\n        return networkEnvironment.getConnectionManager();\n    }\n\n    @java.lang.Override\n    public int getNumberOfInputChannels() {\n        return totalNumberOfInputChannels;\n    }\n\n    public org.apache.flink.runtime.io.network.buffer.BufferProvider getBufferProvider() {\n        return bufferPool;\n    }\n\n    public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        synchronized(requestLock) {\n            if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n                numberOfUninitializedChannels++;\n            }\n        }\n    }\n\n    public void updateInputChannel(org.apache.flink.runtime.deployment.PartitionInfo partitionInfo) throws java.io.IOException {\n        synchronized(requestLock) {\n            if (isReleased) {\n                return;\n            }\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel current = inputChannels.get(partitionId);\n            if (current.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class) {\n                org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n                org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n                if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n                    newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n                } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n                    newChannel = unknownChannel.toLocalInputChannel();\n                } else {\n                    throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n                }\n                inputChannels.put(partitionId, newChannel);\n                newChannel.requestIntermediateResultPartition(queueToRequest);\n                for (org.apache.flink.runtime.event.task.TaskEvent event : pendingEvents) {\n                    newChannel.sendTaskEvent(event);\n                }\n                if ((--numberOfUninitializedChannels) == 0) {\n                    pendingEvents.clear();\n                }\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void requestPartitionsOnce() throws java.io.IOException {\n        if (!hasRequestedPartitions) {\n            if (totalNumberOfInputChannels != inputChannels.size()) {\n                throw new java.lang.IllegalStateException(\"Mismatch between number of total input channels and the currently number of set input channels.\");\n            }\n            synchronized(requestLock) {\n                for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                    inputChannel.requestIntermediateResultPartition(queueToRequest);\n                }\n            }\n            hasRequestedPartitions = true;\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBufferBlocking() throws java.io.IOException, java.lang.InterruptedException {\n        requestPartitionsOnce();\n        while (true) {\n            if (java.lang.Thread.interrupted()) {\n                throw new java.lang.InterruptedException();\n            }\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel currentChannel = null;\n            while (currentChannel == null) {\n                currentChannel = inputChannelsWithData.poll(2000, java.util.concurrent.TimeUnit.MILLISECONDS);\n            } \n            isTaskEvent = false;\n            final org.apache.flink.runtime.io.network.buffer.Buffer buffer = currentChannel.getNextBuffer();\n            if (buffer == null) {\n                throw new java.lang.IllegalStateException(\"Bug in reader logic: queried for a buffer although none was available.\");\n            }\n            if (buffer.isBuffer()) {\n                channelIndexOfLastReadBuffer = currentChannel.getChannelIndex();\n                return buffer;\n            } else {\n                try {\n                    final org.apache.flink.runtime.event.task.AbstractEvent event = org.apache.flink.runtime.io.network.api.serialization.EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n                    if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfPartitionEvent.class) {\n                        currentChannel.releaseAllResources();\n                        return null;\n                    } else if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfSuperstepEvent.class) {\n                        incrementEndOfSuperstepEventAndCheck();\n                        return null;\n                    } else if (event instanceof org.apache.flink.runtime.event.task.TaskEvent) {\n                        taskEventHandler.publish(((org.apache.flink.runtime.event.task.TaskEvent) (event)));\n                        isTaskEvent = true;\n                        return null;\n                    } else {\n                        throw new java.lang.IllegalStateException((((\"Received unexpected event \" + event) + \" from input channel \") + currentChannel) + \".\");\n                    }\n                } catch (java.lang.Throwable t) {\n                    throw new java.io.IOException(\"Error while reading event: \" + t.getMessage(), t);\n                } finally {\n                    buffer.recycle();\n                }\n            }\n        } \n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBuffer(org.apache.flink.runtime.io.network.buffer.Buffer exchangeBuffer) {\n        throw new java.lang.UnsupportedOperationException(\"Buffer exchange when reading data is not yet supported.\");\n    }\n\n    @java.lang.Override\n    public int getChannelIndexOfLastBuffer() {\n        return channelIndexOfLastReadBuffer;\n    }\n\n    @java.lang.Override\n    public boolean isTaskEvent() {\n        return isTaskEvent;\n    }\n\n    @java.lang.Override\n    public boolean isFinished() {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                if (!inputChannel.isReleased()) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n\n    public void releaseAllResources() throws java.io.IOException {\n        synchronized(requestLock) {\n            if (!isReleased) {\n                try {\n                    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                        try {\n                            inputChannel.releaseAllResources();\n                        } catch (java.io.IOException e) {\n                            org.apache.flink.runtime.io.network.api.reader.BufferReader.LOG.warn(\"Error during release of channel resources: \" + e.getMessage(), e);\n                        }\n                    }\n                    if (bufferPool != null) {\n                        bufferPool.destroy();\n                    }\n                } finally {\n                    isReleased = true;\n                }\n            }\n        }\n    }\n\n    public void onAvailableInputChannel(org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        inputChannelsWithData.add(inputChannel);\n        if (readerListener.get() != null) {\n            readerListener.get().onEvent(this);\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToReader(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase> listener) {\n        if (!this.readerListener.compareAndSet(null, listener)) {\n            throw new java.lang.IllegalStateException(listener + \" is already registered as a record availability listener\");\n        }\n    }\n\n    @java.lang.Override\n    public void sendTaskEvent(org.apache.flink.runtime.event.task.TaskEvent event) throws java.io.IOException, java.lang.InterruptedException {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                inputChannel.sendTaskEvent(event);\n            }\n            if (numberOfUninitializedChannels > 0) {\n                pendingEvents.add(event);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToTaskEvent(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.event.task.TaskEvent> listener, java.lang.Class<? extends org.apache.flink.runtime.event.task.TaskEvent> eventType) {\n        taskEventHandler.subscribe(listener, eventType);\n    }\n\n    @java.lang.Override\n    public void setIterativeReader() {\n        isIterativeReader = true;\n    }\n\n    @java.lang.Override\n    public void startNextSuperstep() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Tried to start next superstep in a non-iterative reader.\");\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents == totalNumberOfInputChannels, \"Tried to start next superstep before reaching end of previous superstep.\");\n        currentNumEndOfSuperstepEvents = 0;\n    }\n\n    @java.lang.Override\n    public boolean hasReachedEndOfSuperstep() {\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    private boolean incrementEndOfSuperstepEventAndCheck() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Received end of superstep event in a non-iterative reader.\");\n        currentNumEndOfSuperstepEvents++;\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents <= totalNumberOfInputChannels, (\"Received too many (\" + currentNumEndOfSuperstepEvents) + \") end of superstep events.\");\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return java.lang.String.format(\"BufferReader %s [task: %s, current/total number of input channels: %d/%d]\", consumedResultId, getTaskNameWithSubtasks(), inputChannels.size(), totalNumberOfInputChannels);\n    }\n\n    public static org.apache.flink.runtime.io.network.api.reader.BufferReader create(org.apache.flink.runtime.execution.RuntimeEnvironment runtimeEnvironment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.deployment.PartitionConsumerDeploymentDescriptor desc) {\n        final org.apache.flink.runtime.jobgraph.IntermediateDataSetID resultId = desc.getResultId();\n        final int queueIndex = desc.getQueueIndex();\n        final org.apache.flink.runtime.deployment.PartitionInfo[] partitions = desc.getPartitions();\n        final int numberOfInputChannels = partitions.length;\n        final org.apache.flink.runtime.io.network.api.reader.BufferReader reader = new org.apache.flink.runtime.io.network.api.reader.BufferReader(runtimeEnvironment, networkEnvironment, resultId, numberOfInputChannels, queueIndex);\n        final org.apache.flink.runtime.io.network.partition.consumer.InputChannel[] inputChannels = new org.apache.flink.runtime.io.network.partition.consumer.InputChannel[numberOfInputChannels];\n        int channelIndex = 0;\n        for (org.apache.flink.runtime.deployment.PartitionInfo partition : partitions) {\n            final org.apache.flink.runtime.executiongraph.ExecutionAttemptID producerExecutionId = partition.getProducerExecutionId();\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partition.getPartitionId();\n            final org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation producerLocation = partition.getProducerLocation();\n            switch (producerLocation) {\n                case LOCAL :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n                case REMOTE :\n                    final org.apache.flink.runtime.io.network.RemoteAddress producerAddress = com.google.common.base.Preconditions.checkNotNull(partition.getProducerAddress(), \"Missing producer address for remote intermediate result partition.\");\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel(channelIndex, producerExecutionId, partitionId, reader, producerAddress);\n                    break;\n                case UNKNOWN :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n            }\n            reader.setInputChannel(partitionId, inputChannels[channelIndex]);\n            channelIndex++;\n        }\n        return reader;\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Package",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "true",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Class",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "private int numberOfUninitializedChannels;",
            "src_parent": "public final class BufferReader implements org.apache.flink.runtime.io.network.api.reader.BufferReaderBase {\n    private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger(org.apache.flink.runtime.io.network.api.reader.BufferReader.class);\n\n    private final java.lang.Object requestLock = new java.lang.Object();\n\n    private final org.apache.flink.runtime.execution.RuntimeEnvironment environment;\n\n    private final org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment;\n\n    private final org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent> taskEventHandler = new org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private final org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId;\n\n    private final int totalNumberOfInputChannels;\n\n    private final int queueToRequest;\n\n    private final java.util.Map<org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID, org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannels;\n\n    private org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool;\n\n    private boolean isReleased;\n\n    private boolean isTaskEvent;\n\n    private final java.util.concurrent.BlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannelsWithData = new java.util.concurrent.LinkedBlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel>();\n\n    private final java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>> readerListener = new java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>>(null);\n\n    private final java.util.List<org.apache.flink.runtime.event.task.TaskEvent> pendingEvents = new java.util.ArrayList<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private int numberOfUninitializedChannels;\n\n    private boolean isIterativeReader;\n\n    private int currentNumEndOfSuperstepEvents;\n\n    private int channelIndexOfLastReadBuffer = -1;\n\n    private boolean hasRequestedPartitions = false;\n\n    public BufferReader(org.apache.flink.runtime.execution.RuntimeEnvironment environment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId, int numberOfInputChannels, int queueToRequest) {\n        this.consumedResultId = com.google.common.base.Preconditions.checkNotNull(consumedResultId);\n        this.environment = com.google.common.base.Preconditions.checkNotNull(environment);\n        this.networkEnvironment = networkEnvironment;\n        com.google.common.base.Preconditions.checkArgument(numberOfInputChannels >= 0);\n        this.totalNumberOfInputChannels = numberOfInputChannels;\n        com.google.common.base.Preconditions.checkArgument(queueToRequest >= 0);\n        this.queueToRequest = queueToRequest;\n        this.inputChannels = com.google.common.collect.Maps.newHashMapWithExpectedSize(numberOfInputChannels);\n    }\n\n    public void setBufferPool(org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool) {\n        com.google.common.base.Preconditions.checkArgument(bufferPool.getNumberOfRequiredMemorySegments() == totalNumberOfInputChannels, \"Buffer pool has not enough buffers for this reader.\");\n        com.google.common.base.Preconditions.checkState(this.bufferPool == null, \"Buffer pool has already been set for reader.\");\n        this.bufferPool = com.google.common.base.Preconditions.checkNotNull(bufferPool);\n    }\n\n    public org.apache.flink.runtime.jobgraph.IntermediateDataSetID getConsumedResultId() {\n        return consumedResultId;\n    }\n\n    public java.lang.String getTaskNameWithSubtasks() {\n        return environment.getTaskNameWithSubtasks();\n    }\n\n    public org.apache.flink.runtime.io.network.partition.IntermediateResultPartitionProvider getIntermediateResultPartitionProvider() {\n        return networkEnvironment.getPartitionManager();\n    }\n\n    public org.apache.flink.runtime.io.network.TaskEventDispatcher getTaskEventDispatcher() {\n        return networkEnvironment.getTaskEventDispatcher();\n    }\n\n    public org.apache.flink.runtime.io.network.ConnectionManager getConnectionManager() {\n        return networkEnvironment.getConnectionManager();\n    }\n\n    @java.lang.Override\n    public int getNumberOfInputChannels() {\n        return totalNumberOfInputChannels;\n    }\n\n    public org.apache.flink.runtime.io.network.buffer.BufferProvider getBufferProvider() {\n        return bufferPool;\n    }\n\n    public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        synchronized(requestLock) {\n            if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n                numberOfUninitializedChannels++;\n            }\n        }\n    }\n\n    public void updateInputChannel(org.apache.flink.runtime.deployment.PartitionInfo partitionInfo) throws java.io.IOException {\n        synchronized(requestLock) {\n            if (isReleased) {\n                return;\n            }\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel current = inputChannels.get(partitionId);\n            if (current.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class) {\n                org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n                org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n                if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n                    newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n                } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n                    newChannel = unknownChannel.toLocalInputChannel();\n                } else {\n                    throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n                }\n                inputChannels.put(partitionId, newChannel);\n                newChannel.requestIntermediateResultPartition(queueToRequest);\n                for (org.apache.flink.runtime.event.task.TaskEvent event : pendingEvents) {\n                    newChannel.sendTaskEvent(event);\n                }\n                if ((--numberOfUninitializedChannels) == 0) {\n                    pendingEvents.clear();\n                }\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void requestPartitionsOnce() throws java.io.IOException {\n        if (!hasRequestedPartitions) {\n            if (totalNumberOfInputChannels != inputChannels.size()) {\n                throw new java.lang.IllegalStateException(\"Mismatch between number of total input channels and the currently number of set input channels.\");\n            }\n            synchronized(requestLock) {\n                for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                    inputChannel.requestIntermediateResultPartition(queueToRequest);\n                }\n            }\n            hasRequestedPartitions = true;\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBufferBlocking() throws java.io.IOException, java.lang.InterruptedException {\n        requestPartitionsOnce();\n        while (true) {\n            if (java.lang.Thread.interrupted()) {\n                throw new java.lang.InterruptedException();\n            }\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel currentChannel = null;\n            while (currentChannel == null) {\n                currentChannel = inputChannelsWithData.poll(2000, java.util.concurrent.TimeUnit.MILLISECONDS);\n            } \n            isTaskEvent = false;\n            final org.apache.flink.runtime.io.network.buffer.Buffer buffer = currentChannel.getNextBuffer();\n            if (buffer == null) {\n                throw new java.lang.IllegalStateException(\"Bug in reader logic: queried for a buffer although none was available.\");\n            }\n            if (buffer.isBuffer()) {\n                channelIndexOfLastReadBuffer = currentChannel.getChannelIndex();\n                return buffer;\n            } else {\n                try {\n                    final org.apache.flink.runtime.event.task.AbstractEvent event = org.apache.flink.runtime.io.network.api.serialization.EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n                    if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfPartitionEvent.class) {\n                        currentChannel.releaseAllResources();\n                        return null;\n                    } else if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfSuperstepEvent.class) {\n                        incrementEndOfSuperstepEventAndCheck();\n                        return null;\n                    } else if (event instanceof org.apache.flink.runtime.event.task.TaskEvent) {\n                        taskEventHandler.publish(((org.apache.flink.runtime.event.task.TaskEvent) (event)));\n                        isTaskEvent = true;\n                        return null;\n                    } else {\n                        throw new java.lang.IllegalStateException((((\"Received unexpected event \" + event) + \" from input channel \") + currentChannel) + \".\");\n                    }\n                } catch (java.lang.Throwable t) {\n                    throw new java.io.IOException(\"Error while reading event: \" + t.getMessage(), t);\n                } finally {\n                    buffer.recycle();\n                }\n            }\n        } \n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBuffer(org.apache.flink.runtime.io.network.buffer.Buffer exchangeBuffer) {\n        throw new java.lang.UnsupportedOperationException(\"Buffer exchange when reading data is not yet supported.\");\n    }\n\n    @java.lang.Override\n    public int getChannelIndexOfLastBuffer() {\n        return channelIndexOfLastReadBuffer;\n    }\n\n    @java.lang.Override\n    public boolean isTaskEvent() {\n        return isTaskEvent;\n    }\n\n    @java.lang.Override\n    public boolean isFinished() {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                if (!inputChannel.isReleased()) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n\n    public void releaseAllResources() throws java.io.IOException {\n        synchronized(requestLock) {\n            if (!isReleased) {\n                try {\n                    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                        try {\n                            inputChannel.releaseAllResources();\n                        } catch (java.io.IOException e) {\n                            org.apache.flink.runtime.io.network.api.reader.BufferReader.LOG.warn(\"Error during release of channel resources: \" + e.getMessage(), e);\n                        }\n                    }\n                    if (bufferPool != null) {\n                        bufferPool.destroy();\n                    }\n                } finally {\n                    isReleased = true;\n                }\n            }\n        }\n    }\n\n    public void onAvailableInputChannel(org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        inputChannelsWithData.add(inputChannel);\n        if (readerListener.get() != null) {\n            readerListener.get().onEvent(this);\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToReader(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase> listener) {\n        if (!this.readerListener.compareAndSet(null, listener)) {\n            throw new java.lang.IllegalStateException(listener + \" is already registered as a record availability listener\");\n        }\n    }\n\n    @java.lang.Override\n    public void sendTaskEvent(org.apache.flink.runtime.event.task.TaskEvent event) throws java.io.IOException, java.lang.InterruptedException {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                inputChannel.sendTaskEvent(event);\n            }\n            if (numberOfUninitializedChannels > 0) {\n                pendingEvents.add(event);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToTaskEvent(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.event.task.TaskEvent> listener, java.lang.Class<? extends org.apache.flink.runtime.event.task.TaskEvent> eventType) {\n        taskEventHandler.subscribe(listener, eventType);\n    }\n\n    @java.lang.Override\n    public void setIterativeReader() {\n        isIterativeReader = true;\n    }\n\n    @java.lang.Override\n    public void startNextSuperstep() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Tried to start next superstep in a non-iterative reader.\");\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents == totalNumberOfInputChannels, \"Tried to start next superstep before reaching end of previous superstep.\");\n        currentNumEndOfSuperstepEvents = 0;\n    }\n\n    @java.lang.Override\n    public boolean hasReachedEndOfSuperstep() {\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    private boolean incrementEndOfSuperstepEventAndCheck() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Received end of superstep event in a non-iterative reader.\");\n        currentNumEndOfSuperstepEvents++;\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents <= totalNumberOfInputChannels, (\"Received too many (\" + currentNumEndOfSuperstepEvents) + \") end of superstep events.\");\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return java.lang.String.format(\"BufferReader %s [task: %s, current/total number of input channels: %d/%d]\", consumedResultId, getTaskNameWithSubtasks(), inputChannels.size(), totalNumberOfInputChannels);\n    }\n\n    public static org.apache.flink.runtime.io.network.api.reader.BufferReader create(org.apache.flink.runtime.execution.RuntimeEnvironment runtimeEnvironment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.deployment.PartitionConsumerDeploymentDescriptor desc) {\n        final org.apache.flink.runtime.jobgraph.IntermediateDataSetID resultId = desc.getResultId();\n        final int queueIndex = desc.getQueueIndex();\n        final org.apache.flink.runtime.deployment.PartitionInfo[] partitions = desc.getPartitions();\n        final int numberOfInputChannels = partitions.length;\n        final org.apache.flink.runtime.io.network.api.reader.BufferReader reader = new org.apache.flink.runtime.io.network.api.reader.BufferReader(runtimeEnvironment, networkEnvironment, resultId, numberOfInputChannels, queueIndex);\n        final org.apache.flink.runtime.io.network.partition.consumer.InputChannel[] inputChannels = new org.apache.flink.runtime.io.network.partition.consumer.InputChannel[numberOfInputChannels];\n        int channelIndex = 0;\n        for (org.apache.flink.runtime.deployment.PartitionInfo partition : partitions) {\n            final org.apache.flink.runtime.executiongraph.ExecutionAttemptID producerExecutionId = partition.getProducerExecutionId();\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partition.getPartitionId();\n            final org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation producerLocation = partition.getProducerLocation();\n            switch (producerLocation) {\n                case LOCAL :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n                case REMOTE :\n                    final org.apache.flink.runtime.io.network.RemoteAddress producerAddress = com.google.common.base.Preconditions.checkNotNull(partition.getProducerAddress(), \"Missing producer address for remote intermediate result partition.\");\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel(channelIndex, producerExecutionId, partitionId, reader, producerAddress);\n                    break;\n                case UNKNOWN :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n            }\n            reader.setInputChannel(partitionId, inputChannels[channelIndex]);\n            channelIndex++;\n        }\n        return reader;\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Method",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "@java.lang.Override",
            "src_parent": "@java.lang.Override\npublic int getNumberOfInputChannels() {\n    return totalNumberOfInputChannels;\n}",
            "src_parent_type": "Method",
            "src_type": "Annotation"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Synchronized",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "if (numberOfUninitializedChannels > 0) {\n    pendingEvents.add(event);\n}",
            "src_parent": "{\n    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n        inputChannel.sendTaskEvent(event);\n    }\n    if (numberOfUninitializedChannels > 0) {\n        pendingEvents.add(event);\n    }\n}",
            "src_parent_type": "Block",
            "src_type": "If"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "If",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Synchronized",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "for (org.apache.flink.runtime.event.task.TaskEvent event : pendingEvents) {\n    newChannel.sendTaskEvent(event);\n}",
            "src_parent": "{\n    org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n    org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n    if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n        newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n    } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n        newChannel = unknownChannel.toLocalInputChannel();\n    } else {\n        throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n    }\n    inputChannels.put(partitionId, newChannel);\n    newChannel.requestIntermediateResultPartition(queueToRequest);\n    for (org.apache.flink.runtime.event.task.TaskEvent event : pendingEvents) {\n        newChannel.sendTaskEvent(event);\n    }\n    if ((--numberOfUninitializedChannels) == 0) {\n        pendingEvents.clear();\n    }\n}",
            "src_parent_type": "Block",
            "src_type": "ForEach"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "If",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Synchronized",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "if ((--numberOfUninitializedChannels) == 0) {\n    pendingEvents.clear();\n}",
            "src_parent": "{\n    org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n    org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n    if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n        newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n    } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n        newChannel = unknownChannel.toLocalInputChannel();\n    } else {\n        throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n    }\n    inputChannels.put(partitionId, newChannel);\n    newChannel.requestIntermediateResultPartition(queueToRequest);\n    for (org.apache.flink.runtime.event.task.TaskEvent event : pendingEvents) {\n        newChannel.sendTaskEvent(event);\n    }\n    if ((--numberOfUninitializedChannels) == 0) {\n        pendingEvents.clear();\n    }\n}",
            "src_parent_type": "Block",
            "src_type": "If"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Method",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n    synchronized(requestLock) {\n        if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n            numberOfUninitializedChannels++;\n        }\n    }\n}",
            "dst_parent": "public final class BufferReader implements org.apache.flink.runtime.io.network.api.reader.BufferReaderBase {\n    private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger(org.apache.flink.runtime.io.network.api.reader.BufferReader.class);\n\n    private final java.lang.Object requestLock = new java.lang.Object();\n\n    private final org.apache.flink.runtime.execution.RuntimeEnvironment environment;\n\n    private final org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment;\n\n    private final org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent> taskEventHandler = new org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private final org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId;\n\n    private final int totalNumberOfInputChannels;\n\n    private final int queueToRequest;\n\n    private final java.util.Map<org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID, org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannels;\n\n    private org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool;\n\n    private boolean isReleased;\n\n    private boolean isTaskEvent;\n\n    private final java.util.concurrent.BlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannelsWithData = new java.util.concurrent.LinkedBlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel>();\n\n    private final java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>> readerListener = new java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>>(null);\n\n    private final java.util.List<org.apache.flink.runtime.event.task.TaskEvent> pendingEvents = new java.util.ArrayList<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private int numberOfUninitializedChannels;\n\n    private boolean isIterativeReader;\n\n    private int currentNumEndOfSuperstepEvents;\n\n    private int channelIndexOfLastReadBuffer = -1;\n\n    private boolean hasRequestedPartitions = false;\n\n    public BufferReader(org.apache.flink.runtime.execution.RuntimeEnvironment environment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId, int numberOfInputChannels, int queueToRequest) {\n        this.consumedResultId = com.google.common.base.Preconditions.checkNotNull(consumedResultId);\n        this.environment = com.google.common.base.Preconditions.checkNotNull(environment);\n        this.networkEnvironment = networkEnvironment;\n        com.google.common.base.Preconditions.checkArgument(numberOfInputChannels >= 0);\n        this.totalNumberOfInputChannels = numberOfInputChannels;\n        com.google.common.base.Preconditions.checkArgument(queueToRequest >= 0);\n        this.queueToRequest = queueToRequest;\n        this.inputChannels = com.google.common.collect.Maps.newHashMapWithExpectedSize(numberOfInputChannels);\n    }\n\n    public void setBufferPool(org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool) {\n        com.google.common.base.Preconditions.checkArgument(bufferPool.getNumberOfRequiredMemorySegments() == totalNumberOfInputChannels, \"Buffer pool has not enough buffers for this reader.\");\n        com.google.common.base.Preconditions.checkState(this.bufferPool == null, \"Buffer pool has already been set for reader.\");\n        this.bufferPool = com.google.common.base.Preconditions.checkNotNull(bufferPool);\n    }\n\n    public org.apache.flink.runtime.jobgraph.IntermediateDataSetID getConsumedResultId() {\n        return consumedResultId;\n    }\n\n    public java.lang.String getTaskNameWithSubtasks() {\n        return environment.getTaskNameWithSubtasks();\n    }\n\n    public org.apache.flink.runtime.io.network.partition.IntermediateResultPartitionProvider getIntermediateResultPartitionProvider() {\n        return networkEnvironment.getPartitionManager();\n    }\n\n    public org.apache.flink.runtime.io.network.TaskEventDispatcher getTaskEventDispatcher() {\n        return networkEnvironment.getTaskEventDispatcher();\n    }\n\n    public org.apache.flink.runtime.io.network.ConnectionManager getConnectionManager() {\n        return networkEnvironment.getConnectionManager();\n    }\n\n    @java.lang.Override\n    public int getNumberOfInputChannels() {\n        return totalNumberOfInputChannels;\n    }\n\n    public org.apache.flink.runtime.io.network.buffer.BufferProvider getBufferProvider() {\n        return bufferPool;\n    }\n\n    public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        synchronized(requestLock) {\n            if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n                numberOfUninitializedChannels++;\n            }\n        }\n    }\n\n    public void updateInputChannel(org.apache.flink.runtime.deployment.PartitionInfo partitionInfo) throws java.io.IOException {\n        synchronized(requestLock) {\n            if (isReleased) {\n                return;\n            }\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel current = inputChannels.get(partitionId);\n            if (current.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class) {\n                org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n                org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n                if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n                    newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n                } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n                    newChannel = unknownChannel.toLocalInputChannel();\n                } else {\n                    throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n                }\n                inputChannels.put(partitionId, newChannel);\n                newChannel.requestIntermediateResultPartition(queueToRequest);\n                for (org.apache.flink.runtime.event.task.TaskEvent event : pendingEvents) {\n                    newChannel.sendTaskEvent(event);\n                }\n                if ((--numberOfUninitializedChannels) == 0) {\n                    pendingEvents.clear();\n                }\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void requestPartitionsOnce() throws java.io.IOException {\n        if (!hasRequestedPartitions) {\n            if (totalNumberOfInputChannels != inputChannels.size()) {\n                throw new java.lang.IllegalStateException(\"Mismatch between number of total input channels and the currently number of set input channels.\");\n            }\n            synchronized(requestLock) {\n                for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                    inputChannel.requestIntermediateResultPartition(queueToRequest);\n                }\n            }\n            hasRequestedPartitions = true;\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBufferBlocking() throws java.io.IOException, java.lang.InterruptedException {\n        requestPartitionsOnce();\n        while (true) {\n            if (java.lang.Thread.interrupted()) {\n                throw new java.lang.InterruptedException();\n            }\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel currentChannel = null;\n            while (currentChannel == null) {\n                currentChannel = inputChannelsWithData.poll(2000, java.util.concurrent.TimeUnit.MILLISECONDS);\n            } \n            isTaskEvent = false;\n            final org.apache.flink.runtime.io.network.buffer.Buffer buffer = currentChannel.getNextBuffer();\n            if (buffer == null) {\n                throw new java.lang.IllegalStateException(\"Bug in reader logic: queried for a buffer although none was available.\");\n            }\n            if (buffer.isBuffer()) {\n                channelIndexOfLastReadBuffer = currentChannel.getChannelIndex();\n                return buffer;\n            } else {\n                try {\n                    final org.apache.flink.runtime.event.task.AbstractEvent event = org.apache.flink.runtime.io.network.api.serialization.EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n                    if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfPartitionEvent.class) {\n                        currentChannel.releaseAllResources();\n                        return null;\n                    } else if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfSuperstepEvent.class) {\n                        incrementEndOfSuperstepEventAndCheck();\n                        return null;\n                    } else if (event instanceof org.apache.flink.runtime.event.task.TaskEvent) {\n                        taskEventHandler.publish(((org.apache.flink.runtime.event.task.TaskEvent) (event)));\n                        isTaskEvent = true;\n                        return null;\n                    } else {\n                        throw new java.lang.IllegalStateException((((\"Received unexpected event \" + event) + \" from input channel \") + currentChannel) + \".\");\n                    }\n                } catch (java.lang.Throwable t) {\n                    throw new java.io.IOException(\"Error while reading event: \" + t.getMessage(), t);\n                } finally {\n                    buffer.recycle();\n                }\n            }\n        } \n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBuffer(org.apache.flink.runtime.io.network.buffer.Buffer exchangeBuffer) {\n        throw new java.lang.UnsupportedOperationException(\"Buffer exchange when reading data is not yet supported.\");\n    }\n\n    @java.lang.Override\n    public int getChannelIndexOfLastBuffer() {\n        return channelIndexOfLastReadBuffer;\n    }\n\n    @java.lang.Override\n    public boolean isTaskEvent() {\n        return isTaskEvent;\n    }\n\n    @java.lang.Override\n    public boolean isFinished() {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                if (!inputChannel.isReleased()) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n\n    public void releaseAllResources() throws java.io.IOException {\n        synchronized(requestLock) {\n            if (!isReleased) {\n                try {\n                    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                        try {\n                            inputChannel.releaseAllResources();\n                        } catch (java.io.IOException e) {\n                            org.apache.flink.runtime.io.network.api.reader.BufferReader.LOG.warn(\"Error during release of channel resources: \" + e.getMessage(), e);\n                        }\n                    }\n                    if (bufferPool != null) {\n                        bufferPool.destroy();\n                    }\n                } finally {\n                    isReleased = true;\n                }\n            }\n        }\n    }\n\n    public void onAvailableInputChannel(org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        inputChannelsWithData.add(inputChannel);\n        if (readerListener.get() != null) {\n            readerListener.get().onEvent(this);\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToReader(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase> listener) {\n        if (!this.readerListener.compareAndSet(null, listener)) {\n            throw new java.lang.IllegalStateException(listener + \" is already registered as a record availability listener\");\n        }\n    }\n\n    @java.lang.Override\n    public void sendTaskEvent(org.apache.flink.runtime.event.task.TaskEvent event) throws java.io.IOException, java.lang.InterruptedException {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                inputChannel.sendTaskEvent(event);\n            }\n            if (numberOfUninitializedChannels > 0) {\n                pendingEvents.add(event);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToTaskEvent(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.event.task.TaskEvent> listener, java.lang.Class<? extends org.apache.flink.runtime.event.task.TaskEvent> eventType) {\n        taskEventHandler.subscribe(listener, eventType);\n    }\n\n    @java.lang.Override\n    public void setIterativeReader() {\n        isIterativeReader = true;\n    }\n\n    @java.lang.Override\n    public void startNextSuperstep() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Tried to start next superstep in a non-iterative reader.\");\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents == totalNumberOfInputChannels, \"Tried to start next superstep before reaching end of previous superstep.\");\n        currentNumEndOfSuperstepEvents = 0;\n    }\n\n    @java.lang.Override\n    public boolean hasReachedEndOfSuperstep() {\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    private boolean incrementEndOfSuperstepEventAndCheck() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Received end of superstep event in a non-iterative reader.\");\n        currentNumEndOfSuperstepEvents++;\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents <= totalNumberOfInputChannels, (\"Received too many (\" + currentNumEndOfSuperstepEvents) + \") end of superstep events.\");\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return java.lang.String.format(\"BufferReader %s [task: %s, current/total number of input channels: %d/%d]\", consumedResultId, getTaskNameWithSubtasks(), inputChannels.size(), totalNumberOfInputChannels);\n    }\n\n    public static org.apache.flink.runtime.io.network.api.reader.BufferReader create(org.apache.flink.runtime.execution.RuntimeEnvironment runtimeEnvironment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.deployment.PartitionConsumerDeploymentDescriptor desc) {\n        final org.apache.flink.runtime.jobgraph.IntermediateDataSetID resultId = desc.getResultId();\n        final int queueIndex = desc.getQueueIndex();\n        final org.apache.flink.runtime.deployment.PartitionInfo[] partitions = desc.getPartitions();\n        final int numberOfInputChannels = partitions.length;\n        final org.apache.flink.runtime.io.network.api.reader.BufferReader reader = new org.apache.flink.runtime.io.network.api.reader.BufferReader(runtimeEnvironment, networkEnvironment, resultId, numberOfInputChannels, queueIndex);\n        final org.apache.flink.runtime.io.network.partition.consumer.InputChannel[] inputChannels = new org.apache.flink.runtime.io.network.partition.consumer.InputChannel[numberOfInputChannels];\n        int channelIndex = 0;\n        for (org.apache.flink.runtime.deployment.PartitionInfo partition : partitions) {\n            final org.apache.flink.runtime.executiongraph.ExecutionAttemptID producerExecutionId = partition.getProducerExecutionId();\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partition.getPartitionId();\n            final org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation producerLocation = partition.getProducerLocation();\n            switch (producerLocation) {\n                case LOCAL :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n                case REMOTE :\n                    final org.apache.flink.runtime.io.network.RemoteAddress producerAddress = com.google.common.base.Preconditions.checkNotNull(partition.getProducerAddress(), \"Missing producer address for remote intermediate result partition.\");\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel(channelIndex, producerExecutionId, partitionId, reader, producerAddress);\n                    break;\n                case UNKNOWN :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n            }\n            reader.setInputChannel(partitionId, inputChannels[channelIndex]);\n            channelIndex++;\n        }\n        return reader;\n    }\n}",
            "dst_parent_type": "Class",
            "dst_type": "Method",
            "operator": "MOV",
            "src": "boolean hasInputChannelWithData() {\n    return !inputChannelsWithData.isEmpty();\n}",
            "src_parent": "public final class BufferReader implements org.apache.flink.runtime.io.network.api.reader.BufferReaderBase {\n    private static final org.slf4j.Logger LOG = org.slf4j.LoggerFactory.getLogger(org.apache.flink.runtime.io.network.api.reader.BufferReader.class);\n\n    private final java.lang.Object requestLock = new java.lang.Object();\n\n    private final org.apache.flink.runtime.execution.RuntimeEnvironment environment;\n\n    private final org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment;\n\n    private final org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent> taskEventHandler = new org.apache.flink.runtime.util.event.EventNotificationHandler<org.apache.flink.runtime.event.task.TaskEvent>();\n\n    private final org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId;\n\n    private final int totalNumberOfInputChannels;\n\n    private final int queueToRequest;\n\n    private final java.util.Map<org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID, org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannels;\n\n    private org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool;\n\n    private boolean isReleased;\n\n    private boolean isTaskEvent;\n\n    private final java.util.concurrent.BlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel> inputChannelsWithData = new java.util.concurrent.LinkedBlockingQueue<org.apache.flink.runtime.io.network.partition.consumer.InputChannel>();\n\n    private final java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>> readerListener = new java.util.concurrent.atomic.AtomicReference<org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase>>(null);\n\n    private boolean isIterativeReader;\n\n    private int currentNumEndOfSuperstepEvents;\n\n    private int channelIndexOfLastReadBuffer = -1;\n\n    private boolean hasRequestedPartitions = false;\n\n    public BufferReader(org.apache.flink.runtime.execution.RuntimeEnvironment environment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.jobgraph.IntermediateDataSetID consumedResultId, int numberOfInputChannels, int queueToRequest) {\n        this.consumedResultId = com.google.common.base.Preconditions.checkNotNull(consumedResultId);\n        this.environment = com.google.common.base.Preconditions.checkNotNull(environment);\n        this.networkEnvironment = networkEnvironment;\n        com.google.common.base.Preconditions.checkArgument(numberOfInputChannels >= 0);\n        this.totalNumberOfInputChannels = numberOfInputChannels;\n        com.google.common.base.Preconditions.checkArgument(queueToRequest >= 0);\n        this.queueToRequest = queueToRequest;\n        this.inputChannels = com.google.common.collect.Maps.newHashMapWithExpectedSize(numberOfInputChannels);\n    }\n\n    public void setBufferPool(org.apache.flink.runtime.io.network.buffer.BufferPool bufferPool) {\n        com.google.common.base.Preconditions.checkArgument(bufferPool.getNumberOfRequiredMemorySegments() == totalNumberOfInputChannels, \"Buffer pool has not enough buffers for this reader.\");\n        com.google.common.base.Preconditions.checkState(this.bufferPool == null, \"Buffer pool has already been set for reader.\");\n        this.bufferPool = com.google.common.base.Preconditions.checkNotNull(bufferPool);\n    }\n\n    public org.apache.flink.runtime.jobgraph.IntermediateDataSetID getConsumedResultId() {\n        return consumedResultId;\n    }\n\n    public java.lang.String getTaskNameWithSubtasks() {\n        return environment.getTaskNameWithSubtasks();\n    }\n\n    public org.apache.flink.runtime.io.network.partition.IntermediateResultPartitionProvider getIntermediateResultPartitionProvider() {\n        return networkEnvironment.getPartitionManager();\n    }\n\n    public org.apache.flink.runtime.io.network.TaskEventDispatcher getTaskEventDispatcher() {\n        return networkEnvironment.getTaskEventDispatcher();\n    }\n\n    public org.apache.flink.runtime.io.network.ConnectionManager getConnectionManager() {\n        return networkEnvironment.getConnectionManager();\n    }\n\n    boolean hasInputChannelWithData() {\n        return !inputChannelsWithData.isEmpty();\n    }\n\n    public int getNumberOfInputChannels() {\n        return totalNumberOfInputChannels;\n    }\n\n    public org.apache.flink.runtime.io.network.buffer.BufferProvider getBufferProvider() {\n        return bufferPool;\n    }\n\n    public void setInputChannel(org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId, org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        synchronized(requestLock) {\n            inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel));\n        }\n    }\n\n    public void updateInputChannel(org.apache.flink.runtime.deployment.PartitionInfo partitionInfo) throws java.io.IOException {\n        synchronized(requestLock) {\n            if (isReleased) {\n                return;\n            }\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel current = inputChannels.get(partitionId);\n            if (current.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class) {\n                org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel unknownChannel = ((org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel) (current));\n                org.apache.flink.runtime.io.network.partition.consumer.InputChannel newChannel;\n                if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.REMOTE) {\n                    newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());\n                } else if (partitionInfo.getProducerLocation() == org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation.LOCAL) {\n                    newChannel = unknownChannel.toLocalInputChannel();\n                } else {\n                    throw new java.lang.IllegalStateException(\"Tried to update unknown channel with unknown channel.\");\n                }\n                inputChannels.put(partitionId, newChannel);\n                newChannel.requestIntermediateResultPartition(queueToRequest);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void requestPartitionsOnce() throws java.io.IOException {\n        if (!hasRequestedPartitions) {\n            if (totalNumberOfInputChannels != inputChannels.size()) {\n                throw new java.lang.IllegalStateException(\"Mismatch between number of total input channels and the currently number of set input channels.\");\n            }\n            synchronized(requestLock) {\n                for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                    inputChannel.requestIntermediateResultPartition(queueToRequest);\n                }\n            }\n            hasRequestedPartitions = true;\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBufferBlocking() throws java.io.IOException, java.lang.InterruptedException {\n        requestPartitionsOnce();\n        while (true) {\n            if (java.lang.Thread.interrupted()) {\n                throw new java.lang.InterruptedException();\n            }\n            org.apache.flink.runtime.io.network.partition.consumer.InputChannel currentChannel = null;\n            while (currentChannel == null) {\n                currentChannel = inputChannelsWithData.poll(2000, java.util.concurrent.TimeUnit.MILLISECONDS);\n            } \n            isTaskEvent = false;\n            final org.apache.flink.runtime.io.network.buffer.Buffer buffer = currentChannel.getNextBuffer();\n            if (buffer == null) {\n                throw new java.lang.IllegalStateException(\"Bug in reader logic: queried for a buffer although none was available.\");\n            }\n            if (buffer.isBuffer()) {\n                channelIndexOfLastReadBuffer = currentChannel.getChannelIndex();\n                return buffer;\n            } else {\n                try {\n                    final org.apache.flink.runtime.event.task.AbstractEvent event = org.apache.flink.runtime.io.network.api.serialization.EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n                    if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfPartitionEvent.class) {\n                        currentChannel.releaseAllResources();\n                        return null;\n                    } else if (event.getClass() == org.apache.flink.runtime.io.network.api.EndOfSuperstepEvent.class) {\n                        incrementEndOfSuperstepEventAndCheck();\n                        return null;\n                    } else if (event instanceof org.apache.flink.runtime.event.task.TaskEvent) {\n                        taskEventHandler.publish(((org.apache.flink.runtime.event.task.TaskEvent) (event)));\n                        isTaskEvent = true;\n                        return null;\n                    } else {\n                        throw new java.lang.IllegalStateException((((\"Received unexpected event \" + event) + \" from input channel \") + currentChannel) + \".\");\n                    }\n                } catch (java.lang.Throwable t) {\n                    throw new java.io.IOException(\"Error while reading event: \" + t.getMessage(), t);\n                } finally {\n                    buffer.recycle();\n                }\n            }\n        } \n    }\n\n    @java.lang.Override\n    public org.apache.flink.runtime.io.network.buffer.Buffer getNextBuffer(org.apache.flink.runtime.io.network.buffer.Buffer exchangeBuffer) {\n        throw new java.lang.UnsupportedOperationException(\"Buffer exchange when reading data is not yet supported.\");\n    }\n\n    @java.lang.Override\n    public int getChannelIndexOfLastBuffer() {\n        return channelIndexOfLastReadBuffer;\n    }\n\n    @java.lang.Override\n    public boolean isTaskEvent() {\n        return isTaskEvent;\n    }\n\n    @java.lang.Override\n    public boolean isFinished() {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                if (!inputChannel.isReleased()) {\n                    return false;\n                }\n            }\n        }\n        return true;\n    }\n\n    public void releaseAllResources() throws java.io.IOException {\n        synchronized(requestLock) {\n            if (!isReleased) {\n                try {\n                    for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                        try {\n                            inputChannel.releaseAllResources();\n                        } catch (java.io.IOException e) {\n                            org.apache.flink.runtime.io.network.api.reader.BufferReader.LOG.warn(\"Error during release of channel resources: \" + e.getMessage(), e);\n                        }\n                    }\n                    if (bufferPool != null) {\n                        bufferPool.destroy();\n                    }\n                } finally {\n                    isReleased = true;\n                }\n            }\n        }\n    }\n\n    public void onAvailableInputChannel(org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel) {\n        inputChannelsWithData.add(inputChannel);\n        if (readerListener.get() != null) {\n            readerListener.get().onEvent(this);\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToReader(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.io.network.api.reader.BufferReaderBase> listener) {\n        if (!this.readerListener.compareAndSet(null, listener)) {\n            throw new java.lang.IllegalStateException(listener + \" is already registered as a record availability listener\");\n        }\n    }\n\n    @java.lang.Override\n    public void sendTaskEvent(org.apache.flink.runtime.event.task.TaskEvent event) throws java.io.IOException, java.lang.InterruptedException {\n        synchronized(requestLock) {\n            for (org.apache.flink.runtime.io.network.partition.consumer.InputChannel inputChannel : inputChannels.values()) {\n                inputChannel.sendTaskEvent(event);\n            }\n        }\n    }\n\n    @java.lang.Override\n    public void subscribeToTaskEvent(org.apache.flink.runtime.util.event.EventListener<org.apache.flink.runtime.event.task.TaskEvent> listener, java.lang.Class<? extends org.apache.flink.runtime.event.task.TaskEvent> eventType) {\n        taskEventHandler.subscribe(listener, eventType);\n    }\n\n    @java.lang.Override\n    public void setIterativeReader() {\n        isIterativeReader = true;\n    }\n\n    @java.lang.Override\n    public void startNextSuperstep() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Tried to start next superstep in a non-iterative reader.\");\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents == totalNumberOfInputChannels, \"Tried to start next superstep before reaching end of previous superstep.\");\n        currentNumEndOfSuperstepEvents = 0;\n    }\n\n    @java.lang.Override\n    public boolean hasReachedEndOfSuperstep() {\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    private boolean incrementEndOfSuperstepEventAndCheck() {\n        com.google.common.base.Preconditions.checkState(isIterativeReader, \"Received end of superstep event in a non-iterative reader.\");\n        currentNumEndOfSuperstepEvents++;\n        com.google.common.base.Preconditions.checkState(currentNumEndOfSuperstepEvents <= totalNumberOfInputChannels, (\"Received too many (\" + currentNumEndOfSuperstepEvents) + \") end of superstep events.\");\n        return currentNumEndOfSuperstepEvents == totalNumberOfInputChannels;\n    }\n\n    @java.lang.Override\n    public java.lang.String toString() {\n        return java.lang.String.format(\"BufferReader %s [task: %s, current/total number of input channels: %d/%d]\", consumedResultId, getTaskNameWithSubtasks(), inputChannels.size(), totalNumberOfInputChannels);\n    }\n\n    public static org.apache.flink.runtime.io.network.api.reader.BufferReader create(org.apache.flink.runtime.execution.RuntimeEnvironment runtimeEnvironment, org.apache.flink.runtime.io.network.NetworkEnvironment networkEnvironment, org.apache.flink.runtime.deployment.PartitionConsumerDeploymentDescriptor desc) {\n        final org.apache.flink.runtime.jobgraph.IntermediateDataSetID resultId = desc.getResultId();\n        final int queueIndex = desc.getQueueIndex();\n        final org.apache.flink.runtime.deployment.PartitionInfo[] partitions = desc.getPartitions();\n        final int numberOfInputChannels = partitions.length;\n        final org.apache.flink.runtime.io.network.api.reader.BufferReader reader = new org.apache.flink.runtime.io.network.api.reader.BufferReader(runtimeEnvironment, networkEnvironment, resultId, numberOfInputChannels, queueIndex);\n        final org.apache.flink.runtime.io.network.partition.consumer.InputChannel[] inputChannels = new org.apache.flink.runtime.io.network.partition.consumer.InputChannel[numberOfInputChannels];\n        int channelIndex = 0;\n        for (org.apache.flink.runtime.deployment.PartitionInfo partition : partitions) {\n            final org.apache.flink.runtime.executiongraph.ExecutionAttemptID producerExecutionId = partition.getProducerExecutionId();\n            final org.apache.flink.runtime.jobgraph.IntermediateResultPartitionID partitionId = partition.getPartitionId();\n            final org.apache.flink.runtime.deployment.PartitionInfo.PartitionLocation producerLocation = partition.getProducerLocation();\n            switch (producerLocation) {\n                case LOCAL :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.LocalInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n                case REMOTE :\n                    final org.apache.flink.runtime.io.network.RemoteAddress producerAddress = com.google.common.base.Preconditions.checkNotNull(partition.getProducerAddress(), \"Missing producer address for remote intermediate result partition.\");\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannel(channelIndex, producerExecutionId, partitionId, reader, producerAddress);\n                    break;\n                case UNKNOWN :\n                    inputChannels[channelIndex] = new org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel(channelIndex, producerExecutionId, partitionId, reader);\n                    break;\n            }\n            reader.setInputChannel(partitionId, inputChannels[channelIndex]);\n            channelIndex++;\n        }\n        return reader;\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Method"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Synchronized",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "requestLock",
            "dst_parent": "synchronized(requestLock) {\n    if ((inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null) && (inputChannel.getClass() == org.apache.flink.runtime.io.network.partition.consumer.UnknownInputChannel.class)) {\n        numberOfUninitializedChannels++;\n    }\n}",
            "dst_parent_type": "Synchronized",
            "dst_type": "FieldRead",
            "operator": "MOV",
            "src": "requestLock",
            "src_parent": "synchronized(requestLock) {\n    inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel));\n}",
            "src_parent_type": "Synchronized",
            "src_type": "FieldRead"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Synchronized",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel))",
            "dst_parent": "(inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel)) == null)",
            "dst_parent_type": "BinaryOperator",
            "dst_type": "Invocation",
            "operator": "MOV",
            "src": "inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel))",
            "src_parent": "{\n    inputChannels.put(com.google.common.base.Preconditions.checkNotNull(partitionId), com.google.common.base.Preconditions.checkNotNull(inputChannel));\n}",
            "src_parent_type": "Block",
            "src_type": "Invocation"
          }
        }
      ],
      "file_name": "BufferReader"
    }
  ],
  "id": "flink_0a4c7694"
}