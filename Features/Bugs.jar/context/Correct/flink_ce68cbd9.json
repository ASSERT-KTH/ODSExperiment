{
  "files": [
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "Invocation",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "LocalVariable",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "final backtype.storm.generated.StormTopology stormTopology = this.stormBuilder.createTopology()",
            "dst_parent": "{\n    final backtype.storm.generated.StormTopology stormTopology = this.stormBuilder.createTopology();\n    final org.apache.flink.stormcompatibility.api.FlinkTopology env = new org.apache.flink.stormcompatibility.api.FlinkTopology(stormTopology);\n    env.setParallelism(1);\n    final java.util.HashMap<java.lang.String, java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>> availableInputs = new java.util.HashMap<java.lang.String, java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>>();\n    for (final java.util.Map.Entry<java.lang.String, backtype.storm.topology.IRichSpout> spout : this.spouts.entrySet()) {\n        final java.lang.String spoutId = spout.getKey();\n        final backtype.storm.topology.IRichSpout userSpout = spout.getValue();\n        final org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer declarer = new org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer();\n        userSpout.declareOutputFields(declarer);\n        final java.util.HashMap<java.lang.String, backtype.storm.tuple.Fields> sourceStreams = declarer.outputStreams;\n        this.outputStreams.put(spoutId, sourceStreams);\n        declarers.put(spoutId, declarer);\n        org.apache.flink.stormcompatibility.wrappers.AbstractStormSpoutWrapper spoutWrapper;\n        if (userSpout instanceof org.apache.flink.stormcompatibility.wrappers.FiniteStormSpout) {\n            spoutWrapper = new org.apache.flink.stormcompatibility.wrappers.FiniteStormSpoutWrapper(((org.apache.flink.stormcompatibility.wrappers.FiniteStormSpout) (userSpout)));\n        } else {\n            spoutWrapper = new org.apache.flink.stormcompatibility.wrappers.StormSpoutWrapper(userSpout);\n        }\n        org.apache.flink.streaming.api.datastream.DataStreamSource source;\n        java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> outputStreams = new java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>();\n        if (sourceStreams.size() == 1) {\n            final java.lang.String outputStreamId = ((java.lang.String) (sourceStreams.keySet().toArray()[0]));\n            source = env.addSource(spoutWrapper, spoutId, declarer.getOutputType(outputStreamId));\n            outputStreams.put(outputStreamId, source);\n        } else {\n            source = env.addSource(spoutWrapper, spoutId, org.apache.flink.api.java.typeutils.TypeExtractor.getForClass(org.apache.flink.stormcompatibility.util.SplitStreamType.class));\n            org.apache.flink.streaming.api.datastream.SplitDataStream splitSource = source.split(new org.apache.flink.stormcompatibility.util.FlinkStormStreamSelector());\n            for (java.lang.String streamId : sourceStreams.keySet()) {\n                outputStreams.put(streamId, splitSource.select(streamId));\n            }\n        }\n        availableInputs.put(spoutId, outputStreams);\n        int dop = 1;\n        final backtype.storm.generated.ComponentCommon common = stormTopology.get_spouts().get(spoutId).get_common();\n        if (common.is_set_parallelism_hint()) {\n            dop = common.get_parallelism_hint();\n            source.setParallelism(dop);\n        }\n        env.increaseNumberOfTasks(dop);\n    }\n    final java.util.HashMap<java.lang.String, backtype.storm.topology.IRichBolt> unprocessedBolts = new java.util.HashMap<java.lang.String, backtype.storm.topology.IRichBolt>();\n    unprocessedBolts.putAll(this.bolts);\n    final java.util.HashMap<java.lang.String, java.util.Set<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>>> unprocessdInputsPerBolt = new java.util.HashMap<java.lang.String, java.util.Set<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>>>();\n    boolean makeProgress = true;\n    while (unprocessedBolts.size() > 0) {\n        if (!makeProgress) {\n            throw new java.lang.RuntimeException(\"Unable to build Topology. Could not connect the following bolts: \" + unprocessedBolts.keySet());\n        }\n        makeProgress = false;\n        final java.util.Iterator<java.util.Map.Entry<java.lang.String, backtype.storm.topology.IRichBolt>> boltsIterator = unprocessedBolts.entrySet().iterator();\n        while (boltsIterator.hasNext()) {\n            final java.util.Map.Entry<java.lang.String, backtype.storm.topology.IRichBolt> bolt = boltsIterator.next();\n            final java.lang.String boltId = bolt.getKey();\n            final backtype.storm.topology.IRichBolt userBolt = bolt.getValue();\n            final backtype.storm.generated.ComponentCommon common = stormTopology.get_bolts().get(boltId).get_common();\n            java.util.Set<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>> unprocessedInputs = unprocessdInputsPerBolt.get(boltId);\n            if (unprocessedInputs == null) {\n                unprocessedInputs = new java.util.HashSet<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>>();\n                unprocessedInputs.addAll(common.get_inputs().entrySet());\n                unprocessdInputsPerBolt.put(boltId, unprocessedInputs);\n            }\n            final java.util.Iterator<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>> inputStreamsIterator = unprocessedInputs.iterator();\n            while (inputStreamsIterator.hasNext()) {\n                final java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping> stormInputStream = inputStreamsIterator.next();\n                final java.lang.String producerId = stormInputStream.getKey().get_componentId();\n                final java.lang.String inputStreamId = stormInputStream.getKey().get_streamId();\n                java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> producer = availableInputs.get(producerId);\n                if (producer != null) {\n                    makeProgress = true;\n                    org.apache.flink.streaming.api.datastream.DataStream inputStream = producer.get(inputStreamId);\n                    if (inputStream != null) {\n                        final org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer declarer = new org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer();\n                        userBolt.declareOutputFields(declarer);\n                        final java.util.HashMap<java.lang.String, backtype.storm.tuple.Fields> boltOutputStreams = declarer.outputStreams;\n                        this.outputStreams.put(boltId, boltOutputStreams);\n                        this.declarers.put(boltId, declarer);\n                        final backtype.storm.generated.Grouping grouping = stormInputStream.getValue();\n                        if (grouping.is_set_shuffle()) {\n                            inputStream = inputStream.rebalance();\n                        } else if (grouping.is_set_fields()) {\n                            final java.util.List<java.lang.String> fields = grouping.get_fields();\n                            if (fields.size() > 0) {\n                                org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n                                if (producer.size() == 1) {\n                                    inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n                                } else {\n                                    inputStream = inputStream.groupBy(new org.apache.flink.stormcompatibility.api.SplitStreamTypeKeySelector(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields())));\n                                }\n                            } else {\n                                inputStream = inputStream.global();\n                            }\n                        } else if (grouping.is_set_all()) {\n                            inputStream = inputStream.broadcast();\n                        } else if (!grouping.is_set_local_or_shuffle()) {\n                            throw new java.lang.UnsupportedOperationException(\"Flink only supports (local-or-)shuffle, fields, all, and global grouping\");\n                        }\n                        org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator outputStream;\n                        if (boltOutputStreams.size() < 2) {\n                            java.lang.String outputStreamId = null;\n                            if (boltOutputStreams.size() == 1) {\n                                outputStreamId = ((java.lang.String) (boltOutputStreams.keySet().toArray()[0]));\n                            }\n                            final org.apache.flink.api.common.typeinfo.TypeInformation<?> outType = declarer.getOutputType(outputStreamId);\n                            outputStream = inputStream.transform(boltId, outType, new org.apache.flink.stormcompatibility.wrappers.StormBoltWrapper(userBolt, this.outputStreams.get(producerId).get(inputStreamId)));\n                            if (outType != null) {\n                                java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> op = new java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>();\n                                op.put(outputStreamId, outputStream);\n                                availableInputs.put(boltId, op);\n                            }\n                        } else {\n                            final org.apache.flink.api.common.typeinfo.TypeInformation<?> outType = org.apache.flink.api.java.typeutils.TypeExtractor.getForClass(org.apache.flink.stormcompatibility.util.SplitStreamType.class);\n                            outputStream = inputStream.transform(boltId, outType, new org.apache.flink.stormcompatibility.wrappers.StormBoltWrapper(userBolt, this.outputStreams.get(producerId).get(inputStreamId)));\n                            org.apache.flink.streaming.api.datastream.SplitDataStream splitStreams = outputStream.split(new org.apache.flink.stormcompatibility.util.FlinkStormStreamSelector());\n                            java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> op = new java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>();\n                            for (java.lang.String outputStreamId : boltOutputStreams.keySet()) {\n                                op.put(outputStreamId, splitStreams.select(outputStreamId));\n                            }\n                            availableInputs.put(boltId, op);\n                        }\n                        int dop = 1;\n                        if (common.is_set_parallelism_hint()) {\n                            dop = common.get_parallelism_hint();\n                            outputStream.setParallelism(dop);\n                        }\n                        env.increaseNumberOfTasks(dop);\n                        inputStreamsIterator.remove();\n                    } else {\n                        throw new java.lang.RuntimeException((((((\"Cannot connect '\" + boltId) + \"' to '\") + producerId) + \"'. Stream '\") + inputStreamId) + \"' not found.\");\n                    }\n                }\n            } \n            if (unprocessedInputs.size() == 0) {\n                boltsIterator.remove();\n            }\n        } \n    } \n    return env;\n}",
            "dst_parent_type": "Block",
            "dst_type": "LocalVariable",
            "operator": "UPD",
            "src": "final backtype.storm.generated.StormTopology stormTopolgoy = this.stormBuilder.createTopology()",
            "src_parent": "{\n    final backtype.storm.generated.StormTopology stormTopolgoy = this.stormBuilder.createTopology();\n    final org.apache.flink.stormcompatibility.api.FlinkTopology env = new org.apache.flink.stormcompatibility.api.FlinkTopology(stormTopolgoy);\n    env.setParallelism(1);\n    final java.util.HashMap<java.lang.String, java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>> availableInputs = new java.util.HashMap<java.lang.String, java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>>();\n    for (final java.util.Map.Entry<java.lang.String, backtype.storm.topology.IRichSpout> spout : this.spouts.entrySet()) {\n        final java.lang.String spoutId = spout.getKey();\n        final backtype.storm.topology.IRichSpout userSpout = spout.getValue();\n        final org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer declarer = new org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer();\n        userSpout.declareOutputFields(declarer);\n        final java.util.HashMap<java.lang.String, backtype.storm.tuple.Fields> sourceStreams = declarer.outputStreams;\n        this.outputStreams.put(spoutId, sourceStreams);\n        declarers.put(spoutId, declarer);\n        org.apache.flink.stormcompatibility.wrappers.AbstractStormSpoutWrapper spoutWrapper;\n        if (userSpout instanceof org.apache.flink.stormcompatibility.wrappers.FiniteStormSpout) {\n            spoutWrapper = new org.apache.flink.stormcompatibility.wrappers.FiniteStormSpoutWrapper(((org.apache.flink.stormcompatibility.wrappers.FiniteStormSpout) (userSpout)));\n        } else {\n            spoutWrapper = new org.apache.flink.stormcompatibility.wrappers.StormSpoutWrapper(userSpout);\n        }\n        org.apache.flink.streaming.api.datastream.DataStreamSource source;\n        java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> outputStreams = new java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>();\n        if (sourceStreams.size() == 1) {\n            final java.lang.String outputStreamId = ((java.lang.String) (sourceStreams.keySet().toArray()[0]));\n            source = env.addSource(spoutWrapper, spoutId, declarer.getOutputType(outputStreamId));\n            outputStreams.put(outputStreamId, source);\n        } else {\n            source = env.addSource(spoutWrapper, spoutId, org.apache.flink.api.java.typeutils.TypeExtractor.getForClass(org.apache.flink.stormcompatibility.util.SplitStreamType.class));\n            org.apache.flink.streaming.api.datastream.SplitDataStream splitSource = source.split(new org.apache.flink.stormcompatibility.util.FlinkStormStreamSelector());\n            for (java.lang.String streamId : sourceStreams.keySet()) {\n                outputStreams.put(streamId, splitSource.select(streamId));\n            }\n        }\n        availableInputs.put(spoutId, outputStreams);\n        int dop = 1;\n        final backtype.storm.generated.ComponentCommon common = stormTopolgoy.get_spouts().get(spoutId).get_common();\n        if (common.is_set_parallelism_hint()) {\n            dop = common.get_parallelism_hint();\n            source.setParallelism(dop);\n        }\n        env.increaseNumberOfTasks(dop);\n    }\n    final java.util.HashMap<java.lang.String, backtype.storm.topology.IRichBolt> unprocessedBolts = new java.util.HashMap<java.lang.String, backtype.storm.topology.IRichBolt>();\n    unprocessedBolts.putAll(this.bolts);\n    final java.util.HashMap<java.lang.String, java.util.Set<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>>> unprocessdInputsPerBolt = new java.util.HashMap<java.lang.String, java.util.Set<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>>>();\n    boolean makeProgress = true;\n    while (unprocessedBolts.size() > 0) {\n        if (!makeProgress) {\n            throw new java.lang.RuntimeException(\"Unable to build Topology. Could not connect the following bolts: \" + unprocessedBolts.keySet());\n        }\n        makeProgress = false;\n        final java.util.Iterator<java.util.Map.Entry<java.lang.String, backtype.storm.topology.IRichBolt>> boltsIterator = unprocessedBolts.entrySet().iterator();\n        while (boltsIterator.hasNext()) {\n            final java.util.Map.Entry<java.lang.String, backtype.storm.topology.IRichBolt> bolt = boltsIterator.next();\n            final java.lang.String boltId = bolt.getKey();\n            final backtype.storm.topology.IRichBolt userBolt = bolt.getValue();\n            final backtype.storm.generated.ComponentCommon common = stormTopolgoy.get_bolts().get(boltId).get_common();\n            java.util.Set<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>> unprocessedInputs = unprocessdInputsPerBolt.get(boltId);\n            if (unprocessedInputs == null) {\n                unprocessedInputs = new java.util.HashSet<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>>();\n                unprocessedInputs.addAll(common.get_inputs().entrySet());\n                unprocessdInputsPerBolt.put(boltId, unprocessedInputs);\n            }\n            final java.util.Iterator<java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping>> inputStreamsIterator = unprocessedInputs.iterator();\n            while (inputStreamsIterator.hasNext()) {\n                final java.util.Map.Entry<backtype.storm.generated.GlobalStreamId, backtype.storm.generated.Grouping> stormInputStream = inputStreamsIterator.next();\n                final java.lang.String producerId = stormInputStream.getKey().get_componentId();\n                final java.lang.String inputStreamId = stormInputStream.getKey().get_streamId();\n                java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> producer = availableInputs.get(producerId);\n                if (producer != null) {\n                    makeProgress = true;\n                    org.apache.flink.streaming.api.datastream.DataStream inputStream = producer.get(inputStreamId);\n                    if (inputStream != null) {\n                        final org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer declarer = new org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer();\n                        userBolt.declareOutputFields(declarer);\n                        final java.util.HashMap<java.lang.String, backtype.storm.tuple.Fields> boltOutputStreams = declarer.outputStreams;\n                        this.outputStreams.put(boltId, boltOutputStreams);\n                        this.declarers.put(boltId, declarer);\n                        final backtype.storm.generated.Grouping grouping = stormInputStream.getValue();\n                        if (grouping.is_set_shuffle()) {\n                            inputStream = inputStream.rebalance();\n                        } else if (grouping.is_set_fields()) {\n                            final java.util.List<java.lang.String> fields = grouping.get_fields();\n                            if (fields.size() > 0) {\n                                org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n                                inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n                            } else {\n                                inputStream = inputStream.global();\n                            }\n                        } else if (grouping.is_set_all()) {\n                            inputStream = inputStream.broadcast();\n                        } else if (!grouping.is_set_local_or_shuffle()) {\n                            throw new java.lang.UnsupportedOperationException(\"Flink only supports (local-or-)shuffle, fields, all, and global grouping\");\n                        }\n                        org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator outputStream;\n                        if (boltOutputStreams.size() < 2) {\n                            java.lang.String outputStreamId = null;\n                            if (boltOutputStreams.size() == 1) {\n                                outputStreamId = ((java.lang.String) (boltOutputStreams.keySet().toArray()[0]));\n                            }\n                            final org.apache.flink.api.common.typeinfo.TypeInformation<?> outType = declarer.getOutputType(outputStreamId);\n                            outputStream = inputStream.transform(boltId, outType, new org.apache.flink.stormcompatibility.wrappers.StormBoltWrapper(userBolt, this.outputStreams.get(producerId).get(inputStreamId)));\n                            if (outType != null) {\n                                java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> op = new java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>();\n                                op.put(outputStreamId, outputStream);\n                                availableInputs.put(boltId, op);\n                            }\n                        } else {\n                            final org.apache.flink.api.common.typeinfo.TypeInformation<?> outType = org.apache.flink.api.java.typeutils.TypeExtractor.getForClass(org.apache.flink.stormcompatibility.util.SplitStreamType.class);\n                            outputStream = inputStream.transform(boltId, outType, new org.apache.flink.stormcompatibility.wrappers.StormBoltWrapper(userBolt, this.outputStreams.get(producerId).get(inputStreamId)));\n                            org.apache.flink.streaming.api.datastream.SplitDataStream splitStreams = outputStream.split(new org.apache.flink.stormcompatibility.util.FlinkStormStreamSelector());\n                            java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream> op = new java.util.HashMap<java.lang.String, org.apache.flink.streaming.api.datastream.DataStream>();\n                            for (java.lang.String outputStreamId : boltOutputStreams.keySet()) {\n                                op.put(outputStreamId, splitStreams.select(outputStreamId));\n                            }\n                            availableInputs.put(boltId, op);\n                        }\n                        int dop = 1;\n                        if (common.is_set_parallelism_hint()) {\n                            dop = common.get_parallelism_hint();\n                            outputStream.setParallelism(dop);\n                        }\n                        env.increaseNumberOfTasks(dop);\n                        inputStreamsIterator.remove();\n                    } else {\n                        throw new java.lang.RuntimeException((((((\"Cannot connect '\" + boltId) + \"' to '\") + producerId) + \"'. Stream '\") + inputStreamId) + \"' not found.\");\n                    }\n                }\n            } \n            if (unprocessedInputs.size() == 0) {\n                boltsIterator.remove();\n            }\n        } \n    } \n    return env;\n}",
            "src_parent_type": "Block",
            "src_type": "LocalVariable"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "Invocation",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "ForEach",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "LocalVariable",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "stormTopology",
            "dst_parent": "new org.apache.flink.stormcompatibility.api.FlinkTopology(stormTopology)",
            "dst_parent_type": "ConstructorCall",
            "dst_type": "VariableRead",
            "operator": "UPD",
            "src": "stormTopolgoy",
            "src_parent": "new org.apache.flink.stormcompatibility.api.FlinkTopology(stormTopolgoy)",
            "src_parent_type": "ConstructorCall",
            "src_type": "VariableRead"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "Invocation",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "Invocation",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "If",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "ForEach",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "LocalVariable",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "stormTopology",
            "dst_parent": "stormTopology.get_spouts()",
            "dst_parent_type": "Invocation",
            "dst_type": "VariableRead",
            "operator": "UPD",
            "src": "stormTopolgoy",
            "src_parent": "stormTopolgoy.get_spouts()",
            "src_parent_type": "Invocation",
            "src_type": "VariableRead"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "LocalVariable",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "While",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "true",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "LocalVariable",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "stormTopology",
            "dst_parent": "stormTopology.get_bolts()",
            "dst_parent_type": "Invocation",
            "dst_type": "VariableRead",
            "operator": "UPD",
            "src": "stormTopolgoy",
            "src_parent": "stormTopolgoy.get_bolts()",
            "src_parent_type": "Invocation",
            "src_type": "VariableRead"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "{\n    org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n    if (producer.size() == 1) {\n        inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n    } else {\n        inputStream = inputStream.groupBy(new org.apache.flink.stormcompatibility.api.SplitStreamTypeKeySelector(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields())));\n    }\n}",
            "src_parent": "if (fields.size() > 0) {\n    org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n    if (producer.size() == 1) {\n        inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n    } else {\n        inputStream = inputStream.groupBy(new org.apache.flink.stormcompatibility.api.SplitStreamTypeKeySelector(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields())));\n    }\n} else {\n    inputStream = inputStream.global();\n}",
            "src_parent_type": "If",
            "src_type": "Block"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId)",
            "dst_parent": "{\n    org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n    if (producer.size() == 1) {\n        inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n    } else {\n        inputStream = inputStream.groupBy(new org.apache.flink.stormcompatibility.api.SplitStreamTypeKeySelector(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields())));\n    }\n}",
            "dst_parent_type": "Block",
            "dst_type": "LocalVariable",
            "operator": "MOV",
            "src": "org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId)",
            "src_parent": "{\n    org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n    inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n}",
            "src_parent_type": "Block",
            "src_type": "LocalVariable"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "{\n    inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n}",
            "dst_parent": "if (producer.size() == 1) {\n    inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n} else {\n    inputStream = inputStream.groupBy(new org.apache.flink.stormcompatibility.api.SplitStreamTypeKeySelector(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields())));\n}",
            "dst_parent_type": "If",
            "dst_type": "Block",
            "operator": "MOV",
            "src": "{\n    org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n    inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n}",
            "src_parent": "if (fields.size() > 0) {\n    org.apache.flink.stormcompatibility.api.FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);\n    inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));\n} else {\n    inputStream = inputStream.global();\n}",
            "src_parent_type": "If",
            "src_type": "Block"
          }
        }
      ],
      "file_name": "FlinkTopologyBuilder"
    }
  ],
  "id": "flink_ce68cbd9"
}