{
  "files": [
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Field",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "final java.lang.String encoding;",
            "src_parent": "public class TarArchiveInputStream extends org.apache.commons.compress.archivers.ArchiveInputStream {\n    private static final int SMALL_BUFFER_SIZE = 256;\n\n    private final byte[] SMALL_BUF = new byte[org.apache.commons.compress.archivers.tar.TarArchiveInputStream.SMALL_BUFFER_SIZE];\n\n    private final int recordSize;\n\n    private final int blockSize;\n\n    private boolean hasHitEOF;\n\n    private long entrySize;\n\n    private long entryOffset;\n\n    private final java.io.InputStream is;\n\n    private org.apache.commons.compress.archivers.tar.TarArchiveEntry currEntry;\n\n    private final org.apache.commons.compress.archivers.zip.ZipEncoding zipEncoding;\n\n    final java.lang.String encoding;\n\n    public TarArchiveInputStream(java.io.InputStream is) {\n        this(is, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_BLKSIZE, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    public TarArchiveInputStream(java.io.InputStream is, java.lang.String encoding) {\n        this(is, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_BLKSIZE, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    public TarArchiveInputStream(java.io.InputStream is, int blockSize) {\n        this(is, blockSize, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    public TarArchiveInputStream(java.io.InputStream is, int blockSize, java.lang.String encoding) {\n        this(is, blockSize, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    public TarArchiveInputStream(java.io.InputStream is, int blockSize, int recordSize) {\n        this(is, blockSize, recordSize, null);\n    }\n\n    public TarArchiveInputStream(java.io.InputStream is, int blockSize, int recordSize, java.lang.String encoding) {\n        this.is = is;\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n        this.recordSize = recordSize;\n        this.blockSize = blockSize;\n    }\n\n    @java.lang.Override\n    public void close() throws java.io.IOException {\n        is.close();\n    }\n\n    public int getRecordSize() {\n        return recordSize;\n    }\n\n    @java.lang.Override\n    public int available() throws java.io.IOException {\n        if ((entrySize - entryOffset) > java.lang.Integer.MAX_VALUE) {\n            return java.lang.Integer.MAX_VALUE;\n        }\n        return ((int) (entrySize - entryOffset));\n    }\n\n    @java.lang.Override\n    public long skip(final long n) throws java.io.IOException {\n        if (n <= 0) {\n            return 0;\n        }\n        final long available = entrySize - entryOffset;\n        final long skipped = is.skip(java.lang.Math.min(n, available));\n        count(skipped);\n        entryOffset += skipped;\n        return skipped;\n    }\n\n    @java.lang.Override\n    public boolean markSupported() {\n        return false;\n    }\n\n    @java.lang.Override\n    public void mark(int markLimit) {\n    }\n\n    @java.lang.Override\n    public synchronized void reset() {\n    }\n\n    public org.apache.commons.compress.archivers.tar.TarArchiveEntry getNextTarEntry() throws java.io.IOException {\n        if (hasHitEOF) {\n            return null;\n        }\n        if (currEntry != null) {\n            org.apache.commons.compress.utils.IOUtils.skip(this, java.lang.Long.MAX_VALUE);\n            skipRecordPadding();\n        }\n        byte[] headerBuf = getRecord();\n        if (headerBuf == null) {\n            currEntry = null;\n            return null;\n        }\n        try {\n            currEntry = new org.apache.commons.compress.archivers.tar.TarArchiveEntry(headerBuf, zipEncoding);\n        } catch (java.lang.IllegalArgumentException e) {\n            java.io.IOException ioe = new java.io.IOException(\"Error detected parsing the header\");\n            ioe.initCause(e);\n            throw ioe;\n        }\n        entryOffset = 0;\n        entrySize = currEntry.getSize();\n        if (currEntry.isGNULongLinkEntry()) {\n            byte[] longLinkData = getLongNameData();\n            if (longLinkData == null) {\n                return null;\n            }\n            currEntry.setLinkName(zipEncoding.decode(longLinkData));\n        }\n        if (currEntry.isGNULongNameEntry()) {\n            byte[] longNameData = getLongNameData();\n            if (longNameData == null) {\n                return null;\n            }\n            currEntry.setName(zipEncoding.decode(longNameData));\n        }\n        if (currEntry.isPaxHeader()) {\n            paxHeaders();\n        }\n        if (currEntry.isGNUSparse()) {\n            readGNUSparse();\n        }\n        entrySize = currEntry.getSize();\n        return currEntry;\n    }\n\n    private void skipRecordPadding() throws java.io.IOException {\n        if ((this.entrySize > 0) && ((this.entrySize % this.recordSize) != 0)) {\n            long numRecords = (this.entrySize / this.recordSize) + 1;\n            long padding = (numRecords * this.recordSize) - this.entrySize;\n            long skipped = org.apache.commons.compress.utils.IOUtils.skip(is, padding);\n            count(skipped);\n        }\n    }\n\n    protected byte[] getLongNameData() throws java.io.IOException {\n        java.io.ByteArrayOutputStream longName = new java.io.ByteArrayOutputStream();\n        int length = 0;\n        while ((length = read(SMALL_BUF)) >= 0) {\n            longName.write(SMALL_BUF, 0, length);\n        } \n        getNextEntry();\n        if (currEntry == null) {\n            return null;\n        }\n        byte[] longNameData = longName.toByteArray();\n        length = longNameData.length;\n        while ((length > 0) && (longNameData[length - 1] == 0)) {\n            --length;\n        } \n        if (length != longNameData.length) {\n            byte[] l = new byte[length];\n            java.lang.System.arraycopy(longNameData, 0, l, 0, length);\n            longNameData = l;\n        }\n        return longNameData;\n    }\n\n    private byte[] getRecord() throws java.io.IOException {\n        byte[] headerBuf = readRecord();\n        hasHitEOF = isEOFRecord(headerBuf);\n        if (hasHitEOF && (headerBuf != null)) {\n            tryToConsumeSecondEOFRecord();\n            consumeRemainderOfLastBlock();\n            headerBuf = null;\n        }\n        return headerBuf;\n    }\n\n    protected boolean isEOFRecord(byte[] record) {\n        return (record == null) || org.apache.commons.compress.utils.ArchiveUtils.isArrayZero(record, recordSize);\n    }\n\n    protected byte[] readRecord() throws java.io.IOException {\n        byte[] record = new byte[recordSize];\n        int readNow = org.apache.commons.compress.utils.IOUtils.readFully(is, record);\n        count(readNow);\n        if (readNow != recordSize) {\n            return null;\n        }\n        return record;\n    }\n\n    private void paxHeaders() throws java.io.IOException {\n        java.util.Map<java.lang.String, java.lang.String> headers = parsePaxHeaders(this);\n        getNextEntry();\n        applyPaxHeadersToCurrentEntry(headers);\n    }\n\n    java.util.Map<java.lang.String, java.lang.String> parsePaxHeaders(java.io.InputStream i) throws java.io.IOException {\n        java.util.Map<java.lang.String, java.lang.String> headers = new java.util.HashMap<java.lang.String, java.lang.String>();\n        while (true) {\n            int ch;\n            int len = 0;\n            int read = 0;\n            while ((ch = i.read()) != (-1)) {\n                read++;\n                if (ch == ' ') {\n                    java.io.ByteArrayOutputStream coll = new java.io.ByteArrayOutputStream();\n                    while ((ch = i.read()) != (-1)) {\n                        read++;\n                        if (ch == '=') {\n                            java.lang.String keyword = coll.toString(org.apache.commons.compress.utils.CharsetNames.UTF_8);\n                            final int restLen = len - read;\n                            byte[] rest = new byte[restLen];\n                            int got = org.apache.commons.compress.utils.IOUtils.readFully(i, rest);\n                            if (got != restLen) {\n                                throw new java.io.IOException((((\"Failed to read \" + \"Paxheader. Expected \") + restLen) + \" bytes, read \") + got);\n                            }\n                            java.lang.String value = new java.lang.String(rest, 0, restLen - 1, org.apache.commons.compress.utils.CharsetNames.UTF_8);\n                            headers.put(keyword, value);\n                            break;\n                        }\n                        coll.write(((byte) (ch)));\n                    } \n                    break;\n                }\n                len *= 10;\n                len += ch - '0';\n            } \n            if (ch == (-1)) {\n                break;\n            }\n        } \n        return headers;\n    }\n\n    private void applyPaxHeadersToCurrentEntry(java.util.Map<java.lang.String, java.lang.String> headers) {\n        for (java.util.Map.Entry<java.lang.String, java.lang.String> ent : headers.entrySet()) {\n            java.lang.String key = ent.getKey();\n            java.lang.String val = ent.getValue();\n            if (\"path\".equals(key)) {\n                currEntry.setName(val);\n            } else if (\"linkpath\".equals(key)) {\n                currEntry.setLinkName(val);\n            } else if (\"gid\".equals(key)) {\n                currEntry.setGroupId(java.lang.Integer.parseInt(val));\n            } else if (\"gname\".equals(key)) {\n                currEntry.setGroupName(val);\n            } else if (\"uid\".equals(key)) {\n                currEntry.setUserId(java.lang.Integer.parseInt(val));\n            } else if (\"uname\".equals(key)) {\n                currEntry.setUserName(val);\n            } else if (\"size\".equals(key)) {\n                currEntry.setSize(java.lang.Long.parseLong(val));\n            } else if (\"mtime\".equals(key)) {\n                currEntry.setModTime(((long) (java.lang.Double.parseDouble(val) * 1000)));\n            } else if (\"SCHILY.devminor\".equals(key)) {\n                currEntry.setDevMinor(java.lang.Integer.parseInt(val));\n            } else if (\"SCHILY.devmajor\".equals(key)) {\n                currEntry.setDevMajor(java.lang.Integer.parseInt(val));\n            }\n        }\n    }\n\n    private void readGNUSparse() throws java.io.IOException {\n        if (currEntry.isExtended()) {\n            org.apache.commons.compress.archivers.tar.TarArchiveSparseEntry entry;\n            do {\n                byte[] headerBuf = getRecord();\n                if (headerBuf == null) {\n                    currEntry = null;\n                    break;\n                }\n                entry = new org.apache.commons.compress.archivers.tar.TarArchiveSparseEntry(headerBuf);\n            } while (entry.isExtended() );\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.commons.compress.archivers.ArchiveEntry getNextEntry() throws java.io.IOException {\n        return getNextTarEntry();\n    }\n\n    private void tryToConsumeSecondEOFRecord() throws java.io.IOException {\n        boolean shouldReset = true;\n        boolean marked = is.markSupported();\n        if (marked) {\n            is.mark(recordSize);\n        }\n        try {\n            shouldReset = !isEOFRecord(readRecord());\n        } finally {\n            if (shouldReset && marked) {\n                pushedBackBytes(recordSize);\n                is.reset();\n            }\n        }\n    }\n\n    @java.lang.Override\n    public int read(byte[] buf, int offset, int numToRead) throws java.io.IOException {\n        int totalRead = 0;\n        if (hasHitEOF || (entryOffset >= entrySize)) {\n            return -1;\n        }\n        if (currEntry == null) {\n            throw new java.lang.IllegalStateException(\"No current tar entry\");\n        }\n        numToRead = java.lang.Math.min(numToRead, available());\n        totalRead = is.read(buf, offset, numToRead);\n        if (totalRead == (-1)) {\n            if (numToRead > 0) {\n                throw new java.io.IOException(\"Truncated TAR archive\");\n            }\n            hasHitEOF = true;\n        } else {\n            count(totalRead);\n            entryOffset += totalRead;\n        }\n        return totalRead;\n    }\n\n    @java.lang.Override\n    public boolean canReadEntryData(org.apache.commons.compress.archivers.ArchiveEntry ae) {\n        if (ae instanceof org.apache.commons.compress.archivers.tar.TarArchiveEntry) {\n            org.apache.commons.compress.archivers.tar.TarArchiveEntry te = ((org.apache.commons.compress.archivers.tar.TarArchiveEntry) (ae));\n            return !te.isGNUSparse();\n        }\n        return false;\n    }\n\n    public org.apache.commons.compress.archivers.tar.TarArchiveEntry getCurrentEntry() {\n        return currEntry;\n    }\n\n    protected final void setCurrentEntry(org.apache.commons.compress.archivers.tar.TarArchiveEntry e) {\n        currEntry = e;\n    }\n\n    protected final boolean isAtEOF() {\n        return hasHitEOF;\n    }\n\n    protected final void setAtEOF(boolean b) {\n        hasHitEOF = b;\n    }\n\n    private void consumeRemainderOfLastBlock() throws java.io.IOException {\n        long bytesReadOfLastBlock = getBytesRead() % blockSize;\n        if (bytesReadOfLastBlock > 0) {\n            long skipped = org.apache.commons.compress.utils.IOUtils.skip(is, blockSize - bytesReadOfLastBlock);\n            count(skipped);\n        }\n    }\n\n    public static boolean matches(byte[] signature, int length) {\n        if (length < (org.apache.commons.compress.archivers.tar.TarConstants.VERSION_OFFSET + org.apache.commons.compress.archivers.tar.TarConstants.VERSIONLEN)) {\n            return false;\n        }\n        if (org.apache.commons.compress.utils.ArchiveUtils.matchAsciiBuffer(org.apache.commons.compress.archivers.tar.TarConstants.MAGIC_POSIX, signature, org.apache.commons.compress.archivers.tar.TarConstants.MAGIC_OFFSET, org.apache.commons.compress.archivers.tar.TarConstants.MAGICLEN) && org.apache.commons.compress.utils.ArchiveUtils.matchAsciiBuffer(org.apache.commons.compress.archivers.tar.TarConstants.VERSION_POSIX, signature, org.apache.commons.compress.archivers.tar.TarConstants.VERSION_OFFSET, org.apache.commons.compress.archivers.tar.TarConstants.VERSIONLEN)) {\n            return true;\n        }\n        if (org.apache.commons.compress.utils.ArchiveUtils.matchAsciiBuffer(org.apache.commons.compress.archivers.tar.TarConstants.MAGIC_GNU, signature, org.apache.commons.compress.archivers.tar.TarConstants.MAGIC_OFFSET, org.apache.commons.compress.archivers.tar.TarConstants.MAGICLEN) && (org.apache.commons.compress.utils.ArchiveUtils.matchAsciiBuffer(org.apache.commons.compress.archivers.tar.TarConstants.VERSION_GNU_SPACE, signature, org.apache.commons.compress.archivers.tar.TarConstants.VERSION_OFFSET, org.apache.commons.compress.archivers.tar.TarConstants.VERSIONLEN) || org.apache.commons.compress.utils.ArchiveUtils.matchAsciiBuffer(org.apache.commons.compress.archivers.tar.TarConstants.VERSION_GNU_ZERO, signature, org.apache.commons.compress.archivers.tar.TarConstants.VERSION_OFFSET, org.apache.commons.compress.archivers.tar.TarConstants.VERSIONLEN))) {\n            return true;\n        }\n        if (org.apache.commons.compress.utils.ArchiveUtils.matchAsciiBuffer(org.apache.commons.compress.archivers.tar.TarConstants.MAGIC_ANT, signature, org.apache.commons.compress.archivers.tar.TarConstants.MAGIC_OFFSET, org.apache.commons.compress.archivers.tar.TarConstants.MAGICLEN) && org.apache.commons.compress.utils.ArchiveUtils.matchAsciiBuffer(org.apache.commons.compress.archivers.tar.TarConstants.VERSION_ANT, signature, org.apache.commons.compress.archivers.tar.TarConstants.VERSION_OFFSET, org.apache.commons.compress.archivers.tar.TarConstants.VERSIONLEN)) {\n            return true;\n        }\n        return false;\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "Invocation",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Constructor",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Assignment",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "this.encoding = encoding",
            "src_parent": "{\n    this.is = is;\n    this.hasHitEOF = false;\n    this.encoding = encoding;\n    this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n    this.recordSize = recordSize;\n    this.blockSize = blockSize;\n}",
            "src_parent_type": "Block",
            "src_type": "Assignment"
          }
        }
      ],
      "file_name": "TarArchiveInputStream"
    },
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out, entryEncoding)",
            "src_parent": "{\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out, entryEncoding);\n}",
            "src_parent_type": "Block",
            "src_type": "Return"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "Throw",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "If",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "if (org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)) {\n    if (entryEncoding != null) {\n        return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out, entryEncoding);\n    } else {\n        return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n    }\n}",
            "src_parent": "{\n    if (archiverName == null) {\n        throw new java.lang.IllegalArgumentException(\"Archivername must not be null.\");\n    }\n    if (out == null) {\n        throw new java.lang.IllegalArgumentException(\"OutputStream must not be null.\");\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.AR.equalsIgnoreCase(archiverName)) {\n        return new org.apache.commons.compress.archivers.ar.ArArchiveOutputStream(out);\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.ZIP.equalsIgnoreCase(archiverName)) {\n        org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream zip = new org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream(out);\n        if (entryEncoding != null) {\n            zip.setEncoding(entryEncoding);\n        }\n        return zip;\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.TAR.equalsIgnoreCase(archiverName)) {\n        if (entryEncoding != null) {\n            return new org.apache.commons.compress.archivers.tar.TarArchiveOutputStream(out, entryEncoding);\n        } else {\n            return new org.apache.commons.compress.archivers.tar.TarArchiveOutputStream(out);\n        }\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)) {\n        if (entryEncoding != null) {\n            return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out, entryEncoding);\n        } else {\n            return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n        }\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.CPIO.equalsIgnoreCase(archiverName)) {\n        if (entryEncoding != null) {\n            return new org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream(out, entryEncoding);\n        } else {\n            return new org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream(out);\n        }\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.SEVEN_Z.equalsIgnoreCase(archiverName)) {\n        throw new org.apache.commons.compress.archivers.StreamingNotSupportedException(org.apache.commons.compress.archivers.ArchiveStreamFactory.SEVEN_Z);\n    }\n    throw new org.apache.commons.compress.archivers.ArchiveException((\"Archiver: \" + archiverName) + \" not found.\");\n}",
            "src_parent_type": "Block",
            "src_type": "If"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in, entryEncoding)",
            "src_parent": "{\n    return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in, entryEncoding);\n}",
            "src_parent_type": "Block",
            "src_type": "Return"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "{\n    if (entryEncoding != null) {\n        return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in, entryEncoding);\n    } else {\n        return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in);\n    }\n}",
            "src_parent": "if (org.apache.commons.compress.archivers.arj.ArjArchiveInputStream.matches(signature, signatureLength)) {\n    if (entryEncoding != null) {\n        return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in, entryEncoding);\n    } else {\n        return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in);\n    }\n} else if (org.apache.commons.compress.archivers.sevenz.SevenZFile.matches(signature, signatureLength)) {\n    throw new org.apache.commons.compress.archivers.StreamingNotSupportedException(org.apache.commons.compress.archivers.ArchiveStreamFactory.SEVEN_Z);\n}",
            "src_parent_type": "If",
            "src_type": "Block"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "true",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Method",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "INS",
            "src": "if (org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)) {\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n}",
            "src_parent": "{\n    if (archiverName == null) {\n        throw new java.lang.IllegalArgumentException(\"Archivername must not be null.\");\n    }\n    if (out == null) {\n        throw new java.lang.IllegalArgumentException(\"OutputStream must not be null.\");\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.AR.equalsIgnoreCase(archiverName)) {\n        return new org.apache.commons.compress.archivers.ar.ArArchiveOutputStream(out);\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.ZIP.equalsIgnoreCase(archiverName)) {\n        org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream zip = new org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream(out);\n        if (entryEncoding != null) {\n            zip.setEncoding(entryEncoding);\n        }\n        return zip;\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.TAR.equalsIgnoreCase(archiverName)) {\n        if (entryEncoding != null) {\n            return new org.apache.commons.compress.archivers.tar.TarArchiveOutputStream(out, entryEncoding);\n        } else {\n            return new org.apache.commons.compress.archivers.tar.TarArchiveOutputStream(out);\n        }\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)) {\n        return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.CPIO.equalsIgnoreCase(archiverName)) {\n        if (entryEncoding != null) {\n            return new org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream(out, entryEncoding);\n        } else {\n            return new org.apache.commons.compress.archivers.cpio.CpioArchiveOutputStream(out);\n        }\n    }\n    if (org.apache.commons.compress.archivers.ArchiveStreamFactory.SEVEN_Z.equalsIgnoreCase(archiverName)) {\n        throw new org.apache.commons.compress.archivers.StreamingNotSupportedException(org.apache.commons.compress.archivers.ArchiveStreamFactory.SEVEN_Z);\n    }\n    throw new org.apache.commons.compress.archivers.ArchiveException((\"Archiver: \" + archiverName) + \" not found.\");\n}",
            "src_parent_type": "Block",
            "src_type": "If"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "Throw",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "If",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "If",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Method",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)",
            "dst_parent": "if (org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)) {\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n}",
            "dst_parent_type": "If",
            "dst_type": "Invocation",
            "operator": "MOV",
            "src": "org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)",
            "src_parent": "if (org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)) {\n    if (entryEncoding != null) {\n        return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out, entryEncoding);\n    } else {\n        return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n    }\n}",
            "src_parent_type": "If",
            "src_type": "Invocation"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "{\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n}",
            "dst_parent": "if (org.apache.commons.compress.archivers.ArchiveStreamFactory.JAR.equalsIgnoreCase(archiverName)) {\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n}",
            "dst_parent_type": "If",
            "dst_type": "Block",
            "operator": "MOV",
            "src": "{\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out, entryEncoding);\n}",
            "src_parent": "if (entryEncoding != null) {\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out, entryEncoding);\n} else {\n    return new org.apache.commons.compress.archivers.jar.JarArchiveOutputStream(out);\n}",
            "src_parent_type": "If",
            "src_type": "Block"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "If",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "If",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "{\n    return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in);\n}",
            "dst_parent": "if (org.apache.commons.compress.archivers.arj.ArjArchiveInputStream.matches(signature, signatureLength)) {\n    return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in);\n} else if (org.apache.commons.compress.archivers.sevenz.SevenZFile.matches(signature, signatureLength)) {\n    throw new org.apache.commons.compress.archivers.StreamingNotSupportedException(org.apache.commons.compress.archivers.ArchiveStreamFactory.SEVEN_Z);\n}",
            "dst_parent_type": "If",
            "dst_type": "Block",
            "operator": "MOV",
            "src": "{\n    return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in, entryEncoding);\n}",
            "src_parent": "if (entryEncoding != null) {\n    return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in, entryEncoding);\n} else {\n    return new org.apache.commons.compress.archivers.arj.ArjArchiveInputStream(in);\n}",
            "src_parent_type": "If",
            "src_type": "Block"
          }
        }
      ],
      "file_name": "ArchiveStreamFactory"
    },
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Field",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "final java.lang.String encoding;",
            "src_parent": "public class CpioArchiveOutputStream extends org.apache.commons.compress.archivers.ArchiveOutputStream implements org.apache.commons.compress.archivers.cpio.CpioConstants {\n    private org.apache.commons.compress.archivers.cpio.CpioArchiveEntry entry;\n\n    private boolean closed = false;\n\n    private boolean finished;\n\n    private final short entryFormat;\n\n    private final java.util.HashMap<java.lang.String, org.apache.commons.compress.archivers.cpio.CpioArchiveEntry> names = new java.util.HashMap<java.lang.String, org.apache.commons.compress.archivers.cpio.CpioArchiveEntry>();\n\n    private long crc = 0;\n\n    private long written;\n\n    private final java.io.OutputStream out;\n\n    private final int blockSize;\n\n    private long nextArtificalDeviceAndInode = 1;\n\n    private final org.apache.commons.compress.archivers.zip.ZipEncoding zipEncoding;\n\n    final java.lang.String encoding;\n\n    public CpioArchiveOutputStream(final java.io.OutputStream out, final short format) {\n        this(out, format, org.apache.commons.compress.archivers.cpio.CpioConstants.BLOCK_SIZE, org.apache.commons.compress.utils.CharsetNames.US_ASCII);\n    }\n\n    public CpioArchiveOutputStream(final java.io.OutputStream out, final short format, final int blockSize) {\n        this(out, format, blockSize, org.apache.commons.compress.utils.CharsetNames.US_ASCII);\n    }\n\n    public CpioArchiveOutputStream(final java.io.OutputStream out, final short format, final int blockSize, final java.lang.String encoding) {\n        this.out = out;\n        switch (format) {\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW :\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC :\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_ASCII :\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_BINARY :\n                break;\n            default :\n                throw new java.lang.IllegalArgumentException(\"Unknown format: \" + format);\n        }\n        this.entryFormat = format;\n        this.blockSize = blockSize;\n        this.encoding = encoding;\n        this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n    }\n\n    public CpioArchiveOutputStream(final java.io.OutputStream out) {\n        this(out, org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW);\n    }\n\n    public CpioArchiveOutputStream(final java.io.OutputStream out, java.lang.String encoding) {\n        this(out, org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW, org.apache.commons.compress.archivers.cpio.CpioConstants.BLOCK_SIZE, encoding);\n    }\n\n    private void ensureOpen() throws java.io.IOException {\n        if (this.closed) {\n            throw new java.io.IOException(\"Stream closed\");\n        }\n    }\n\n    @java.lang.Override\n    public void putArchiveEntry(org.apache.commons.compress.archivers.ArchiveEntry entry) throws java.io.IOException {\n        if (finished) {\n            throw new java.io.IOException(\"Stream has already been finished\");\n        }\n        org.apache.commons.compress.archivers.cpio.CpioArchiveEntry e = ((org.apache.commons.compress.archivers.cpio.CpioArchiveEntry) (entry));\n        ensureOpen();\n        if (this.entry != null) {\n            closeArchiveEntry();\n        }\n        if (e.getTime() == (-1)) {\n            e.setTime(java.lang.System.currentTimeMillis() / 1000);\n        }\n        final short format = e.getFormat();\n        if (format != this.entryFormat) {\n            throw new java.io.IOException(((\"Header format: \" + format) + \" does not match existing format: \") + this.entryFormat);\n        }\n        if (this.names.put(e.getName(), e) != null) {\n            throw new java.io.IOException(\"duplicate entry: \" + e.getName());\n        }\n        writeHeader(e);\n        this.entry = e;\n        this.written = 0;\n    }\n\n    private void writeHeader(final org.apache.commons.compress.archivers.cpio.CpioArchiveEntry e) throws java.io.IOException {\n        switch (e.getFormat()) {\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW :\n                out.write(org.apache.commons.compress.utils.ArchiveUtils.toAsciiBytes(org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_NEW));\n                count(6);\n                writeNewEntry(e);\n                break;\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC :\n                out.write(org.apache.commons.compress.utils.ArchiveUtils.toAsciiBytes(org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_NEW_CRC));\n                count(6);\n                writeNewEntry(e);\n                break;\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_ASCII :\n                out.write(org.apache.commons.compress.utils.ArchiveUtils.toAsciiBytes(org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_OLD_ASCII));\n                count(6);\n                writeOldAsciiEntry(e);\n                break;\n            case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_BINARY :\n                boolean swapHalfWord = true;\n                writeBinaryLong(org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_OLD_BINARY, 2, swapHalfWord);\n                writeOldBinaryEntry(e, swapHalfWord);\n                break;\n            default :\n                throw new java.io.IOException(\"unknown format \" + e.getFormat());\n        }\n    }\n\n    private void writeNewEntry(final org.apache.commons.compress.archivers.cpio.CpioArchiveEntry entry) throws java.io.IOException {\n        long inode = entry.getInode();\n        long devMin = entry.getDeviceMin();\n        if (org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER.equals(entry.getName())) {\n            inode = devMin = 0;\n        } else if ((inode == 0) && (devMin == 0)) {\n            inode = nextArtificalDeviceAndInode & 0xffffffff;\n            devMin = ((nextArtificalDeviceAndInode++) >> 32) & 0xffffffff;\n        } else {\n            nextArtificalDeviceAndInode = java.lang.Math.max(nextArtificalDeviceAndInode, inode + (0x100000000L * devMin)) + 1;\n        }\n        writeAsciiLong(inode, 8, 16);\n        writeAsciiLong(entry.getMode(), 8, 16);\n        writeAsciiLong(entry.getUID(), 8, 16);\n        writeAsciiLong(entry.getGID(), 8, 16);\n        writeAsciiLong(entry.getNumberOfLinks(), 8, 16);\n        writeAsciiLong(entry.getTime(), 8, 16);\n        writeAsciiLong(entry.getSize(), 8, 16);\n        writeAsciiLong(entry.getDeviceMaj(), 8, 16);\n        writeAsciiLong(devMin, 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMaj(), 8, 16);\n        writeAsciiLong(entry.getRemoteDeviceMin(), 8, 16);\n        writeAsciiLong(entry.getName().length() + 1, 8, 16);\n        writeAsciiLong(entry.getChksum(), 8, 16);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    private void writeOldAsciiEntry(final org.apache.commons.compress.archivers.cpio.CpioArchiveEntry entry) throws java.io.IOException {\n        long inode = entry.getInode();\n        long device = entry.getDevice();\n        if (org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER.equals(entry.getName())) {\n            inode = device = 0;\n        } else if ((inode == 0) && (device == 0)) {\n            inode = nextArtificalDeviceAndInode & 0777777;\n            device = ((nextArtificalDeviceAndInode++) >> 18) & 0777777;\n        } else {\n            nextArtificalDeviceAndInode = java.lang.Math.max(nextArtificalDeviceAndInode, inode + (01000000 * device)) + 1;\n        }\n        writeAsciiLong(device, 6, 8);\n        writeAsciiLong(inode, 6, 8);\n        writeAsciiLong(entry.getMode(), 6, 8);\n        writeAsciiLong(entry.getUID(), 6, 8);\n        writeAsciiLong(entry.getGID(), 6, 8);\n        writeAsciiLong(entry.getNumberOfLinks(), 6, 8);\n        writeAsciiLong(entry.getRemoteDevice(), 6, 8);\n        writeAsciiLong(entry.getTime(), 11, 8);\n        writeAsciiLong(entry.getName().length() + 1, 6, 8);\n        writeAsciiLong(entry.getSize(), 11, 8);\n        writeCString(entry.getName());\n    }\n\n    private void writeOldBinaryEntry(final org.apache.commons.compress.archivers.cpio.CpioArchiveEntry entry, final boolean swapHalfWord) throws java.io.IOException {\n        long inode = entry.getInode();\n        long device = entry.getDevice();\n        if (org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER.equals(entry.getName())) {\n            inode = device = 0;\n        } else if ((inode == 0) && (device == 0)) {\n            inode = nextArtificalDeviceAndInode & 0xffff;\n            device = ((nextArtificalDeviceAndInode++) >> 16) & 0xffff;\n        } else {\n            nextArtificalDeviceAndInode = java.lang.Math.max(nextArtificalDeviceAndInode, inode + (0x10000 * device)) + 1;\n        }\n        writeBinaryLong(device, 2, swapHalfWord);\n        writeBinaryLong(inode, 2, swapHalfWord);\n        writeBinaryLong(entry.getMode(), 2, swapHalfWord);\n        writeBinaryLong(entry.getUID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getGID(), 2, swapHalfWord);\n        writeBinaryLong(entry.getNumberOfLinks(), 2, swapHalfWord);\n        writeBinaryLong(entry.getRemoteDevice(), 2, swapHalfWord);\n        writeBinaryLong(entry.getTime(), 4, swapHalfWord);\n        writeBinaryLong(entry.getName().length() + 1, 2, swapHalfWord);\n        writeBinaryLong(entry.getSize(), 4, swapHalfWord);\n        writeCString(entry.getName());\n        pad(entry.getHeaderPadCount());\n    }\n\n    @java.lang.Override\n    public void closeArchiveEntry() throws java.io.IOException {\n        if (finished) {\n            throw new java.io.IOException(\"Stream has already been finished\");\n        }\n        ensureOpen();\n        if (entry == null) {\n            throw new java.io.IOException(\"Trying to close non-existent entry\");\n        }\n        if (this.entry.getSize() != this.written) {\n            throw new java.io.IOException((((\"invalid entry size (expected \" + this.entry.getSize()) + \" but got \") + this.written) + \" bytes)\");\n        }\n        pad(this.entry.getDataPadCount());\n        if ((this.entry.getFormat() == org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC) && (this.crc != this.entry.getChksum())) {\n            throw new java.io.IOException(\"CRC Error\");\n        }\n        this.entry = null;\n        this.crc = 0;\n        this.written = 0;\n    }\n\n    @java.lang.Override\n    public void write(final byte[] b, final int off, final int len) throws java.io.IOException {\n        ensureOpen();\n        if (((off < 0) || (len < 0)) || (off > (b.length - len))) {\n            throw new java.lang.IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return;\n        }\n        if (this.entry == null) {\n            throw new java.io.IOException(\"no current CPIO entry\");\n        }\n        if ((this.written + len) > this.entry.getSize()) {\n            throw new java.io.IOException(\"attempt to write past end of STORED entry\");\n        }\n        out.write(b, off, len);\n        this.written += len;\n        if (this.entry.getFormat() == org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < len; pos++) {\n                this.crc += b[pos] & 0xff;\n            }\n        }\n        count(len);\n    }\n\n    @java.lang.Override\n    public void finish() throws java.io.IOException {\n        ensureOpen();\n        if (finished) {\n            throw new java.io.IOException(\"This archive has already been finished\");\n        }\n        if (this.entry != null) {\n            throw new java.io.IOException(\"This archive contains unclosed entries.\");\n        }\n        this.entry = new org.apache.commons.compress.archivers.cpio.CpioArchiveEntry(this.entryFormat);\n        this.entry.setName(org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER);\n        this.entry.setNumberOfLinks(1);\n        writeHeader(this.entry);\n        closeArchiveEntry();\n        int lengthOfLastBlock = ((int) (getBytesWritten() % blockSize));\n        if (lengthOfLastBlock != 0) {\n            pad(blockSize - lengthOfLastBlock);\n        }\n        finished = true;\n    }\n\n    @java.lang.Override\n    public void close() throws java.io.IOException {\n        if (!finished) {\n            finish();\n        }\n        if (!this.closed) {\n            out.close();\n            this.closed = true;\n        }\n    }\n\n    private void pad(int count) throws java.io.IOException {\n        if (count > 0) {\n            byte[] buff = new byte[count];\n            out.write(buff);\n            count(count);\n        }\n    }\n\n    private void writeBinaryLong(final long number, final int length, final boolean swapHalfWord) throws java.io.IOException {\n        byte[] tmp = org.apache.commons.compress.archivers.cpio.CpioUtil.long2byteArray(number, length, swapHalfWord);\n        out.write(tmp);\n        count(tmp.length);\n    }\n\n    private void writeAsciiLong(final long number, final int length, final int radix) throws java.io.IOException {\n        java.lang.StringBuilder tmp = new java.lang.StringBuilder();\n        java.lang.String tmpStr;\n        if (radix == 16) {\n            tmp.append(java.lang.Long.toHexString(number));\n        } else if (radix == 8) {\n            tmp.append(java.lang.Long.toOctalString(number));\n        } else {\n            tmp.append(java.lang.Long.toString(number));\n        }\n        if (tmp.length() <= length) {\n            long insertLength = length - tmp.length();\n            for (int pos = 0; pos < insertLength; pos++) {\n                tmp.insert(0, \"0\");\n            }\n            tmpStr = tmp.toString();\n        } else {\n            tmpStr = tmp.substring(tmp.length() - length);\n        }\n        byte[] b = org.apache.commons.compress.utils.ArchiveUtils.toAsciiBytes(tmpStr);\n        out.write(b);\n        count(b.length);\n    }\n\n    private void writeCString(final java.lang.String str) throws java.io.IOException {\n        java.nio.ByteBuffer buf = zipEncoding.encode(str);\n        final int len = buf.limit() - buf.position();\n        out.write(buf.array(), buf.arrayOffset(), len);\n        out.write('\\u0000');\n        count(len + 1);\n    }\n\n    @java.lang.Override\n    public org.apache.commons.compress.archivers.ArchiveEntry createArchiveEntry(java.io.File inputFile, java.lang.String entryName) throws java.io.IOException {\n        if (finished) {\n            throw new java.io.IOException(\"Stream has already been finished\");\n        }\n        return new org.apache.commons.compress.archivers.cpio.CpioArchiveEntry(inputFile, entryName);\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "Switch",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Constructor",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Assignment",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "this.encoding = encoding",
            "src_parent": "{\n    this.out = out;\n    switch (format) {\n        case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW :\n        case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC :\n        case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_ASCII :\n        case org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_BINARY :\n            break;\n        default :\n            throw new java.lang.IllegalArgumentException(\"Unknown format: \" + format);\n    }\n    this.entryFormat = format;\n    this.blockSize = blockSize;\n    this.encoding = encoding;\n    this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n}",
            "src_parent_type": "Block",
            "src_type": "Assignment"
          }
        }
      ],
      "file_name": "CpioArchiveOutputStream"
    },
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Field",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "final java.lang.String encoding;",
            "src_parent": "public class ZipArchiveInputStream extends org.apache.commons.compress.archivers.ArchiveInputStream {\n    private final org.apache.commons.compress.archivers.zip.ZipEncoding zipEncoding;\n\n    final java.lang.String encoding;\n\n    private final boolean useUnicodeExtraFields;\n\n    private final java.io.InputStream in;\n\n    private final java.util.zip.Inflater inf = new java.util.zip.Inflater(true);\n\n    private final java.nio.ByteBuffer buf = java.nio.ByteBuffer.allocate(org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.BUFFER_SIZE);\n\n    private org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.CurrentEntry current = null;\n\n    private boolean closed = false;\n\n    private boolean hitCentralDirectory = false;\n\n    private java.io.ByteArrayInputStream lastStoredEntry = null;\n\n    private boolean allowStoredEntriesWithDataDescriptor = false;\n\n    private static final int LFH_LEN = 30;\n\n    private static final int CFH_LEN = 46;\n\n    private static final long TWO_EXP_32 = org.apache.commons.compress.archivers.zip.ZipConstants.ZIP64_MAGIC + 1;\n\n    private final byte[] LFH_BUF = new byte[org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH_LEN];\n\n    private final byte[] SKIP_BUF = new byte[1024];\n\n    private final byte[] SHORT_BUF = new byte[org.apache.commons.compress.archivers.zip.ZipConstants.SHORT];\n\n    private final byte[] WORD_BUF = new byte[org.apache.commons.compress.archivers.zip.ZipConstants.WORD];\n\n    private final byte[] TWO_DWORD_BUF = new byte[2 * org.apache.commons.compress.archivers.zip.ZipConstants.DWORD];\n\n    private int entriesRead = 0;\n\n    public ZipArchiveInputStream(java.io.InputStream inputStream) {\n        this(inputStream, org.apache.commons.compress.archivers.zip.ZipEncodingHelper.UTF8);\n    }\n\n    public ZipArchiveInputStream(java.io.InputStream inputStream, java.lang.String encoding) {\n        this(inputStream, encoding, true);\n    }\n\n    public ZipArchiveInputStream(java.io.InputStream inputStream, java.lang.String encoding, boolean useUnicodeExtraFields) {\n        this(inputStream, encoding, useUnicodeExtraFields, false);\n    }\n\n    public ZipArchiveInputStream(java.io.InputStream inputStream, java.lang.String encoding, boolean useUnicodeExtraFields, boolean allowStoredEntriesWithDataDescriptor) {\n        this.encoding = encoding;\n        zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n        this.useUnicodeExtraFields = useUnicodeExtraFields;\n        in = new java.io.PushbackInputStream(inputStream, buf.capacity());\n        this.allowStoredEntriesWithDataDescriptor = allowStoredEntriesWithDataDescriptor;\n        buf.limit(0);\n    }\n\n    public org.apache.commons.compress.archivers.zip.ZipArchiveEntry getNextZipEntry() throws java.io.IOException {\n        boolean firstEntry = true;\n        if (closed || hitCentralDirectory) {\n            return null;\n        }\n        if (current != null) {\n            closeEntry();\n            firstEntry = false;\n        }\n        try {\n            if (firstEntry) {\n                readFirstLocalFileHeader(LFH_BUF);\n            } else {\n                readFully(LFH_BUF);\n            }\n        } catch (java.io.EOFException e) {\n            return null;\n        }\n        org.apache.commons.compress.archivers.zip.ZipLong sig = new org.apache.commons.compress.archivers.zip.ZipLong(LFH_BUF);\n        if (sig.equals(org.apache.commons.compress.archivers.zip.ZipLong.CFH_SIG) || sig.equals(org.apache.commons.compress.archivers.zip.ZipLong.AED_SIG)) {\n            hitCentralDirectory = true;\n            skipRemainderOfArchive();\n        }\n        if (!sig.equals(org.apache.commons.compress.archivers.zip.ZipLong.LFH_SIG)) {\n            return null;\n        }\n        int off = org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n        current = new org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.CurrentEntry();\n        int versionMadeBy = org.apache.commons.compress.archivers.zip.ZipShort.getValue(LFH_BUF, off);\n        off += org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\n        current.entry.setPlatform((versionMadeBy >> org.apache.commons.compress.archivers.zip.ZipFile.BYTE_SHIFT) & org.apache.commons.compress.archivers.zip.ZipFile.NIBLET_MASK);\n        final org.apache.commons.compress.archivers.zip.GeneralPurposeBit gpFlag = org.apache.commons.compress.archivers.zip.GeneralPurposeBit.parse(LFH_BUF, off);\n        final boolean hasUTF8Flag = gpFlag.usesUTF8ForNames();\n        final org.apache.commons.compress.archivers.zip.ZipEncoding entryEncoding = (hasUTF8Flag) ? org.apache.commons.compress.archivers.zip.ZipEncodingHelper.UTF8_ZIP_ENCODING : zipEncoding;\n        current.hasDataDescriptor = gpFlag.usesDataDescriptor();\n        current.entry.setGeneralPurposeBit(gpFlag);\n        off += org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\n        current.entry.setMethod(org.apache.commons.compress.archivers.zip.ZipShort.getValue(LFH_BUF, off));\n        off += org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\n        long time = org.apache.commons.compress.archivers.zip.ZipUtil.dosToJavaTime(org.apache.commons.compress.archivers.zip.ZipLong.getValue(LFH_BUF, off));\n        current.entry.setTime(time);\n        off += org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n        org.apache.commons.compress.archivers.zip.ZipLong size = null;\n        org.apache.commons.compress.archivers.zip.ZipLong cSize = null;\n        if (!current.hasDataDescriptor) {\n            current.entry.setCrc(org.apache.commons.compress.archivers.zip.ZipLong.getValue(LFH_BUF, off));\n            off += org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n            cSize = new org.apache.commons.compress.archivers.zip.ZipLong(LFH_BUF, off);\n            off += org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n            size = new org.apache.commons.compress.archivers.zip.ZipLong(LFH_BUF, off);\n            off += org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n        } else {\n            off += 3 * org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n        }\n        int fileNameLen = org.apache.commons.compress.archivers.zip.ZipShort.getValue(LFH_BUF, off);\n        off += org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\n        int extraLen = org.apache.commons.compress.archivers.zip.ZipShort.getValue(LFH_BUF, off);\n        off += org.apache.commons.compress.archivers.zip.ZipConstants.SHORT;\n        byte[] fileName = new byte[fileNameLen];\n        readFully(fileName);\n        current.entry.setName(entryEncoding.decode(fileName), fileName);\n        byte[] extraData = new byte[extraLen];\n        readFully(extraData);\n        current.entry.setExtra(extraData);\n        if ((!hasUTF8Flag) && useUnicodeExtraFields) {\n            org.apache.commons.compress.archivers.zip.ZipUtil.setNameAndCommentFromExtraFields(current.entry, fileName, null);\n        }\n        processZip64Extra(size, cSize);\n        if (current.entry.getCompressedSize() != org.apache.commons.compress.archivers.zip.ZipArchiveEntry.SIZE_UNKNOWN) {\n            if (current.entry.getMethod() == org.apache.commons.compress.archivers.zip.ZipMethod.UNSHRINKING.getCode()) {\n                current.in = new org.apache.commons.compress.archivers.zip.UnshrinkingInputStream(new org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.BoundedInputStream(in, current.entry.getCompressedSize()));\n            } else if (current.entry.getMethod() == org.apache.commons.compress.archivers.zip.ZipMethod.IMPLODING.getCode()) {\n                current.in = new org.apache.commons.compress.archivers.zip.ExplodingInputStream(current.entry.getGeneralPurposeBit().getSlidingDictionarySize(), current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(), new org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.BoundedInputStream(in, current.entry.getCompressedSize()));\n            }\n        }\n        entriesRead++;\n        return current.entry;\n    }\n\n    private void readFirstLocalFileHeader(byte[] lfh) throws java.io.IOException {\n        readFully(lfh);\n        org.apache.commons.compress.archivers.zip.ZipLong sig = new org.apache.commons.compress.archivers.zip.ZipLong(lfh);\n        if (sig.equals(org.apache.commons.compress.archivers.zip.ZipLong.DD_SIG)) {\n            throw new org.apache.commons.compress.archivers.zip.UnsupportedZipFeatureException(org.apache.commons.compress.archivers.zip.UnsupportedZipFeatureException.Feature.SPLITTING);\n        }\n        if (sig.equals(org.apache.commons.compress.archivers.zip.ZipLong.SINGLE_SEGMENT_SPLIT_MARKER)) {\n            byte[] missedLfhBytes = new byte[4];\n            readFully(missedLfhBytes);\n            java.lang.System.arraycopy(lfh, 4, lfh, 0, org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH_LEN - 4);\n            java.lang.System.arraycopy(missedLfhBytes, 0, lfh, org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH_LEN - 4, 4);\n        }\n    }\n\n    private void processZip64Extra(org.apache.commons.compress.archivers.zip.ZipLong size, org.apache.commons.compress.archivers.zip.ZipLong cSize) {\n        org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField z64 = ((org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField) (current.entry.getExtraField(org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField.HEADER_ID)));\n        current.usesZip64 = z64 != null;\n        if (!current.hasDataDescriptor) {\n            if ((z64 != null) && (cSize.equals(org.apache.commons.compress.archivers.zip.ZipLong.ZIP64_MAGIC) || size.equals(org.apache.commons.compress.archivers.zip.ZipLong.ZIP64_MAGIC))) {\n                current.entry.setCompressedSize(z64.getCompressedSize().getLongValue());\n                current.entry.setSize(z64.getSize().getLongValue());\n            } else {\n                current.entry.setCompressedSize(cSize.getValue());\n                current.entry.setSize(size.getValue());\n            }\n        }\n    }\n\n    @java.lang.Override\n    public org.apache.commons.compress.archivers.ArchiveEntry getNextEntry() throws java.io.IOException {\n        return getNextZipEntry();\n    }\n\n    @java.lang.Override\n    public boolean canReadEntryData(org.apache.commons.compress.archivers.ArchiveEntry ae) {\n        if (ae instanceof org.apache.commons.compress.archivers.zip.ZipArchiveEntry) {\n            org.apache.commons.compress.archivers.zip.ZipArchiveEntry ze = ((org.apache.commons.compress.archivers.zip.ZipArchiveEntry) (ae));\n            return org.apache.commons.compress.archivers.zip.ZipUtil.canHandleEntryData(ze) && supportsDataDescriptorFor(ze);\n        }\n        return false;\n    }\n\n    @java.lang.Override\n    public int read(byte[] buffer, int offset, int length) throws java.io.IOException {\n        if (closed) {\n            throw new java.io.IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return -1;\n        }\n        if ((((offset > buffer.length) || (length < 0)) || (offset < 0)) || ((buffer.length - offset) < length)) {\n            throw new java.lang.ArrayIndexOutOfBoundsException();\n        }\n        org.apache.commons.compress.archivers.zip.ZipUtil.checkRequestedFeatures(current.entry);\n        if (!supportsDataDescriptorFor(current.entry)) {\n            throw new org.apache.commons.compress.archivers.zip.UnsupportedZipFeatureException(org.apache.commons.compress.archivers.zip.UnsupportedZipFeatureException.Feature.DATA_DESCRIPTOR, current.entry);\n        }\n        int read;\n        if (current.entry.getMethod() == org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.STORED) {\n            read = readStored(buffer, offset, length);\n        } else if (current.entry.getMethod() == org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.DEFLATED) {\n            read = readDeflated(buffer, offset, length);\n        } else if ((current.entry.getMethod() == org.apache.commons.compress.archivers.zip.ZipMethod.UNSHRINKING.getCode()) || (current.entry.getMethod() == org.apache.commons.compress.archivers.zip.ZipMethod.IMPLODING.getCode())) {\n            read = current.in.read(buffer, offset, length);\n        } else {\n            throw new org.apache.commons.compress.archivers.zip.UnsupportedZipFeatureException(org.apache.commons.compress.archivers.zip.ZipMethod.getMethodByCode(current.entry.getMethod()), current.entry);\n        }\n        if (read >= 0) {\n            current.crc.update(buffer, offset, read);\n        }\n        return read;\n    }\n\n    private int readStored(byte[] buffer, int offset, int length) throws java.io.IOException {\n        if (current.hasDataDescriptor) {\n            if (lastStoredEntry == null) {\n                readStoredEntry();\n            }\n            return lastStoredEntry.read(buffer, offset, length);\n        }\n        long csize = current.entry.getSize();\n        if (current.bytesRead >= csize) {\n            return -1;\n        }\n        if (buf.position() >= buf.limit()) {\n            buf.position(0);\n            int l = in.read(buf.array());\n            if (l == (-1)) {\n                return -1;\n            }\n            buf.limit(l);\n            count(l);\n            current.bytesReadFromStream += l;\n        }\n        int toRead = java.lang.Math.min(buf.remaining(), length);\n        if ((csize - current.bytesRead) < toRead) {\n            toRead = ((int) (csize - current.bytesRead));\n        }\n        buf.get(buffer, offset, toRead);\n        current.bytesRead += toRead;\n        return toRead;\n    }\n\n    private int readDeflated(byte[] buffer, int offset, int length) throws java.io.IOException {\n        int read = readFromInflater(buffer, offset, length);\n        if (read <= 0) {\n            if (inf.finished()) {\n                return -1;\n            } else if (inf.needsDictionary()) {\n                throw new java.util.zip.ZipException(\"This archive needs a preset dictionary\" + (\" which is not supported by Commons\" + \" Compress.\"));\n            } else if (read == (-1)) {\n                throw new java.io.IOException(\"Truncated ZIP file\");\n            }\n        }\n        return read;\n    }\n\n    private int readFromInflater(byte[] buffer, int offset, int length) throws java.io.IOException {\n        int read = 0;\n        do {\n            if (inf.needsInput()) {\n                int l = fill();\n                if (l > 0) {\n                    current.bytesReadFromStream += buf.limit();\n                } else if (l == (-1)) {\n                    return -1;\n                } else {\n                    break;\n                }\n            }\n            try {\n                read = inf.inflate(buffer, offset, length);\n            } catch (java.util.zip.DataFormatException e) {\n                throw ((java.io.IOException) (new java.util.zip.ZipException(e.getMessage()).initCause(e)));\n            }\n        } while ((read == 0) && inf.needsInput() );\n        return read;\n    }\n\n    @java.lang.Override\n    public void close() throws java.io.IOException {\n        if (!closed) {\n            closed = true;\n            in.close();\n            inf.end();\n        }\n    }\n\n    @java.lang.Override\n    public long skip(long value) throws java.io.IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = read(SKIP_BUF, 0, ((int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length)));\n                if (x == (-1)) {\n                    return skipped;\n                }\n                skipped += x;\n            } \n            return skipped;\n        }\n        throw new java.lang.IllegalArgumentException();\n    }\n\n    public static boolean matches(byte[] signature, int length) {\n        if (length < org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.LFH_SIG.length) {\n            return false;\n        }\n        return ((org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.checksig(signature, org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.LFH_SIG) || org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.checksig(signature, org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.EOCD_SIG)) || org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.checksig(signature, org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.DD_SIG)) || org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.checksig(signature, org.apache.commons.compress.archivers.zip.ZipLong.SINGLE_SEGMENT_SPLIT_MARKER.getBytes());\n    }\n\n    private static boolean checksig(byte[] signature, byte[] expected) {\n        for (int i = 0; i < expected.length; i++) {\n            if (signature[i] != expected[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    private void closeEntry() throws java.io.IOException {\n        if (closed) {\n            throw new java.io.IOException(\"The stream is closed\");\n        }\n        if (current == null) {\n            return;\n        }\n        if ((current.bytesReadFromStream <= current.entry.getCompressedSize()) && (!current.hasDataDescriptor)) {\n            drainCurrentEntryData();\n        } else {\n            skip(java.lang.Long.MAX_VALUE);\n            long inB = (current.entry.getMethod() == org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.DEFLATED) ? getBytesInflated() : current.bytesRead;\n            int diff = ((int) (current.bytesReadFromStream - inB));\n            if (diff > 0) {\n                pushback(buf.array(), buf.limit() - diff, diff);\n            }\n        }\n        if ((lastStoredEntry == null) && current.hasDataDescriptor) {\n            readDataDescriptor();\n        }\n        inf.reset();\n        buf.clear().flip();\n        current = null;\n        lastStoredEntry = null;\n    }\n\n    private void drainCurrentEntryData() throws java.io.IOException {\n        long remaining = current.entry.getCompressedSize() - current.bytesReadFromStream;\n        while (remaining > 0) {\n            long n = in.read(buf.array(), 0, ((int) (java.lang.Math.min(buf.capacity(), remaining))));\n            if (n < 0) {\n                throw new java.io.EOFException(\"Truncated ZIP entry: \" + current.entry.getName());\n            } else {\n                count(n);\n                remaining -= n;\n            }\n        } \n    }\n\n    private long getBytesInflated() {\n        long inB = inf.getBytesRead();\n        if (current.bytesReadFromStream >= org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.TWO_EXP_32) {\n            while ((inB + org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.TWO_EXP_32) <= current.bytesReadFromStream) {\n                inB += org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.TWO_EXP_32;\n            } \n        }\n        return inB;\n    }\n\n    private int fill() throws java.io.IOException {\n        if (closed) {\n            throw new java.io.IOException(\"The stream is closed\");\n        }\n        int length = in.read(buf.array());\n        if (length > 0) {\n            buf.limit(length);\n            count(buf.limit());\n            inf.setInput(buf.array(), 0, buf.limit());\n        }\n        return length;\n    }\n\n    private void readFully(byte[] b) throws java.io.IOException {\n        int count = org.apache.commons.compress.utils.IOUtils.readFully(in, b);\n        count(count);\n        if (count < b.length) {\n            throw new java.io.EOFException();\n        }\n    }\n\n    private void readDataDescriptor() throws java.io.IOException {\n        readFully(WORD_BUF);\n        org.apache.commons.compress.archivers.zip.ZipLong val = new org.apache.commons.compress.archivers.zip.ZipLong(WORD_BUF);\n        if (org.apache.commons.compress.archivers.zip.ZipLong.DD_SIG.equals(val)) {\n            readFully(WORD_BUF);\n            val = new org.apache.commons.compress.archivers.zip.ZipLong(WORD_BUF);\n        }\n        current.entry.setCrc(val.getValue());\n        readFully(TWO_DWORD_BUF);\n        org.apache.commons.compress.archivers.zip.ZipLong potentialSig = new org.apache.commons.compress.archivers.zip.ZipLong(TWO_DWORD_BUF, org.apache.commons.compress.archivers.zip.ZipConstants.DWORD);\n        if (potentialSig.equals(org.apache.commons.compress.archivers.zip.ZipLong.CFH_SIG) || potentialSig.equals(org.apache.commons.compress.archivers.zip.ZipLong.LFH_SIG)) {\n            pushback(TWO_DWORD_BUF, org.apache.commons.compress.archivers.zip.ZipConstants.DWORD, org.apache.commons.compress.archivers.zip.ZipConstants.DWORD);\n            current.entry.setCompressedSize(org.apache.commons.compress.archivers.zip.ZipLong.getValue(TWO_DWORD_BUF));\n            current.entry.setSize(org.apache.commons.compress.archivers.zip.ZipLong.getValue(TWO_DWORD_BUF, org.apache.commons.compress.archivers.zip.ZipConstants.WORD));\n        } else {\n            current.entry.setCompressedSize(org.apache.commons.compress.archivers.zip.ZipEightByteInteger.getLongValue(TWO_DWORD_BUF));\n            current.entry.setSize(org.apache.commons.compress.archivers.zip.ZipEightByteInteger.getLongValue(TWO_DWORD_BUF, org.apache.commons.compress.archivers.zip.ZipConstants.DWORD));\n        }\n    }\n\n    private boolean supportsDataDescriptorFor(org.apache.commons.compress.archivers.zip.ZipArchiveEntry entry) {\n        return ((!entry.getGeneralPurposeBit().usesDataDescriptor()) || (allowStoredEntriesWithDataDescriptor && (entry.getMethod() == java.util.zip.ZipEntry.STORED))) || (entry.getMethod() == java.util.zip.ZipEntry.DEFLATED);\n    }\n\n    private void readStoredEntry() throws java.io.IOException {\n        java.io.ByteArrayOutputStream bos = new java.io.ByteArrayOutputStream();\n        int off = 0;\n        boolean done = false;\n        int ddLen = (current.usesZip64) ? org.apache.commons.compress.archivers.zip.ZipConstants.WORD + (2 * org.apache.commons.compress.archivers.zip.ZipConstants.DWORD) : 3 * org.apache.commons.compress.archivers.zip.ZipConstants.WORD;\n        while (!done) {\n            int r = in.read(buf.array(), off, org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.BUFFER_SIZE - off);\n            if (r <= 0) {\n                throw new java.io.IOException(\"Truncated ZIP file\");\n            }\n            if ((r + off) < 4) {\n                off += r;\n                continue;\n            }\n            done = bufferContainsSignature(bos, off, r, ddLen);\n            if (!done) {\n                off = cacheBytesRead(bos, off, r, ddLen);\n            }\n        } \n        byte[] b = bos.toByteArray();\n        lastStoredEntry = new java.io.ByteArrayInputStream(b);\n    }\n\n    private static final byte[] LFH = org.apache.commons.compress.archivers.zip.ZipLong.LFH_SIG.getBytes();\n\n    private static final byte[] CFH = org.apache.commons.compress.archivers.zip.ZipLong.CFH_SIG.getBytes();\n\n    private static final byte[] DD = org.apache.commons.compress.archivers.zip.ZipLong.DD_SIG.getBytes();\n\n    private boolean bufferContainsSignature(java.io.ByteArrayOutputStream bos, int offset, int lastRead, int expectedDDLen) throws java.io.IOException {\n        boolean done = false;\n        int readTooMuch = 0;\n        for (int i = 0; (!done) && (i < (lastRead - 4)); i++) {\n            if ((buf.array()[i] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH[0]) && (buf.array()[i + 1] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH[1])) {\n                if (((buf.array()[i + 2] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH[2]) && (buf.array()[i + 3] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH[3])) || ((buf.array()[i] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.CFH[2]) && (buf.array()[i + 3] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.CFH[3]))) {\n                    readTooMuch = ((offset + lastRead) - i) - expectedDDLen;\n                    done = true;\n                } else if ((buf.array()[i + 2] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.DD[2]) && (buf.array()[i + 3] == org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.DD[3])) {\n                    readTooMuch = (offset + lastRead) - i;\n                    done = true;\n                }\n                if (done) {\n                    pushback(buf.array(), (offset + lastRead) - readTooMuch, readTooMuch);\n                    bos.write(buf.array(), 0, i);\n                    readDataDescriptor();\n                }\n            }\n        }\n        return done;\n    }\n\n    private int cacheBytesRead(java.io.ByteArrayOutputStream bos, int offset, int lastRead, int expecteDDLen) {\n        final int cacheable = ((offset + lastRead) - expecteDDLen) - 3;\n        if (cacheable > 0) {\n            bos.write(buf.array(), 0, cacheable);\n            java.lang.System.arraycopy(buf.array(), cacheable, buf.array(), 0, expecteDDLen + 3);\n            offset = expecteDDLen + 3;\n        } else {\n            offset += lastRead;\n        }\n        return offset;\n    }\n\n    private void pushback(byte[] buf, int offset, int length) throws java.io.IOException {\n        ((java.io.PushbackInputStream) (in)).unread(buf, offset, length);\n        pushedBackBytes(length);\n    }\n\n    private void skipRemainderOfArchive() throws java.io.IOException {\n        realSkip((entriesRead * org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.CFH_LEN) - org.apache.commons.compress.archivers.zip.ZipArchiveInputStream.LFH_LEN);\n        findEocdRecord();\n        realSkip((org.apache.commons.compress.archivers.zip.ZipFile.MIN_EOCD_SIZE - org.apache.commons.compress.archivers.zip.ZipConstants.WORD) - org.apache.commons.compress.archivers.zip.ZipConstants.SHORT);\n        readFully(SHORT_BUF);\n        realSkip(org.apache.commons.compress.archivers.zip.ZipShort.getValue(SHORT_BUF));\n    }\n\n    private void findEocdRecord() throws java.io.IOException {\n        int currentByte = -1;\n        boolean skipReadCall = false;\n        while (skipReadCall || ((currentByte = readOneByte()) > (-1))) {\n            skipReadCall = false;\n            if (!isFirstByteOfEocdSig(currentByte)) {\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.EOCD_SIG[1]) {\n                if (currentByte == (-1)) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if (currentByte != org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.EOCD_SIG[2]) {\n                if (currentByte == (-1)) {\n                    break;\n                }\n                skipReadCall = isFirstByteOfEocdSig(currentByte);\n                continue;\n            }\n            currentByte = readOneByte();\n            if ((currentByte == (-1)) || (currentByte == org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.EOCD_SIG[3])) {\n                break;\n            }\n            skipReadCall = isFirstByteOfEocdSig(currentByte);\n        } \n    }\n\n    private void realSkip(long value) throws java.io.IOException {\n        if (value >= 0) {\n            long skipped = 0;\n            while (skipped < value) {\n                long rem = value - skipped;\n                int x = in.read(SKIP_BUF, 0, ((int) (SKIP_BUF.length > rem ? rem : SKIP_BUF.length)));\n                if (x == (-1)) {\n                    return;\n                }\n                count(x);\n                skipped += x;\n            } \n            return;\n        }\n        throw new java.lang.IllegalArgumentException();\n    }\n\n    private int readOneByte() throws java.io.IOException {\n        int b = in.read();\n        if (b != (-1)) {\n            count(1);\n        }\n        return b;\n    }\n\n    private boolean isFirstByteOfEocdSig(int b) {\n        return b == org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream.EOCD_SIG[0];\n    }\n\n    private static final class CurrentEntry {\n        private final org.apache.commons.compress.archivers.zip.ZipArchiveEntry entry = new org.apache.commons.compress.archivers.zip.ZipArchiveEntry();\n\n        private boolean hasDataDescriptor;\n\n        private boolean usesZip64;\n\n        private long bytesRead;\n\n        private long bytesReadFromStream;\n\n        private final java.util.zip.CRC32 crc = new java.util.zip.CRC32();\n\n        private java.io.InputStream in;\n    }\n\n    private class BoundedInputStream extends java.io.InputStream {\n        private final java.io.InputStream in;\n\n        private final long max;\n\n        private long pos = 0;\n\n        public BoundedInputStream(final java.io.InputStream in, final long size) {\n            this.max = size;\n            this.in = in;\n        }\n\n        @java.lang.Override\n        public int read() throws java.io.IOException {\n            if ((max >= 0) && (pos >= max)) {\n                return -1;\n            }\n            final int result = in.read();\n            pos++;\n            count(1);\n            current.bytesReadFromStream++;\n            return result;\n        }\n\n        @java.lang.Override\n        public int read(final byte[] b) throws java.io.IOException {\n            return this.read(b, 0, b.length);\n        }\n\n        @java.lang.Override\n        public int read(final byte[] b, final int off, final int len) throws java.io.IOException {\n            if ((max >= 0) && (pos >= max)) {\n                return -1;\n            }\n            final long maxRead = (max >= 0) ? java.lang.Math.min(len, max - pos) : len;\n            final int bytesRead = in.read(b, off, ((int) (maxRead)));\n            if (bytesRead == (-1)) {\n                return -1;\n            }\n            pos += bytesRead;\n            count(bytesRead);\n            current.bytesReadFromStream += bytesRead;\n            return bytesRead;\n        }\n\n        @java.lang.Override\n        public long skip(final long n) throws java.io.IOException {\n            final long toSkip = (max >= 0) ? java.lang.Math.min(n, max - pos) : n;\n            final long skippedBytes = in.skip(toSkip);\n            pos += skippedBytes;\n            return skippedBytes;\n        }\n\n        @java.lang.Override\n        public int available() throws java.io.IOException {\n            if ((max >= 0) && (pos >= max)) {\n                return 0;\n            }\n            return in.available();\n        }\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "Invocation",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Constructor",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Assignment",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "this.encoding = encoding",
            "src_parent": "{\n    this.encoding = encoding;\n    zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n    this.useUnicodeExtraFields = useUnicodeExtraFields;\n    in = new java.io.PushbackInputStream(inputStream, buf.capacity());\n    this.allowStoredEntriesWithDataDescriptor = allowStoredEntriesWithDataDescriptor;\n    buf.limit(0);\n}",
            "src_parent_type": "Block",
            "src_type": "Assignment"
          }
        }
      ],
      "file_name": "ZipArchiveInputStream"
    },
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Field",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "final java.lang.String encoding;",
            "src_parent": "public class DumpArchiveInputStream extends org.apache.commons.compress.archivers.ArchiveInputStream {\n    private org.apache.commons.compress.archivers.dump.DumpArchiveSummary summary;\n\n    private org.apache.commons.compress.archivers.dump.DumpArchiveEntry active;\n\n    private boolean isClosed;\n\n    private boolean hasHitEOF;\n\n    private long entrySize;\n\n    private long entryOffset;\n\n    private int readIdx;\n\n    private final byte[] readBuf = new byte[org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE];\n\n    private byte[] blockBuffer;\n\n    private int recordOffset;\n\n    private long filepos;\n\n    protected org.apache.commons.compress.archivers.dump.TapeInputStream raw;\n\n    private final java.util.Map<java.lang.Integer, org.apache.commons.compress.archivers.dump.Dirent> names = new java.util.HashMap<java.lang.Integer, org.apache.commons.compress.archivers.dump.Dirent>();\n\n    private final java.util.Map<java.lang.Integer, org.apache.commons.compress.archivers.dump.DumpArchiveEntry> pending = new java.util.HashMap<java.lang.Integer, org.apache.commons.compress.archivers.dump.DumpArchiveEntry>();\n\n    private java.util.Queue<org.apache.commons.compress.archivers.dump.DumpArchiveEntry> queue;\n\n    private final org.apache.commons.compress.archivers.zip.ZipEncoding zipEncoding;\n\n    final java.lang.String encoding;\n\n    public DumpArchiveInputStream(java.io.InputStream is) throws org.apache.commons.compress.archivers.ArchiveException {\n        this(is, null);\n    }\n\n    public DumpArchiveInputStream(java.io.InputStream is, java.lang.String encoding) throws org.apache.commons.compress.archivers.ArchiveException {\n        this.raw = new org.apache.commons.compress.archivers.dump.TapeInputStream(is);\n        this.hasHitEOF = false;\n        this.encoding = encoding;\n        this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n        try {\n            byte[] headerBytes = raw.readRecord();\n            if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(headerBytes)) {\n                throw new org.apache.commons.compress.archivers.dump.UnrecognizedFormatException();\n            }\n            summary = new org.apache.commons.compress.archivers.dump.DumpArchiveSummary(headerBytes, this.zipEncoding);\n            raw.resetBlockSize(summary.getNTRec(), summary.isCompressed());\n            blockBuffer = new byte[4 * org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE];\n            readCLRI();\n            readBITS();\n        } catch (java.io.IOException ex) {\n            throw new org.apache.commons.compress.archivers.ArchiveException(ex.getMessage(), ex);\n        }\n        org.apache.commons.compress.archivers.dump.Dirent root = new org.apache.commons.compress.archivers.dump.Dirent(2, 2, 4, \".\");\n        names.put(2, root);\n        queue = new java.util.PriorityQueue<org.apache.commons.compress.archivers.dump.DumpArchiveEntry>(10, new java.util.Comparator<org.apache.commons.compress.archivers.dump.DumpArchiveEntry>() {\n            public int compare(org.apache.commons.compress.archivers.dump.DumpArchiveEntry p, org.apache.commons.compress.archivers.dump.DumpArchiveEntry q) {\n                if ((p.getOriginalName() == null) || (q.getOriginalName() == null)) {\n                    return java.lang.Integer.MAX_VALUE;\n                }\n                return p.getOriginalName().compareTo(q.getOriginalName());\n            }\n        });\n    }\n\n    @java.lang.Deprecated\n    @java.lang.Override\n    public int getCount() {\n        return ((int) (getBytesRead()));\n    }\n\n    @java.lang.Override\n    public long getBytesRead() {\n        return raw.getBytesRead();\n    }\n\n    public org.apache.commons.compress.archivers.dump.DumpArchiveSummary getSummary() {\n        return summary;\n    }\n\n    private void readCLRI() throws java.io.IOException {\n        byte[] buffer = raw.readRecord();\n        if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(buffer)) {\n            throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n        }\n        active = org.apache.commons.compress.archivers.dump.DumpArchiveEntry.parse(buffer);\n        if (org.apache.commons.compress.archivers.dump.DumpArchiveConstants.SEGMENT_TYPE.CLRI != active.getHeaderType()) {\n            throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n        }\n        if (raw.skip(org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE * active.getHeaderCount()) == (-1)) {\n            throw new java.io.EOFException();\n        }\n        readIdx = active.getHeaderCount();\n    }\n\n    private void readBITS() throws java.io.IOException {\n        byte[] buffer = raw.readRecord();\n        if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(buffer)) {\n            throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n        }\n        active = org.apache.commons.compress.archivers.dump.DumpArchiveEntry.parse(buffer);\n        if (org.apache.commons.compress.archivers.dump.DumpArchiveConstants.SEGMENT_TYPE.BITS != active.getHeaderType()) {\n            throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n        }\n        if (raw.skip(org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE * active.getHeaderCount()) == (-1)) {\n            throw new java.io.EOFException();\n        }\n        readIdx = active.getHeaderCount();\n    }\n\n    public org.apache.commons.compress.archivers.dump.DumpArchiveEntry getNextDumpEntry() throws java.io.IOException {\n        return getNextEntry();\n    }\n\n    @java.lang.Override\n    public org.apache.commons.compress.archivers.dump.DumpArchiveEntry getNextEntry() throws java.io.IOException {\n        org.apache.commons.compress.archivers.dump.DumpArchiveEntry entry = null;\n        java.lang.String path = null;\n        if (!queue.isEmpty()) {\n            return queue.remove();\n        }\n        while (entry == null) {\n            if (hasHitEOF) {\n                return null;\n            }\n            while (readIdx < active.getHeaderCount()) {\n                if ((!active.isSparseRecord(readIdx++)) && (raw.skip(org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE) == (-1))) {\n                    throw new java.io.EOFException();\n                }\n            } \n            readIdx = 0;\n            filepos = raw.getBytesRead();\n            byte[] headerBytes = raw.readRecord();\n            if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(headerBytes)) {\n                throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n            }\n            active = org.apache.commons.compress.archivers.dump.DumpArchiveEntry.parse(headerBytes);\n            while (org.apache.commons.compress.archivers.dump.DumpArchiveConstants.SEGMENT_TYPE.ADDR == active.getHeaderType()) {\n                if (raw.skip(org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE * (active.getHeaderCount() - active.getHeaderHoles())) == (-1)) {\n                    throw new java.io.EOFException();\n                }\n                filepos = raw.getBytesRead();\n                headerBytes = raw.readRecord();\n                if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(headerBytes)) {\n                    throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n                }\n                active = org.apache.commons.compress.archivers.dump.DumpArchiveEntry.parse(headerBytes);\n            } \n            if (org.apache.commons.compress.archivers.dump.DumpArchiveConstants.SEGMENT_TYPE.END == active.getHeaderType()) {\n                hasHitEOF = true;\n                return null;\n            }\n            entry = active;\n            if (entry.isDirectory()) {\n                readDirectoryEntry(active);\n                entryOffset = 0;\n                entrySize = 0;\n                readIdx = active.getHeaderCount();\n            } else {\n                entryOffset = 0;\n                entrySize = active.getEntrySize();\n                readIdx = 0;\n            }\n            recordOffset = readBuf.length;\n            path = getPath(entry);\n            if (path == null) {\n                entry = null;\n            }\n        } \n        entry.setName(path);\n        entry.setSimpleName(names.get(entry.getIno()).getName());\n        entry.setOffset(filepos);\n        return entry;\n    }\n\n    private void readDirectoryEntry(org.apache.commons.compress.archivers.dump.DumpArchiveEntry entry) throws java.io.IOException {\n        long size = entry.getEntrySize();\n        boolean first = true;\n        while (first || (org.apache.commons.compress.archivers.dump.DumpArchiveConstants.SEGMENT_TYPE.ADDR == entry.getHeaderType())) {\n            if (!first) {\n                raw.readRecord();\n            }\n            if ((!names.containsKey(entry.getIno())) && (org.apache.commons.compress.archivers.dump.DumpArchiveConstants.SEGMENT_TYPE.INODE == entry.getHeaderType())) {\n                pending.put(entry.getIno(), entry);\n            }\n            int datalen = org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE * entry.getHeaderCount();\n            if (blockBuffer.length < datalen) {\n                blockBuffer = new byte[datalen];\n            }\n            if (raw.read(blockBuffer, 0, datalen) != datalen) {\n                throw new java.io.EOFException();\n            }\n            int reclen = 0;\n            for (int i = 0; (i < (datalen - 8)) && (i < (size - 8)); i += reclen) {\n                int ino = org.apache.commons.compress.archivers.dump.DumpArchiveUtil.convert32(blockBuffer, i);\n                reclen = org.apache.commons.compress.archivers.dump.DumpArchiveUtil.convert16(blockBuffer, i + 4);\n                byte type = blockBuffer[i + 6];\n                java.lang.String name = org.apache.commons.compress.archivers.dump.DumpArchiveUtil.decode(zipEncoding, blockBuffer, i + 8, blockBuffer[i + 7]);\n                if (\".\".equals(name) || \"..\".equals(name)) {\n                    continue;\n                }\n                org.apache.commons.compress.archivers.dump.Dirent d = new org.apache.commons.compress.archivers.dump.Dirent(ino, entry.getIno(), type, name);\n                names.put(ino, d);\n                for (java.util.Map.Entry<java.lang.Integer, org.apache.commons.compress.archivers.dump.DumpArchiveEntry> e : pending.entrySet()) {\n                    java.lang.String path = getPath(e.getValue());\n                    if (path != null) {\n                        e.getValue().setName(path);\n                        e.getValue().setSimpleName(names.get(e.getKey()).getName());\n                        queue.add(e.getValue());\n                    }\n                }\n                for (org.apache.commons.compress.archivers.dump.DumpArchiveEntry e : queue) {\n                    pending.remove(e.getIno());\n                }\n            }\n            byte[] peekBytes = raw.peek();\n            if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(peekBytes)) {\n                throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n            }\n            entry = org.apache.commons.compress.archivers.dump.DumpArchiveEntry.parse(peekBytes);\n            first = false;\n            size -= org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE;\n        } \n    }\n\n    private java.lang.String getPath(org.apache.commons.compress.archivers.dump.DumpArchiveEntry entry) {\n        java.util.Stack<java.lang.String> elements = new java.util.Stack<java.lang.String>();\n        org.apache.commons.compress.archivers.dump.Dirent dirent = null;\n        for (int i = entry.getIno(); ; i = dirent.getParentIno()) {\n            if (!names.containsKey(i)) {\n                elements.clear();\n                break;\n            }\n            dirent = names.get(i);\n            elements.push(dirent.getName());\n            if (dirent.getIno() == dirent.getParentIno()) {\n                break;\n            }\n        }\n        if (elements.isEmpty()) {\n            pending.put(entry.getIno(), entry);\n            return null;\n        }\n        java.lang.StringBuilder sb = new java.lang.StringBuilder(elements.pop());\n        while (!elements.isEmpty()) {\n            sb.append('/');\n            sb.append(elements.pop());\n        } \n        return sb.toString();\n    }\n\n    @java.lang.Override\n    public int read(byte[] buf, int off, int len) throws java.io.IOException {\n        int totalRead = 0;\n        if ((hasHitEOF || isClosed) || (entryOffset >= entrySize)) {\n            return -1;\n        }\n        if (active == null) {\n            throw new java.lang.IllegalStateException(\"No current dump entry\");\n        }\n        if ((len + entryOffset) > entrySize) {\n            len = ((int) (entrySize - entryOffset));\n        }\n        while (len > 0) {\n            int sz = (len > (readBuf.length - recordOffset)) ? readBuf.length - recordOffset : len;\n            if ((recordOffset + sz) <= readBuf.length) {\n                java.lang.System.arraycopy(readBuf, recordOffset, buf, off, sz);\n                totalRead += sz;\n                recordOffset += sz;\n                len -= sz;\n                off += sz;\n            }\n            if (len > 0) {\n                if (readIdx >= 512) {\n                    byte[] headerBytes = raw.readRecord();\n                    if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(headerBytes)) {\n                        throw new org.apache.commons.compress.archivers.dump.InvalidFormatException();\n                    }\n                    active = org.apache.commons.compress.archivers.dump.DumpArchiveEntry.parse(headerBytes);\n                    readIdx = 0;\n                }\n                if (!active.isSparseRecord(readIdx++)) {\n                    int r = raw.read(readBuf, 0, readBuf.length);\n                    if (r != readBuf.length) {\n                        throw new java.io.EOFException();\n                    }\n                } else {\n                    java.util.Arrays.fill(readBuf, ((byte) (0)));\n                }\n                recordOffset = 0;\n            }\n        } \n        entryOffset += totalRead;\n        return totalRead;\n    }\n\n    @java.lang.Override\n    public void close() throws java.io.IOException {\n        if (!isClosed) {\n            isClosed = true;\n            raw.close();\n        }\n    }\n\n    public static boolean matches(byte[] buffer, int length) {\n        if (length < 32) {\n            return false;\n        }\n        if (length >= org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE) {\n            return org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(buffer);\n        }\n        return org.apache.commons.compress.archivers.dump.DumpArchiveConstants.NFS_MAGIC == org.apache.commons.compress.archivers.dump.DumpArchiveUtil.convert32(buffer, 24);\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "Try",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "LocalVariable",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "Invocation",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Constructor",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Assignment",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "true",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "this.encoding = encoding",
            "src_parent": "{\n    this.raw = new org.apache.commons.compress.archivers.dump.TapeInputStream(is);\n    this.hasHitEOF = false;\n    this.encoding = encoding;\n    this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n    try {\n        byte[] headerBytes = raw.readRecord();\n        if (!org.apache.commons.compress.archivers.dump.DumpArchiveUtil.verify(headerBytes)) {\n            throw new org.apache.commons.compress.archivers.dump.UnrecognizedFormatException();\n        }\n        summary = new org.apache.commons.compress.archivers.dump.DumpArchiveSummary(headerBytes, this.zipEncoding);\n        raw.resetBlockSize(summary.getNTRec(), summary.isCompressed());\n        blockBuffer = new byte[4 * org.apache.commons.compress.archivers.dump.DumpArchiveConstants.TP_SIZE];\n        readCLRI();\n        readBITS();\n    } catch (java.io.IOException ex) {\n        throw new org.apache.commons.compress.archivers.ArchiveException(ex.getMessage(), ex);\n    }\n    org.apache.commons.compress.archivers.dump.Dirent root = new org.apache.commons.compress.archivers.dump.Dirent(2, 2, 4, \".\");\n    names.put(2, root);\n    queue = new java.util.PriorityQueue<org.apache.commons.compress.archivers.dump.DumpArchiveEntry>(10, new java.util.Comparator<org.apache.commons.compress.archivers.dump.DumpArchiveEntry>() {\n        public int compare(org.apache.commons.compress.archivers.dump.DumpArchiveEntry p, org.apache.commons.compress.archivers.dump.DumpArchiveEntry q) {\n            if ((p.getOriginalName() == null) || (q.getOriginalName() == null)) {\n                return java.lang.Integer.MAX_VALUE;\n            }\n            return p.getOriginalName().compareTo(q.getOriginalName());\n        }\n    });\n}",
            "src_parent_type": "Block",
            "src_type": "Assignment"
          }
        }
      ],
      "file_name": "DumpArchiveInputStream"
    },
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Field",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "final java.lang.String encoding;",
            "src_parent": "public class TarArchiveOutputStream extends org.apache.commons.compress.archivers.ArchiveOutputStream {\n    public static final int LONGFILE_ERROR = 0;\n\n    public static final int LONGFILE_TRUNCATE = 1;\n\n    public static final int LONGFILE_GNU = 2;\n\n    public static final int LONGFILE_POSIX = 3;\n\n    public static final int BIGNUMBER_ERROR = 0;\n\n    public static final int BIGNUMBER_STAR = 1;\n\n    public static final int BIGNUMBER_POSIX = 2;\n\n    private long currSize;\n\n    private java.lang.String currName;\n\n    private long currBytes;\n\n    private final byte[] recordBuf;\n\n    private int assemLen;\n\n    private final byte[] assemBuf;\n\n    private int longFileMode = org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.LONGFILE_ERROR;\n\n    private int bigNumberMode = org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.BIGNUMBER_ERROR;\n\n    private int recordsWritten;\n\n    private final int recordsPerBlock;\n\n    private final int recordSize;\n\n    private boolean closed = false;\n\n    private boolean haveUnclosedEntry = false;\n\n    private boolean finished = false;\n\n    private final java.io.OutputStream out;\n\n    private final org.apache.commons.compress.archivers.zip.ZipEncoding zipEncoding;\n\n    final java.lang.String encoding;\n\n    private boolean addPaxHeadersForNonAsciiNames = false;\n\n    private static final org.apache.commons.compress.archivers.zip.ZipEncoding ASCII = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(\"ASCII\");\n\n    public TarArchiveOutputStream(java.io.OutputStream os) {\n        this(os, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_BLKSIZE, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    public TarArchiveOutputStream(java.io.OutputStream os, java.lang.String encoding) {\n        this(os, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_BLKSIZE, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    public TarArchiveOutputStream(java.io.OutputStream os, int blockSize) {\n        this(os, blockSize, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE);\n    }\n\n    public TarArchiveOutputStream(java.io.OutputStream os, int blockSize, java.lang.String encoding) {\n        this(os, blockSize, org.apache.commons.compress.archivers.tar.TarConstants.DEFAULT_RCDSIZE, encoding);\n    }\n\n    public TarArchiveOutputStream(java.io.OutputStream os, int blockSize, int recordSize) {\n        this(os, blockSize, recordSize, null);\n    }\n\n    public TarArchiveOutputStream(java.io.OutputStream os, int blockSize, int recordSize, java.lang.String encoding) {\n        out = new org.apache.commons.compress.utils.CountingOutputStream(os);\n        this.encoding = encoding;\n        this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n        this.assemLen = 0;\n        this.assemBuf = new byte[recordSize];\n        this.recordBuf = new byte[recordSize];\n        this.recordSize = recordSize;\n        this.recordsPerBlock = blockSize / recordSize;\n    }\n\n    public void setLongFileMode(int longFileMode) {\n        this.longFileMode = longFileMode;\n    }\n\n    public void setBigNumberMode(int bigNumberMode) {\n        this.bigNumberMode = bigNumberMode;\n    }\n\n    public void setAddPaxHeadersForNonAsciiNames(boolean b) {\n        addPaxHeadersForNonAsciiNames = b;\n    }\n\n    @java.lang.Deprecated\n    @java.lang.Override\n    public int getCount() {\n        return ((int) (getBytesWritten()));\n    }\n\n    @java.lang.Override\n    public long getBytesWritten() {\n        return ((org.apache.commons.compress.utils.CountingOutputStream) (out)).getBytesWritten();\n    }\n\n    @java.lang.Override\n    public void finish() throws java.io.IOException {\n        if (finished) {\n            throw new java.io.IOException(\"This archive has already been finished\");\n        }\n        if (haveUnclosedEntry) {\n            throw new java.io.IOException(\"This archives contains unclosed entries.\");\n        }\n        writeEOFRecord();\n        writeEOFRecord();\n        padAsNeeded();\n        out.flush();\n        finished = true;\n    }\n\n    @java.lang.Override\n    public void close() throws java.io.IOException {\n        if (!finished) {\n            finish();\n        }\n        if (!closed) {\n            out.close();\n            closed = true;\n        }\n    }\n\n    public int getRecordSize() {\n        return this.recordSize;\n    }\n\n    @java.lang.Override\n    public void putArchiveEntry(org.apache.commons.compress.archivers.ArchiveEntry archiveEntry) throws java.io.IOException {\n        if (finished) {\n            throw new java.io.IOException(\"Stream has already been finished\");\n        }\n        org.apache.commons.compress.archivers.tar.TarArchiveEntry entry = ((org.apache.commons.compress.archivers.tar.TarArchiveEntry) (archiveEntry));\n        java.util.Map<java.lang.String, java.lang.String> paxHeaders = new java.util.HashMap<java.lang.String, java.lang.String>();\n        final java.lang.String entryName = entry.getName();\n        boolean paxHeaderContainsPath = handleLongName(entry, entryName, paxHeaders, \"path\", org.apache.commons.compress.archivers.tar.TarConstants.LF_GNUTYPE_LONGNAME, \"file name\");\n        final java.lang.String linkName = entry.getLinkName();\n        boolean paxHeaderContainsLinkPath = ((linkName != null) && (linkName.length() > 0)) && handleLongName(entry, linkName, paxHeaders, \"linkpath\", org.apache.commons.compress.archivers.tar.TarConstants.LF_GNUTYPE_LONGLINK, \"link name\");\n        if (bigNumberMode == org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.BIGNUMBER_POSIX) {\n            addPaxHeadersForBigNumbers(paxHeaders, entry);\n        } else if (bigNumberMode != org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.BIGNUMBER_STAR) {\n            failForBigNumbers(entry);\n        }\n        if ((addPaxHeadersForNonAsciiNames && (!paxHeaderContainsPath)) && (!org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.ASCII.canEncode(entryName))) {\n            paxHeaders.put(\"path\", entryName);\n        }\n        if (((addPaxHeadersForNonAsciiNames && (!paxHeaderContainsLinkPath)) && (entry.isLink() || entry.isSymbolicLink())) && (!org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.ASCII.canEncode(linkName))) {\n            paxHeaders.put(\"linkpath\", linkName);\n        }\n        if (paxHeaders.size() > 0) {\n            writePaxHeaders(entry, entryName, paxHeaders);\n        }\n        entry.writeEntryHeader(recordBuf, zipEncoding, bigNumberMode == org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.BIGNUMBER_STAR);\n        writeRecord(recordBuf);\n        currBytes = 0;\n        if (entry.isDirectory()) {\n            currSize = 0;\n        } else {\n            currSize = entry.getSize();\n        }\n        currName = entryName;\n        haveUnclosedEntry = true;\n    }\n\n    @java.lang.Override\n    public void closeArchiveEntry() throws java.io.IOException {\n        if (finished) {\n            throw new java.io.IOException(\"Stream has already been finished\");\n        }\n        if (!haveUnclosedEntry) {\n            throw new java.io.IOException(\"No current entry to close\");\n        }\n        if (assemLen > 0) {\n            for (int i = assemLen; i < assemBuf.length; ++i) {\n                assemBuf[i] = 0;\n            }\n            writeRecord(assemBuf);\n            currBytes += assemLen;\n            assemLen = 0;\n        }\n        if (currBytes < currSize) {\n            throw new java.io.IOException((((((\"entry '\" + currName) + \"' closed at '\") + currBytes) + \"' before the '\") + currSize) + \"' bytes specified in the header were written\");\n        }\n        haveUnclosedEntry = false;\n    }\n\n    @java.lang.Override\n    public void write(byte[] wBuf, int wOffset, int numToWrite) throws java.io.IOException {\n        if (!haveUnclosedEntry) {\n            throw new java.lang.IllegalStateException(\"No current tar entry\");\n        }\n        if ((currBytes + numToWrite) > currSize) {\n            throw new java.io.IOException((((((\"request to write '\" + numToWrite) + \"' bytes exceeds size in header of '\") + currSize) + \"' bytes for entry '\") + currName) + \"'\");\n        }\n        if (assemLen > 0) {\n            if ((assemLen + numToWrite) >= recordBuf.length) {\n                int aLen = recordBuf.length - assemLen;\n                java.lang.System.arraycopy(assemBuf, 0, recordBuf, 0, assemLen);\n                java.lang.System.arraycopy(wBuf, wOffset, recordBuf, assemLen, aLen);\n                writeRecord(recordBuf);\n                currBytes += recordBuf.length;\n                wOffset += aLen;\n                numToWrite -= aLen;\n                assemLen = 0;\n            } else {\n                java.lang.System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);\n                wOffset += numToWrite;\n                assemLen += numToWrite;\n                numToWrite = 0;\n            }\n        }\n        while (numToWrite > 0) {\n            if (numToWrite < recordBuf.length) {\n                java.lang.System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);\n                assemLen += numToWrite;\n                break;\n            }\n            writeRecord(wBuf, wOffset);\n            int num = recordBuf.length;\n            currBytes += num;\n            numToWrite -= num;\n            wOffset += num;\n        } \n    }\n\n    void writePaxHeaders(org.apache.commons.compress.archivers.tar.TarArchiveEntry entry, java.lang.String entryName, java.util.Map<java.lang.String, java.lang.String> headers) throws java.io.IOException {\n        java.lang.String name = \"./PaxHeaders.X/\" + stripTo7Bits(entryName);\n        if (name.length() >= org.apache.commons.compress.archivers.tar.TarConstants.NAMELEN) {\n            name = name.substring(0, org.apache.commons.compress.archivers.tar.TarConstants.NAMELEN - 1);\n        }\n        org.apache.commons.compress.archivers.tar.TarArchiveEntry pex = new org.apache.commons.compress.archivers.tar.TarArchiveEntry(name, org.apache.commons.compress.archivers.tar.TarConstants.LF_PAX_EXTENDED_HEADER_LC);\n        transferModTime(entry, pex);\n        java.io.StringWriter w = new java.io.StringWriter();\n        for (java.util.Map.Entry<java.lang.String, java.lang.String> h : headers.entrySet()) {\n            java.lang.String key = h.getKey();\n            java.lang.String value = h.getValue();\n            int len = ((key.length() + value.length()) + 3) + 2;\n            java.lang.String line = ((((len + \" \") + key) + \"=\") + value) + \"\\n\";\n            int actualLength = line.getBytes(org.apache.commons.compress.utils.CharsetNames.UTF_8).length;\n            while (len != actualLength) {\n                len = actualLength;\n                line = ((((len + \" \") + key) + \"=\") + value) + \"\\n\";\n                actualLength = line.getBytes(org.apache.commons.compress.utils.CharsetNames.UTF_8).length;\n            } \n            w.write(line);\n        }\n        byte[] data = w.toString().getBytes(org.apache.commons.compress.utils.CharsetNames.UTF_8);\n        pex.setSize(data.length);\n        putArchiveEntry(pex);\n        write(data);\n        closeArchiveEntry();\n    }\n\n    private java.lang.String stripTo7Bits(java.lang.String name) {\n        final int length = name.length();\n        java.lang.StringBuilder result = new java.lang.StringBuilder(length);\n        for (int i = 0; i < length; i++) {\n            char stripped = ((char) (name.charAt(i) & 0x7f));\n            if (shouldBeReplaced(stripped)) {\n                result.append(\"_\");\n            } else {\n                result.append(stripped);\n            }\n        }\n        return result.toString();\n    }\n\n    private boolean shouldBeReplaced(char c) {\n        return ((c == 0) || (c == '/')) || (c == '\\\\');\n    }\n\n    private void writeEOFRecord() throws java.io.IOException {\n        java.util.Arrays.fill(recordBuf, ((byte) (0)));\n        writeRecord(recordBuf);\n    }\n\n    @java.lang.Override\n    public void flush() throws java.io.IOException {\n        out.flush();\n    }\n\n    @java.lang.Override\n    public org.apache.commons.compress.archivers.ArchiveEntry createArchiveEntry(java.io.File inputFile, java.lang.String entryName) throws java.io.IOException {\n        if (finished) {\n            throw new java.io.IOException(\"Stream has already been finished\");\n        }\n        return new org.apache.commons.compress.archivers.tar.TarArchiveEntry(inputFile, entryName);\n    }\n\n    private void writeRecord(byte[] record) throws java.io.IOException {\n        if (record.length != recordSize) {\n            throw new java.io.IOException((((\"record to write has length '\" + record.length) + \"' which is not the record size of '\") + recordSize) + \"'\");\n        }\n        out.write(record);\n        recordsWritten++;\n    }\n\n    private void writeRecord(byte[] buf, int offset) throws java.io.IOException {\n        if ((offset + recordSize) > buf.length) {\n            throw new java.io.IOException((((((\"record has length '\" + buf.length) + \"' with offset '\") + offset) + \"' which is less than the record size of '\") + recordSize) + \"'\");\n        }\n        out.write(buf, offset, recordSize);\n        recordsWritten++;\n    }\n\n    private void padAsNeeded() throws java.io.IOException {\n        int start = recordsWritten % recordsPerBlock;\n        if (start != 0) {\n            for (int i = start; i < recordsPerBlock; i++) {\n                writeEOFRecord();\n            }\n        }\n    }\n\n    private void addPaxHeadersForBigNumbers(java.util.Map<java.lang.String, java.lang.String> paxHeaders, org.apache.commons.compress.archivers.tar.TarArchiveEntry entry) {\n        addPaxHeaderForBigNumber(paxHeaders, \"size\", entry.getSize(), org.apache.commons.compress.archivers.tar.TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"gid\", entry.getGroupId(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"mtime\", entry.getModTime().getTime() / 1000, org.apache.commons.compress.archivers.tar.TarConstants.MAXSIZE);\n        addPaxHeaderForBigNumber(paxHeaders, \"uid\", entry.getUserId(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devmajor\", entry.getDevMajor(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        addPaxHeaderForBigNumber(paxHeaders, \"SCHILY.devminor\", entry.getDevMinor(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        failForBigNumber(\"mode\", entry.getMode(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n    }\n\n    private void addPaxHeaderForBigNumber(java.util.Map<java.lang.String, java.lang.String> paxHeaders, java.lang.String header, long value, long maxValue) {\n        if ((value < 0) || (value > maxValue)) {\n            paxHeaders.put(header, java.lang.String.valueOf(value));\n        }\n    }\n\n    private void failForBigNumbers(org.apache.commons.compress.archivers.tar.TarArchiveEntry entry) {\n        failForBigNumber(\"entry size\", entry.getSize(), org.apache.commons.compress.archivers.tar.TarConstants.MAXSIZE);\n        failForBigNumberWithPosixMessage(\"group id\", entry.getGroupId(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        failForBigNumber(\"last modification time\", entry.getModTime().getTime() / 1000, org.apache.commons.compress.archivers.tar.TarConstants.MAXSIZE);\n        failForBigNumber(\"user id\", entry.getUserId(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        failForBigNumber(\"mode\", entry.getMode(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        failForBigNumber(\"major device number\", entry.getDevMajor(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n        failForBigNumber(\"minor device number\", entry.getDevMinor(), org.apache.commons.compress.archivers.tar.TarConstants.MAXID);\n    }\n\n    private void failForBigNumber(java.lang.String field, long value, long maxValue) {\n        failForBigNumber(field, value, maxValue, \"\");\n    }\n\n    private void failForBigNumberWithPosixMessage(java.lang.String field, long value, long maxValue) {\n        failForBigNumber(field, value, maxValue, \" Use STAR or POSIX extensions to overcome this limit\");\n    }\n\n    private void failForBigNumber(java.lang.String field, long value, long maxValue, java.lang.String additionalMsg) {\n        if ((value < 0) || (value > maxValue)) {\n            throw new java.lang.RuntimeException((((((field + \" '\") + value) + \"' is too big ( > \") + maxValue) + \" ).\") + additionalMsg);\n        }\n    }\n\n    private boolean handleLongName(org.apache.commons.compress.archivers.tar.TarArchiveEntry entry, java.lang.String name, java.util.Map<java.lang.String, java.lang.String> paxHeaders, java.lang.String paxHeaderName, byte linkType, java.lang.String fieldName) throws java.io.IOException {\n        final java.nio.ByteBuffer encodedName = zipEncoding.encode(name);\n        final int len = encodedName.limit() - encodedName.position();\n        if (len >= org.apache.commons.compress.archivers.tar.TarConstants.NAMELEN) {\n            if (longFileMode == org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.LONGFILE_POSIX) {\n                paxHeaders.put(paxHeaderName, name);\n                return true;\n            } else if (longFileMode == org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.LONGFILE_GNU) {\n                org.apache.commons.compress.archivers.tar.TarArchiveEntry longLinkEntry = new org.apache.commons.compress.archivers.tar.TarArchiveEntry(org.apache.commons.compress.archivers.tar.TarConstants.GNU_LONGLINK, linkType);\n                longLinkEntry.setSize(len + 1);\n                transferModTime(entry, longLinkEntry);\n                putArchiveEntry(longLinkEntry);\n                write(encodedName.array(), encodedName.arrayOffset(), len);\n                write(0);\n                closeArchiveEntry();\n            } else if (longFileMode != org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.LONGFILE_TRUNCATE) {\n                throw new java.lang.RuntimeException(((((fieldName + \" '\") + name) + \"' is too long ( > \") + org.apache.commons.compress.archivers.tar.TarConstants.NAMELEN) + \" bytes)\");\n            }\n        }\n        return false;\n    }\n\n    private void transferModTime(org.apache.commons.compress.archivers.tar.TarArchiveEntry from, org.apache.commons.compress.archivers.tar.TarArchiveEntry to) {\n        java.util.Date fromModTime = from.getModTime();\n        long fromModTimeSeconds = fromModTime.getTime() / 1000;\n        if ((fromModTimeSeconds < 0) || (fromModTimeSeconds > org.apache.commons.compress.archivers.tar.TarConstants.MAXSIZE)) {\n            fromModTime = new java.util.Date(0);\n        }\n        to.setModTime(fromModTime);\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "Invocation",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Constructor",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Assignment",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "this.encoding = encoding",
            "src_parent": "{\n    out = new org.apache.commons.compress.utils.CountingOutputStream(os);\n    this.encoding = encoding;\n    this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n    this.assemLen = 0;\n    this.assemBuf = new byte[recordSize];\n    this.recordBuf = new byte[recordSize];\n    this.recordSize = recordSize;\n    this.recordsPerBlock = blockSize / recordSize;\n}",
            "src_parent_type": "Block",
            "src_type": "Assignment"
          }
        }
      ],
      "file_name": "TarArchiveOutputStream"
    },
    {
      "features": [
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Class",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Field",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "final java.lang.String encoding;",
            "src_parent": "public class CpioArchiveInputStream extends org.apache.commons.compress.archivers.ArchiveInputStream implements org.apache.commons.compress.archivers.cpio.CpioConstants {\n    private boolean closed = false;\n\n    private org.apache.commons.compress.archivers.cpio.CpioArchiveEntry entry;\n\n    private long entryBytesRead = 0;\n\n    private boolean entryEOF = false;\n\n    private final byte[] tmpbuf = new byte[4096];\n\n    private long crc = 0;\n\n    private final java.io.InputStream in;\n\n    private final byte[] TWO_BYTES_BUF = new byte[2];\n\n    private final byte[] FOUR_BYTES_BUF = new byte[4];\n\n    private final byte[] SIX_BYTES_BUF = new byte[6];\n\n    private final int blockSize;\n\n    private final org.apache.commons.compress.archivers.zip.ZipEncoding zipEncoding;\n\n    final java.lang.String encoding;\n\n    public CpioArchiveInputStream(final java.io.InputStream in) {\n        this(in, org.apache.commons.compress.archivers.cpio.CpioConstants.BLOCK_SIZE, org.apache.commons.compress.utils.CharsetNames.US_ASCII);\n    }\n\n    public CpioArchiveInputStream(final java.io.InputStream in, java.lang.String encoding) {\n        this(in, org.apache.commons.compress.archivers.cpio.CpioConstants.BLOCK_SIZE, encoding);\n    }\n\n    public CpioArchiveInputStream(final java.io.InputStream in, int blockSize) {\n        this(in, blockSize, org.apache.commons.compress.utils.CharsetNames.US_ASCII);\n    }\n\n    public CpioArchiveInputStream(final java.io.InputStream in, int blockSize, java.lang.String encoding) {\n        this.in = in;\n        this.blockSize = blockSize;\n        this.encoding = encoding;\n        this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n    }\n\n    @java.lang.Override\n    public int available() throws java.io.IOException {\n        ensureOpen();\n        if (this.entryEOF) {\n            return 0;\n        }\n        return 1;\n    }\n\n    @java.lang.Override\n    public void close() throws java.io.IOException {\n        if (!this.closed) {\n            in.close();\n            this.closed = true;\n        }\n    }\n\n    private void closeEntry() throws java.io.IOException {\n        while (skip(((long) (java.lang.Integer.MAX_VALUE))) == java.lang.Integer.MAX_VALUE) {\n        } \n    }\n\n    private void ensureOpen() throws java.io.IOException {\n        if (this.closed) {\n            throw new java.io.IOException(\"Stream closed\");\n        }\n    }\n\n    public org.apache.commons.compress.archivers.cpio.CpioArchiveEntry getNextCPIOEntry() throws java.io.IOException {\n        ensureOpen();\n        if (this.entry != null) {\n            closeEntry();\n        }\n        readFully(TWO_BYTES_BUF, 0, TWO_BYTES_BUF.length);\n        if (org.apache.commons.compress.archivers.cpio.CpioUtil.byteArray2long(TWO_BYTES_BUF, false) == org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(false);\n        } else if (org.apache.commons.compress.archivers.cpio.CpioUtil.byteArray2long(TWO_BYTES_BUF, true) == org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_OLD_BINARY) {\n            this.entry = readOldBinaryEntry(true);\n        } else {\n            java.lang.System.arraycopy(TWO_BYTES_BUF, 0, SIX_BYTES_BUF, 0, TWO_BYTES_BUF.length);\n            readFully(SIX_BYTES_BUF, TWO_BYTES_BUF.length, FOUR_BYTES_BUF.length);\n            java.lang.String magicString = org.apache.commons.compress.utils.ArchiveUtils.toAsciiString(SIX_BYTES_BUF);\n            if (magicString.equals(org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_NEW)) {\n                this.entry = readNewEntry(false);\n            } else if (magicString.equals(org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_NEW_CRC)) {\n                this.entry = readNewEntry(true);\n            } else if (magicString.equals(org.apache.commons.compress.archivers.cpio.CpioConstants.MAGIC_OLD_ASCII)) {\n                this.entry = readOldAsciiEntry();\n            } else {\n                throw new java.io.IOException(((\"Unknown magic [\" + magicString) + \"]. Occured at byte: \") + getBytesRead());\n            }\n        }\n        this.entryBytesRead = 0;\n        this.entryEOF = false;\n        this.crc = 0;\n        if (this.entry.getName().equals(org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER)) {\n            this.entryEOF = true;\n            skipRemainderOfLastBlock();\n            return null;\n        }\n        return this.entry;\n    }\n\n    private void skip(int bytes) throws java.io.IOException {\n        if (bytes > 0) {\n            readFully(FOUR_BYTES_BUF, 0, bytes);\n        }\n    }\n\n    @java.lang.Override\n    public int read(final byte[] b, final int off, final int len) throws java.io.IOException {\n        ensureOpen();\n        if (((off < 0) || (len < 0)) || (off > (b.length - len))) {\n            throw new java.lang.IndexOutOfBoundsException();\n        } else if (len == 0) {\n            return 0;\n        }\n        if ((this.entry == null) || this.entryEOF) {\n            return -1;\n        }\n        if (this.entryBytesRead == this.entry.getSize()) {\n            skip(entry.getDataPadCount());\n            this.entryEOF = true;\n            if ((this.entry.getFormat() == org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC) && (this.crc != this.entry.getChksum())) {\n                throw new java.io.IOException(\"CRC Error. Occured at byte: \" + getBytesRead());\n            }\n            return -1;\n        }\n        int tmplength = ((int) (java.lang.Math.min(len, this.entry.getSize() - this.entryBytesRead)));\n        if (tmplength < 0) {\n            return -1;\n        }\n        int tmpread = readFully(b, off, tmplength);\n        if (this.entry.getFormat() == org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC) {\n            for (int pos = 0; pos < tmpread; pos++) {\n                this.crc += b[pos] & 0xff;\n            }\n        }\n        this.entryBytesRead += tmpread;\n        return tmpread;\n    }\n\n    private final int readFully(final byte[] b, final int off, final int len) throws java.io.IOException {\n        int count = org.apache.commons.compress.utils.IOUtils.readFully(in, b, off, len);\n        count(count);\n        if (count < len) {\n            throw new java.io.EOFException();\n        }\n        return count;\n    }\n\n    private long readBinaryLong(final int length, final boolean swapHalfWord) throws java.io.IOException {\n        byte[] tmp = new byte[length];\n        readFully(tmp, 0, tmp.length);\n        return org.apache.commons.compress.archivers.cpio.CpioUtil.byteArray2long(tmp, swapHalfWord);\n    }\n\n    private long readAsciiLong(final int length, final int radix) throws java.io.IOException {\n        byte[] tmpBuffer = new byte[length];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        return java.lang.Long.parseLong(org.apache.commons.compress.utils.ArchiveUtils.toAsciiString(tmpBuffer), radix);\n    }\n\n    private org.apache.commons.compress.archivers.cpio.CpioArchiveEntry readNewEntry(final boolean hasCrc) throws java.io.IOException {\n        org.apache.commons.compress.archivers.cpio.CpioArchiveEntry ret;\n        if (hasCrc) {\n            ret = new org.apache.commons.compress.archivers.cpio.CpioArchiveEntry(org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW_CRC);\n        } else {\n            ret = new org.apache.commons.compress.archivers.cpio.CpioArchiveEntry(org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_NEW);\n        }\n        ret.setInode(readAsciiLong(8, 16));\n        long mode = readAsciiLong(8, 16);\n        if (org.apache.commons.compress.archivers.cpio.CpioUtil.fileType(mode) != 0) {\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(8, 16));\n        ret.setGID(readAsciiLong(8, 16));\n        ret.setNumberOfLinks(readAsciiLong(8, 16));\n        ret.setTime(readAsciiLong(8, 16));\n        ret.setSize(readAsciiLong(8, 16));\n        ret.setDeviceMaj(readAsciiLong(8, 16));\n        ret.setDeviceMin(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMaj(readAsciiLong(8, 16));\n        ret.setRemoteDeviceMin(readAsciiLong(8, 16));\n        long namesize = readAsciiLong(8, 16);\n        ret.setChksum(readAsciiLong(8, 16));\n        java.lang.String name = readCString(((int) (namesize)));\n        ret.setName(name);\n        if ((org.apache.commons.compress.archivers.cpio.CpioUtil.fileType(mode) == 0) && (!name.equals(org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER))) {\n            throw new java.io.IOException(((\"Mode 0 only allowed in the trailer. Found entry name: \" + name) + \" Occured at byte: \") + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n        return ret;\n    }\n\n    private org.apache.commons.compress.archivers.cpio.CpioArchiveEntry readOldAsciiEntry() throws java.io.IOException {\n        org.apache.commons.compress.archivers.cpio.CpioArchiveEntry ret = new org.apache.commons.compress.archivers.cpio.CpioArchiveEntry(org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_ASCII);\n        ret.setDevice(readAsciiLong(6, 8));\n        ret.setInode(readAsciiLong(6, 8));\n        final long mode = readAsciiLong(6, 8);\n        if (org.apache.commons.compress.archivers.cpio.CpioUtil.fileType(mode) != 0) {\n            ret.setMode(mode);\n        }\n        ret.setUID(readAsciiLong(6, 8));\n        ret.setGID(readAsciiLong(6, 8));\n        ret.setNumberOfLinks(readAsciiLong(6, 8));\n        ret.setRemoteDevice(readAsciiLong(6, 8));\n        ret.setTime(readAsciiLong(11, 8));\n        long namesize = readAsciiLong(6, 8);\n        ret.setSize(readAsciiLong(11, 8));\n        final java.lang.String name = readCString(((int) (namesize)));\n        ret.setName(name);\n        if ((org.apache.commons.compress.archivers.cpio.CpioUtil.fileType(mode) == 0) && (!name.equals(org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER))) {\n            throw new java.io.IOException(((\"Mode 0 only allowed in the trailer. Found entry: \" + name) + \" Occured at byte: \") + getBytesRead());\n        }\n        return ret;\n    }\n\n    private org.apache.commons.compress.archivers.cpio.CpioArchiveEntry readOldBinaryEntry(final boolean swapHalfWord) throws java.io.IOException {\n        org.apache.commons.compress.archivers.cpio.CpioArchiveEntry ret = new org.apache.commons.compress.archivers.cpio.CpioArchiveEntry(org.apache.commons.compress.archivers.cpio.CpioConstants.FORMAT_OLD_BINARY);\n        ret.setDevice(readBinaryLong(2, swapHalfWord));\n        ret.setInode(readBinaryLong(2, swapHalfWord));\n        final long mode = readBinaryLong(2, swapHalfWord);\n        if (org.apache.commons.compress.archivers.cpio.CpioUtil.fileType(mode) != 0) {\n            ret.setMode(mode);\n        }\n        ret.setUID(readBinaryLong(2, swapHalfWord));\n        ret.setGID(readBinaryLong(2, swapHalfWord));\n        ret.setNumberOfLinks(readBinaryLong(2, swapHalfWord));\n        ret.setRemoteDevice(readBinaryLong(2, swapHalfWord));\n        ret.setTime(readBinaryLong(4, swapHalfWord));\n        long namesize = readBinaryLong(2, swapHalfWord);\n        ret.setSize(readBinaryLong(4, swapHalfWord));\n        final java.lang.String name = readCString(((int) (namesize)));\n        ret.setName(name);\n        if ((org.apache.commons.compress.archivers.cpio.CpioUtil.fileType(mode) == 0) && (!name.equals(org.apache.commons.compress.archivers.cpio.CpioConstants.CPIO_TRAILER))) {\n            throw new java.io.IOException(((\"Mode 0 only allowed in the trailer. Found entry: \" + name) + \"Occured at byte: \") + getBytesRead());\n        }\n        skip(ret.getHeaderPadCount());\n        return ret;\n    }\n\n    private java.lang.String readCString(final int length) throws java.io.IOException {\n        byte[] tmpBuffer = new byte[length - 1];\n        readFully(tmpBuffer, 0, tmpBuffer.length);\n        this.in.read();\n        return zipEncoding.decode(tmpBuffer);\n    }\n\n    @java.lang.Override\n    public long skip(final long n) throws java.io.IOException {\n        if (n < 0) {\n            throw new java.lang.IllegalArgumentException(\"negative skip length\");\n        }\n        ensureOpen();\n        int max = ((int) (java.lang.Math.min(n, java.lang.Integer.MAX_VALUE)));\n        int total = 0;\n        while (total < max) {\n            int len = max - total;\n            if (len > this.tmpbuf.length) {\n                len = this.tmpbuf.length;\n            }\n            len = read(this.tmpbuf, 0, len);\n            if (len == (-1)) {\n                this.entryEOF = true;\n                break;\n            }\n            total += len;\n        } \n        return total;\n    }\n\n    @java.lang.Override\n    public org.apache.commons.compress.archivers.ArchiveEntry getNextEntry() throws java.io.IOException {\n        return getNextCPIOEntry();\n    }\n\n    private void skipRemainderOfLastBlock() throws java.io.IOException {\n        long readFromLastBlock = getBytesRead() % blockSize;\n        long remainingBytes = (readFromLastBlock == 0) ? 0 : blockSize - readFromLastBlock;\n        while (remainingBytes > 0) {\n            long skipped = skip(blockSize - readFromLastBlock);\n            if (skipped <= 0) {\n                break;\n            }\n            remainingBytes -= skipped;\n        } \n    }\n\n    public static boolean matches(byte[] signature, int length) {\n        if (length < 6) {\n            return false;\n        }\n        if ((signature[0] == 0x71) && ((signature[1] & 0xff) == 0xc7)) {\n            return true;\n        }\n        if ((signature[1] == 0x71) && ((signature[0] & 0xff) == 0xc7)) {\n            return true;\n        }\n        if (signature[0] != 0x30) {\n            return false;\n        }\n        if (signature[1] != 0x37) {\n            return false;\n        }\n        if (signature[2] != 0x30) {\n            return false;\n        }\n        if (signature[3] != 0x37) {\n            return false;\n        }\n        if (signature[4] != 0x30) {\n            return false;\n        }\n        if (signature[5] == 0x31) {\n            return true;\n        }\n        if (signature[5] == 0x32) {\n            return true;\n        }\n        if (signature[5] == 0x37) {\n            return true;\n        }\n        return false;\n    }\n}",
            "src_parent_type": "Class",
            "src_type": "Field"
          }
        },
        {
          "FEATURES_METHOD_INVOCATION": {},
          "FEATURES_TYPEACCESS": {},
          "FEATURES_VARS": {},
          "S10_METHOD_CALL_WITH_NULL_GUARD": "false",
          "S11_FAULTY_CLASS_EXCEPTION_TYPE": "false",
          "S12_METHOD_CALL_WITH_TRY_CATCH": "false",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_2": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_AFTER_3": "",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_1": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_2": "Assignment",
          "S13_TYPE_OF_FAULTY_STATEMENT_BEFORE_3": "Invocation",
          "S14_TYPE_OF_FAULTY_STATEMENT_PARENT": "Constructor",
          "S15_HAS_OBJECTIVE_METHOD_CALL": "false",
          "S16_HAS_Invocations_Prone_Exception": "false",
          "S18_In_Synchronized_Method": "false",
          "S1_LOCAL_VAR_NOT_ASSIGNED": "false",
          "S1_LOCAL_VAR_NOT_USED": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NORMAL_GUARD": "false",
          "S2_SIMILAR_OBJECT_TYPE_WITH_NULL_GUARD": "false",
          "S3_TYPE_OF_FAULTY_STATEMENT": "Assignment",
          "S4_Field_NOT_ASSIGNED": "false",
          "S4_Field_NOT_USED": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NORMAL_GUARD": "false",
          "S5_SIMILAR_PRIMITIVE_TYPE_WITH_NULL_GUARD": "false",
          "S6_METHOD_THROWS_EXCEPTION": "false",
          "S7_OBJECT_USED_IN_ASSIGNMENT": "false",
          "S8_PRIMITIVE_USED_IN_ASSIGNMENT": "false",
          "S9_METHOD_CALL_WITH_NORMAL_GUARD": "false",
          "ast_info": {
            "dst": "null",
            "dst_parent": "null",
            "dst_parent_type": "null",
            "dst_type": "null",
            "operator": "DEL",
            "src": "this.encoding = encoding",
            "src_parent": "{\n    this.in = in;\n    this.blockSize = blockSize;\n    this.encoding = encoding;\n    this.zipEncoding = org.apache.commons.compress.archivers.zip.ZipEncodingHelper.getZipEncoding(encoding);\n}",
            "src_parent_type": "Block",
            "src_type": "Assignment"
          }
        }
      ],
      "file_name": "CpioArchiveInputStream"
    }
  ],
  "id": "Compress_29"
}